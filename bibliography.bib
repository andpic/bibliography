% Encoding: UTF-8

@InProceedings{Dufrechou2018,
  author    = {Dufrechou, Ernesto and Ezzatti, Pablo},
  title     = {Solving Sparse Triangular Linear Systems in Modern {GPUs}: A Synchronization-Free Algorithm},
  booktitle = {Proceedings of the 26th Euromicro International Conference on Parallel, Distributed and Network-based Processing},
  year      = {2018},
  series    = {PDP},
  location  = {Cambridge, UK},
  pages     = {196--203},
  doi       = {10.1109/PDP2018.2018.00034},
  abstract  = {Sparse triangular linear systems are ubiquitous in a wide range of science and engineering fields, and represent one of the most important building blocks of Sparse Numerical Lineal Algebra methods. For this reason, their parallel solution has been subject of exhaustive study, and efficient implementations of this kernel can be found for almost every hardware platform. However, the strong data dependencies that serialize a great deal of the execution and the load imbalance inherent to the triangular structure poses serious difficulties for its parallel performance, specially in the context of massively- parallel processors such as GPUs. To this day, the most widespread GPU implementation of this kernel is the one distributed in NVIDIA CUSPARSE library, which relies on a preprocessing stage to determine the parallel execution schedule. Although the solution phase is highly efficient, this strategy pays the cost of constant synchronizations with the CPU. In this work, we present a synchronization-free GPU al- gorithm to solve sparse triangular linear systems for the CSR format. The experimental evaluation shows performance improvements over CUSPARSE and a recently proposed synchronization-free method for the CSC matrix format.},
  timestamp = {Tue, 03 Jul 2018 17:32:39 +0200},
}

@PhdThesis{Achterberg2008,
  author      = {Tobias Achterberg},
  title       = {Constraint Integer Programming},
  institution = {Technische Universität Berlin},
  date        = {2008},
  url         = {https://opus4.kobv.de/opus4-zib/frontdoor/index/index/docId/1112},
 abstract = {This thesis introduces the novel paradigm of constraint integer programming (CIP), which integrates constraint programming (CP) and mixed integer programming (MIP) modeling and solving techniques. It is supplemented by the software SCIP, which is a solver and framework for constraint integer programming that also features SAT solving techniques. SCIP is freely available in source code for academic and non-commercial purposes. \\ Our constraint integer programming approach is a generalization of MIP that allows for the inclusion of arbitrary constraints, as long as they turn into linear constraints on the continuous variables after all integer variables have been fixed. The constraints, may they be linear or more complex, are treated by any combination of CP and MIP techniques: the propagation of the domains by constraint specific algorithms, the generation of a linear relaxation and its solving by LP methods, and the strengthening of the LP by cutting plane separation. \\ The current version of SCIP comes with all of the necessary components to solve mixed integer programs. In the thesis, we cover most of these ingredients and present extensive computational results to compare different variants for the individual building blocks of a MIP solver. We focus on the algorithms and their impact on the overall performance of the solver. \\ In addition to mixed integer programming, the thesis deals with chip design verification, which is an important topic of electronic design automation. Chip manufacturers have to make sure that the logic design of a circuit conforms to the specification of the chip. Otherwise, the chip would show an erroneous behavior that may cause failures in the device where it is employed. An important subproblem of chip design verification is the property checking problem, which is to verify whether a circuit satisfies a specified property. We show how this problem can be modeled as constraint integer program and provide a number of problem-specific algorithms that exploit the structure of the individual constraints and the circuit as a whole. Another set of extensive computational benchmarks compares our CIP approach to the current state-of-the-art SAT methodology and documents the success of our method.},
  owner       = {Andrea},
  timestamp   = {2013.12.28},
}

@InCollection{Alvarado1993,
  author    = {Alvarado, Fernando L. and Pothen, Alex and Schreiber, Robert},
  title     = {Highly Parallel Sparse Triangular Solution},
  booktitle = {{G}raph {T}heory and {S}parse {M}atrix {C}omputation},
  date      = {1993},
  editor    = {George, Alan and Gilbert, John R. and Liu, Joseph W. H.},
  language  = {English},
  volume    = {56},
  series    = {The IMA Volumes in Mathematics and its Applications},
  publisher = {Springer New York},
  isbn      = {978-1-4613-8371-0},
  pages     = {141--157},
  doi       = {10.1007/978-1-4613-8369-7_7},
  abstract  = {In this paper we survey a recent approach for solving sparse triangular systems of equations on highly parallel computers. This approach employs a partitioned representation of the inverse of the triangular matrix so that the solution can be computed by matrix-vector multiplication. The number of factors in the partitioned inverse is proportional to the number of general communication steps (router steps on a CM-2) required in a highly parallel algorithm. We describe partitioning algorithms that minimize the number of factors in the partitioned inverse over all symmetric permutations of the triangular matrix such that the permuted matrix continues to be triangular. For a Cholesky factor we describe an O(n) time and space algorithm to solve the partitioning problem above, where n is the order of the matrix. Our computational results on a CM-2 demonstrate the potential superiority of the partitioned inverse approach over the conventional substitution algorithm for highly parallel sparse triangular solution. Finally we describe current and future extensions of these results.},
  keywords  = {chordal graph; directed acyclic graph; elimination tree; graph partitioning; massively parallel computers; partitioned inverse; sparse triangular systems; transitive closure},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@TechReport{Alvarez2015,
  author      = {Alejandro Marcos Alvarez and Louis Wehenkel and Quentin Louveaux},
  title       = {Machine Learning to Balance the Load in Parallel Branch-and-Bound},
  institution = {Department of Electrical Engineering and Computer Science, University of Liege},
  date        = {2015},
  month       = mar,
  url         = {http://www.optimization-online.org/DB_FILE/2015/03/4832.pdf},
  abstract    = {We describe in this paper a new approach to parallelize branch-and-bound on a certain number of processors. We propose to split the optimization of the original problem into the optimization of several subproblems that can be optimized separately with the goal that the amount of work that each processor carries out is balanced between the processors, while achieving interesting speedups. The main innovation of our approach consists in the use of machine learning to create a function able to estimate the difficulty (number of nodes) of a subproblem of the original problem. We also present a set of features that we developed in order to characterize the encountered subproblems. These features are used as input of the function learned with machine learning in order to estimate the difficulty of a subproblem. The estimates of the numbers of nodes are then used to decide how to partition the original optimization tree into a given number of subproblems, and to decide how to distribute them among the available processors. The experiments that we carry out show that our approach succeeds in balancing the amount of work between the processors, and that interesting speedups can be achieved with little effort.},
  owner       = {andrea},
  timestamp   = {2015.04.07},
}

@Book{Anderson1999,
  author    = {Anderson, E. and Bai, Z. and Bischof, C. and Blackford, S. and Demmel, J. and Dongarra, J. and Du Croz, J. and Greenbaum, A. and Hammarling, S. and McKenney, A. and Sorensen, D.},
  title     = {{LAPACK} Users' Guide},
  date      = {1999},
  edition   = {Third},
  publisher = {Society for Industrial and Applied Mathematics},
  location  = {Philadelphia, PA},
  isbn      = {0-89871-447-8 (paperback)},
  owner     = {andrea},
  timestamp = {2016.11.07},
}

@PhdThesis{Anderson2014,
  author      = {Michael Anderson},
  title       = {A Framework for Composing High-Performance {OpenCL} from Python Descriptions},
  institution = {University of California at Berkeley},
  date        = {2014},
  note        = {UCB/EECS-2014-177},
  month       = nov,
  url         = {http://digitalassets.lib.berkeley.edu/etd/ucb/text/Anderson_berkeley_0028E_14773.pdf},
  abstract    = {Parallel processors have become ubiquitous; most programmers today have access to parallel hardware such as multi-core processors and graphics processors. This has created an implementation gap, where efficiency programmers with knowledge of hardware details can attain high performance by exploiting parallel hardware, while productivity programmers with application-level knowledge may not understand low-level performance trade-offs. Ideally, we would like to be able to write programs in productivity languages such as Python or MATLAB, and achieve performance comparable to the best hand-tuned code. \\One approach toward achieving this ideal is to write libraries that get high efficiency on certain operations, and call these libraries from the productivity environment. We propose a framework that addresses two problems with this approach: that it fails to fuse operations for efficiency, and that it may not consider runtime information such as shapes and sizes of data structures. With our framework, efficiency programmers write and/or generate customized OpenCL snippets at runtime and the framework automatically fuses, compiles, and executes these operations based on a Python description. \\We evaluate the framework with case studies of two very different applications: space-time adaptive radar processing and optical flow. For a space-time adaptive radar processing application, our framework's implementation is competitive with a hand-coded implementation that uses a vendor-optimized library. For optical flow, a computer vision application, the framework achieves frame rates that are between 0.5$\times$ and 0.97$\times$ hand-coded OpenCL performance.},
  owner       = {andrea},
  timestamp   = {2015.01.29},
}

@Article{Asanovic2006,
  author       = {Asanovic, Krste and Catanzaro, Bryan Christopher and Patterson, David a and Yelick, Katherine},
  title        = {The Landscape of Parallel Computing Research : A View from {B}erkeley},
  journaltitle = {Communications of the {ACM}},
  date         = {2006},
  volume       = {52},
  number       = {10},
  pages        = {56--67},
  issn         = {0001-0782},
  doi          = {10.1145/1562764.1562783},
 abstract = {Writing programs that scale with increasing numbers of cores should be as easy as writing programs for sequential computers.},
  institution  = {EECS Department, University of California Berkeley},
  owner        = {andrea},
  timestamp    = {2016.09.07},
}

@Article{Aykanat2004,
  author       = {Cevdet Aykanat and Ali Pinar and Ümit V. Çatalyürek},
  title        = {Permuting Sparse Rectangular Matrices into Block-Diagonal Form},
  journaltitle = {{SIAM} Journal on Scientific Computing},
  date         = {2004},
  volume       = {25},
  number       = {6},
  pages        = {1860--1879},
  doi          = {10.1137/S1064827502401953},
  abstract     = {We investigate the problem of permuting a sparse rectangular matrix into block-diagonal form. Block-diagonal form of a matrix grants an inherent parallelism for solving the deriving problem, as recently investigated in the context of mathematical programming, LU factorization, and QR factorization. To represent the nonzero structure of a matrix, we propose bipartite graph and hypergraph models that reduce the permutation problem to those of graph partitioning by vertex separator and hypergraph partitioning, respectively. Our experiments on a wide range of matrices, using the state-of-the-art graph and hypergraph partitioning tools MeTiS and PaToH, revealed that the proposed methods yield very effective solutions both in terms of solution quality and runtime.},
  owner        = {andrea},
  timestamp    = {2014.12.15},
}

@Article{Azad2016,
  Title                    = {Exploiting Multiple Levels of Parallelism in Sparse Matrix-Matrix Multiplication},
  Author                   = {Ariful Azad and Grey Ballard and Aydin Buluç and James Demmel and Laura Grigori and Oded Schwartz and Sivan Toledo and Samuel Williams},
  Number                   = {6},
  Pages                    = {C624-C651},
  Volume                   = {38},

 abstract = {Sparse matrix-matrix multiplication (or SpGEMM) is a key primitive for many high-performance graph algorithms as well as for some linear solvers, such as algebraic multigrid. The scaling of existing parallel implementations of SpGEMM is heavily bound by communication. Even though 3D (or 2.5D) algorithms have been proposed and theoretically analyzed in the flat MPI model on Erdős–Rényi matrices, those algorithms had not been implemented in practice and their complexities had not been analyzed for the general case. In this work, we present the first implementation of the 3D SpGEMM formulation that exploits multiple (intranode and internode) levels of parallelism, achieving significant speedups over the state-of-the-art publicly available codes at all levels of concurrencies. We extensively evaluate our implementation and identify bottlenecks that should be subject to further research.},
  Date                     = {2016},
  Doi                      = {10.1137/15M104253X},
  Journaltitle             = {SIAM Journal on Scientific Computing}
}

@InProceedings{Bakhoda2009,
  author    = {Ali Bakhoda and George L. Yuan and Wilson W. L. Fung and Henry Wong and Tor M. Aamodt},
  title     = {Analyzing {CUDA} workloads using a detailed {GPU} simulator},
  booktitle = {{P}roceedings of the {IEEE} {I}nternational {S}ymposium on {P}erformance {A}nalysis of {S}ystems and {S}oftware},
  date      = {2009},
  series    = {ISPASS '09},
  location  = {Boston, MA, USA},
  month     = apr,
  pages     = {163--174},
  doi       = {10.1109/ISPASS.2009.4919648},
  abstract  = {Modern Graphic Processing Units (GPUs) provide sufficiently flexible programming models that understanding their performance can provide insight in designing tomorrow's manycore processors, whether those are GPUs or otherwise. The combination of multiple, multithreaded, SIMD cores makes studying these GPUs useful in understanding tradeoffs among memory, data, and thread level parallelism. While modern GPUs offer orders of magnitude more raw computing power than contemporary CPUs, many important applications, even those with abundant data level parallelism, do not achieve peak performance. This paper characterizes several non-graphics applications written in NVIDIA's CUDA programming model by running them on a novel detailed microarchitecture performance simulator that runs NVIDIA's parallel thread execution (PTX) virtual instruction set. For this study, we selected twelve non-trivial CUDA applications demonstrating varying levels of performance improvement on GPU hardware (versus a CPU-only sequential version of the application). We study the performance of these applications on our GPU performance simulator with configurations comparable to contemporary high-end graphics cards. We characterize the performance impact of several microarchitecture design choices including choice of interconnect topology, use of caches, design of memory controller, parallel workload distribution mechanisms, and memory request coalescing hardware. Two observations we make are (1) that for the applications we study, performance is more sensitive to interconnect bisection bandwidth rather than latency, and (2) that, for some applications, running fewer threads concurrently than on-chip resources might otherwise allow can improve performance by reducing contention in the memory system.},
  keywords  = {cache storage;computer graphic equipment;instruction sets;multi-threading;multiprocessing systems;parallel architectures;CUDA programming;CUDA workload;GPU hardware;GPU simulator;caches;flexible programming model;graphic processing unit;high-end graphics card;interconnect topology;memory controller;memory request coalescing hardware;microarchitecture design;microarchitecture performance simulator;parallel thread execution;parallel workload distribution;virtual instruction set;Analytical models;Computational modeling;Concurrent computing;Graphics;Hardware;Microarchitecture;Parallel processing;Parallel programming;Process design;Yarn},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@TechReport{Baskaran2008,
  Title                    = {Optimizing Sparse Matrix-Vector Multiplication on {GPUs} Using Compile-time and Run-time Strategies},
  Author                   = {Muthu Manikandan Baskaran and Rajesh Bordawekar},
  Institution              = {IBM Research Division},

 abstract = {We are witnessing the emergence of Graphics Processor units (GPUs) as powerful massively parallel systems. Furthermore, the introduction of new APIs for general-purpose computations on GPUs, namely CUDA from NVIDIA, Stream SDK from AMD, and OpenCL, makes GPUs an attractive choice for high-performance numerical and scientific computing. Sparse Matrix-Vector multiplication (SpMV) is one of the most important and heavily used kernels in scientific computing. However with indirect and irregular memory accesses resulting in more memory accesses per floating point operation, optimization of SpMV kernel is a significant challenge in any architecture. \\ In this paper, we evaluate the various challenges in developing a high-performance SpMV kernel on NVIDIA GPUs using the CUDA programming model and propose a framework that employs both compile-time and run-time optimizations. The compile-time optimizations include: (1) exploiting synchronization-free parallelism, (2) optimized thread mapping based on the affinity towards optimal memory access pattern, (3) optimized off-chip memory access to tolerate the high latency, and (4) exploiting data reuse. The runtime optimizations involve a runtime inspection of the sparse matrix to determine dense non-zero sub-blocks, which facilitate the reuse of input vector elements while execution. We propose a new blocked storage format for storing and accessing elements of a sparse matrix in an optimized manner from the GPU memories. We evaluate our optimizations over two classes of NVIDIA GPU chips, namely, GeForce 8800 GTX and GeForce GTX 280, and we compare the performance of our approach with that of existing parallel SpMV implementations such as the one from NVIDIA's CUDPP library and the one implemented using optimal segmented scan primitive. Our approach outperforms the other existing implementations by a factor of 2 to 4. Using our framework, we achieve a peak SpMV performance that is 70\% of the performance observed for SpMV computations using dense matrices stored in sparse format.},
  Date                     = {2008},
  Owner                    = {andrea},
  Timestamp                = {2017.05.07},
  Url                      = {http://domino.watson.ibm.com/library/CyberDig.nsf/1e4115aea78b6e7c85256b360066f0d4/1d32f6d23b99f7898525752200618339?OpenDocument}
}

@InProceedings{Bayliss2006,
  author    = {Samuel Bayliss and Christos-S. Bouganis and George A. Constantinides and Wayne Luk},
  title     = {An {FPGA} Implementation of the Simplex Algorithm},
  booktitle = {{P}roceedings of the {IEEE} {I}nternational {C}onference on {F}ield {P}rogrammable {T}echnology},
  date      = {2006},
  series    = {FPT '06},
  location  = {Bangkok, TH},
  month     = dec,
  pages     = {49--56},
  doi       = {10.1109/FPT.2006.270294},
  abstract  = {Linear programming is applied to a large variety of scientific computing applications and industrial optimization problems. The Simplex algorithm is widely used for solving linear programs due to its robustness and scalability properties. However, application of the current software implementations of the Simplex algorithm to real-life optimization problems are time consuming when used as the bounding engine within an integer linear programming framework. This work aims to accelerate the Simplex algorithm by proposing a novel parameterizable hardware implementation of the algorithm on an FPGA. Evaluation of the proposed design using real problems demonstrates a speedup of up to 20 times over a highly optimized commercial software implementation running on a 3.4GHz Pentium 4 processor, which is itself 100 times faster than one of the main public domain solvers},
  keywords  = {field programmable gate arrays;integer programming;linear programming;logic design;microprocessor chips;3.4 GHz;FPGA;Pentium 4 processor;Simplex algorithm;bounding engine;industrial optimization problems;integer linear programming framework;scientific computing applications;Application software;Computer industry;Engines;Field programmable gate arrays;Integer linear programming;Linear programming;Robustness;Scalability;Scientific computing;Software algorithms},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Book{Bazaraa2010,
  Title                    = {Linear Programming and Network Flows},
  Author                   = {Mokhtar S. Bazaraa and John J. Jarvis and Hanif D. Sherali},
  Publisher                = {Wiley},

  Date                     = {2010},
  Owner                    = {andrea},
  Timestamp                = {2015.09.28}
}

@Article{Belotti2013,
  author       = {Pietro Belotti and Christian Kirches and Sven Leyffer and Jeff Linderoth and James Luedtke and Ashutosh Mahajan},
  title        = {Mixed-integer nonlinear optimization},
  journaltitle = {Acta Numerica},
  date         = {2013},
  volume       = {22},
  month        = {5},
  pages        = {1--131},
  issn         = {1474-0508},
  doi          = {10.1017/S0962492913000032},
  abstract     = {Many optimal decision problems in scientific, engineering, and public sector applications involve both discrete decisions and nonlinear system dynamics that affect the quality of the final design or plan. These decision problems lead to mixed-integer nonlinear programming (MINLP) problems that combine the combinatorial difficulty of optimizing over discrete variable sets with the challenges of handling nonlinear functions. We review models and applications of MINLP, and survey the state of the art in methods for solving this challenging class of problems. \\Most solution methods for MINLP apply some form of tree search. We distinguish two broad classes of methods: single-tree and multitree methods. We discuss these two classes of methods first in the case where the underlying problem functions are convex. Classical single-tree methods include nonlinear branch-and-bound and branch-and-cut methods, while classical multitree methods include outer approximation and Benders decomposition. The most efficient class of methods for convex MINLP are hybrid methods that combine the strengths of both classes of classical techniques. \\Non-convex MINLPs pose additional challenges, because they contain non-convex functions in the objective function or the constraints; hence even when the integer variables are relaxed to be continuous, the feasible region is generally non-convex, resulting in many local minima. We discuss a range of approaches for tackling this challenging class of problems, including piecewise linear approximations, generic strategies for obtaining convex relaxations for non-convex functions, spatial branch-and-bound methods, and a small sample of techniques that exploit particular types of non-convex structures to obtain improved convex relaxations. \\We finish our survey with a brief discussion of three important aspects of MINLP. First, we review heuristic techniques that can obtain good feasible solution in situations where the search-tree has grown too large or we require real-time solutions. Second, we describe an emerging area of mixed-integer optimal control that adds systems of ordinary differential equations to MINLP. Third, we survey the state of the art in software for MINLP.},
  numpages     = {131},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@Manual{Berkelaar2013,
  author    = {Berkelaar, M. and Eikland, K. and Notebaert, P.},
  title     = {{lp\_solve} reference guide},
  date      = {2013},
  edition   = {5.5.2.0},
  note      = {Accessed 30 March 2014},
  url       = {http://lpsolve.sourceforge.net/5.5/},
  month     = apr,
  owner     = {andrea},
  timestamp = {2014.03.30},
}

@Book{Bertsekas1999,
  author    = {Dimitri P. Bertsekas},
  title     = {Nonlinear Programming},
  date      = {1999},
  publisher = {Athena Scientific},
  isbn      = {1-886529-00-0},
  owner     = {andrea},
  timestamp = {2015.09.28},
}

@InProceedings{Bieling2010,
  author     = {Jakob Bieling and Patrick Peschlow and Peter Martini},
  title      = {An Efficient {GPU} implementation of the Revised Simplex Method},
  booktitle  = {{P}roceedings of the 2011 {IEEE} {I}nternational {P}arallel and {D}istributed {P}rocessing {S}ymposium},
  date       = {2010},
  series     = {IPDPS '10},
  location   = {Atlanta, GE, USA},
  pages      = {1--8},
  doi        = {10.1109/IPDPSW.2010.5470831},
  abstract   = {The computational power provided by the massive parallelism of modern graphics processing units (GPUs) has moved increasingly into focus over the past few years. In particular, general purpose computing on GPUs (GPGPU) is attracting attention among researchers and practitioners alike. Yet GPGPU research is still in its infancy, and a major challenge is to rearrange existing algorithms so as to obtain a significant performance gain from the execution on a GPU. In this paper, we address this challenge by presenting an efficient GPU implementation of a very popular algorithm for linear programming, the revised simplex method. We describe how to carry out the steps of the revised simplex method to take full advantage of the parallel processing capabilities of a GPU. Our experiments demonstrate considerable speedup over a widely used CPU implementation, thus underlining the tremendous potential of GPGPU.},
  annotation = {{I}mplementation of the two-phase tableau simplex method with steepest edge heuristics instead of pseudocost. {A}lways find the edge from the current vertex with the steepest local slope under the objective function leading to an adjacent vertex. {I}mplemented with {C}-for-graphics. {T}ested against randomly generated instances, max speedup $\times$10 compared to the same problem on {GPLK}. {PC} {I}ntel {C}ore 2 {D}uo {E}8400 {CPU} (3 {GH}z, {FSB} 1333 {MH}z, 6 {MB} {L}2 cache), {N}vidia {G}e{F}orce 9600 {GT} {GPU} (1 {GB} {RAM}, 64 shader processors).},
  file       = {:home/andrea/Dropbox/PhD/Papers/Bieling et al. - An Efficient GPU Implementation of the Revised Simplex Method.pdf:PDF},
  keywords   = {coprocessors;linear programming;mathematics computing;parallel processing;general purpose computing;graphics processing units;linear programming;parallel processing;revised simplex method;Central Processing Unit;Computer graphics;Computer science;Concurrent computing;Hardware;Linear algebra;Linear programming;Parallel processing;Performance gain;Scalability},
  owner      = {ap8213},
  timestamp  = {2014.10.09},
}

@Article{Bixby2002,
  author       = {Robert E. Bixby},
  title        = {Solving Real-World Linear Programs: A Decade And More Of Progress},
  journaltitle = {Operations Research},
  date         = {2002},
  volume       = {50},
  number       = {1},
  month        = jan,
  pages        = {3--15},
  doi          = {10.1287/opre.50.1.3.17780},
  abstract     = {This paper is an invited contribution to the 50th anniversary issue of the journalOperations Research, published by the Institute of Operations Research and Management Science (INFORMS). It describes one person's perspective on the development of computational tools for linear programming. The paper begins with a short personal history, followed by historical remarks covering the some 40 years of linear-programming developments that predate my own involvement in this subject. It concludes with a more detailed look at the evolution of computational linear programming since 1987.},
  owner        = {andrea},
  timestamp    = {2015.09.28},
}

@InBook{Bixby2004,
  author    = {Robert E. Bixby and Mary Fenelon and Zonghao Gu and Ed Rothberg and Roland Wunderling},
  title     = {Mixed-Integer Programming: A Progress Report},
  booktitle = {{T}he {S}harpest {C}ut},
  date      = {2004},
  editor    = {Martin Grötschel},
  series    = {MOS-SIAM Series on Optimization},
  chapter   = {18},
  pages     = {309--325},
  doi       = {10.1137/1.9780898718805.ch18},
  eprint    = {http://epubs.siam.org/doi/pdf/10.1137/1.9780898718805.ch18},
  abstract  = {Over the last several decades, from the early 1970s to as recently as 1998, the underlying solution technology in commercial mixed-integer programming codes remained essentially unchanged. In spite of important advances in the theory, many of these advances have clear computational value. In the last several years, that situation has changed. The result has been a major step forward in our ability to solve real-world mixed-integer programming problems.},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Article{Blackford2001,
  Title                    = {An Updated Set of Basic Linear Algebra Subprograms ({BLAS})},
  Author                   = {L. S. Blackford and J. Demmel and J. Dongarra and I. Duff and S. Hammarling and G. Henry and M. Heroux and L. Kaufman and A. Lumsdaine and A. Petitet and R. Pozo and K. Remington and R. C. Whaley},
  Pages                    = {135--151},
  Volume                   = {28},

  Date                     = {2001},
  Doi                      = {10.1145/567806.567807},
  Journaltitle             = {{ACM} Transactions on Mathematical Software},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07}
}

@InProceedings{Bleris2006,
  author    = {Bleris, L.G. and Vouzis, P.D. and Arnold, M.G. and Kothare, M.V.},
  title     = {A co-processor {FPGA} platform for the implementation of real-time model predictive control},
  booktitle = {{A}merican {C}ontrol {C}onference},
  date      = {2006},
  series    = {ACC '06},
  location  = {Minneapolis, MN, USA},
  month     = jun,
  pages     = {6 pp.},
  doi       = {10.1109/ACC.2006.1656499},
  abstract  = {In order to effectively control nonlinear and multivariable models, and to incorporate constraints on system states, inputs and outputs (bounds, rate of change), a suitable (sometimes necessary) controller is model predictive control (MPC). MPC is an optimization-based control scheme that requires abundant matrix operations for the calculation of the optimal control moves. In this work we propose a mixed software and hardware embedded MPC implementation. Using a codesign step and based on profiling results, we decompose the optimization algorithm into two parts: one that fits into a host processor and one that fits into a custom made unit that performs the computationally demanding arithmetic operations. The profiling results and information on the co-processor design are provided},
  keywords  = {control engineering computing;coprocessors;field programmable gate arrays;matrix algebra;multivariable control systems;nonlinear control systems;optimal control;predictive control;coprocessor FPGA platform;coprocessor design;matrix operations;multivariable model control;nonlinear model control;optimal control;optimization-based control;real-time model predictive control;Arithmetic;Coprocessors;Embedded software;Field programmable gate arrays;Hardware;Matrix decomposition;Nonlinear control systems;Optimal control;Predictive control;Predictive models},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@InProceedings{Blumofe1995,
  Title                    = {Cilk: An Efficient Multithreaded Runtime System},
  Author                   = {Blumofe, Robert D. and Joerg, Christopher F. and Kuszmaul, Bradley C. and Leiserson, Charles E. and Randall, Keith H. and Zhou, Yuli},
  Booktitle                = {{P}roceedings of the 5th {ACM} {SIGPLAN} {S}ymposium on {P}rinciples and {P}ractice of {P}arallel {P}rogramming},

  Address                  = {New York, NY, USA},
  Pages                    = {207--216},
  Publisher                = {ACM},
  Series                   = {PPOPP '95},

 abstract = {Cilk (pronounced “silk”) is a C-based runtime system for multi-threaded parallel programming. In this paper, we document the efficiency of the Cilk work-stealing scheduler, both empirically and analytically. We show that on real and synthetic applications, the “work” and “critical path” of a Cilk computation can be used to accurately model performance. Consequently, a Cilk programmer can focus on reducing the work and critical path of his computation, insulated from load balancing and other runtime scheduling issues. We also prove that for the class of “fully strict” (well-structured) programs, the Cilk scheduler achieves space, time and communication bounds all within a constant factor of optimal.The Cilk runtime system currently runs on the Connection Machine CM5 MPP, the Intel Paragon MPP, the Silicon Graphics Power Challenge SMP, and the MIT Phish network of workstations. Applications written in Cilk include protein folding, graphic rendering, backtrack search, and the *Socrates chess program, which won third prize in the 1994 ACM International Computer Chess Championship.},
  Acmid                    = {209958},
  Date                     = {1995},
  Doi                      = {10.1145/209936.209958},
  ISBN                     = {0-89791-700-6},
  Location                 = {Santa Barbara, California, USA},
  Numpages                 = {10}
}

@InProceedings{Boechat2013,
  author    = {Marc-Alexandre Boéchat and Junyi Liu and Helfried Peyril and Alessandro Zanarini and Thomas Besselmann},
  title     = {An Architecture for Solving Quadratic Programs with the Fast Gradient Method on a Field Programmable Gate Array},
  booktitle = {{P}roceedings of the 21st {M}editerranean {C}onference on {C}ontrol {A}utomation},
  date      = {2013},
  series    = {MED '13},
  location  = {Platanias-Chania, GR},
  month     = jun,
  pages     = {1557--1562},
  doi       = {10.1109/MED.2013.6608929},
  abstract  = {In this paper an architecture for the implementation of gradient-based optimisation methods on a Field Programmable Gate Array (FPGA) is proposed. Combining the algorithmic advantages of gradient-based algorithms with the computational strengths of a tailored FPGA implementation allows to solve quadratic programs occurring, for example, in Model Predictive Control (MPC) applications in the microsecond range. The experimental comparisons show a computational advantage of the proposed FPGA implementation against parallel software versions ranging between one and two orders of magnitude. The proposed FPGA-based solution can broaden the applicability of MPC to problems that were considered out-of-reach till recent years.},
  keywords  = {field programmable gate arrays;gradient methods;predictive control;quadratic programming;FPGA;MPC applications;architecture;computational strengths;fast gradient method;field programmable gate array;gradient-based algorithms;gradient-based optimisation methods;microsecond range;model predictive control;quadratic programs;Adders;Clocks;Computer architecture;Field programmable gate arrays;Gradient methods;Vectors},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@InProceedings{Boisvert1997,
  Title                    = {Matrix Market: A Web Resource for Test Matrix Collections},
  Author                   = {Boisvert, Ronald F. and Pozo, Roldan and Remington, Karin and Barrett, Richard F. and Dongarra, Jack J.},
  Booktitle                = {{P}roceedings of the {IFIP} {TC2/WG2.5} {W}orking {C}onference on {Q}uality of {N}umerical {S}oftware: {A}ssessment and {E}nhancement},

  Address                  = {London, UK},
  Pages                    = {125--137},
  Publisher                = {Chapman \& Hall, Ltd.},

  Date                     = {1997},
  ISBN                     = {0-412-80530-8},
  Location                 = {Oxford, UK},
  Numpages                 = {13},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07},
  Url                      = {http://dl.acm.org/citation.cfm?id=265834.265854}
}

@InProceedings{Boland2008,
  author    = {Boland, D. and Constantinides, G.A.},
  title     = {An {FPGA}-based implementation of the {MINRES} algorithm},
  booktitle = {{P}roceedings of the {I}nternational {C}onference on {F}ield {P}rogrammable {L}ogic and {A}pplications},
  date      = {2008},
  series    = {FPL '08},
  location  = {Heidelberg, DEU},
  month     = sep,
  pages     = {379--384},
  doi       = {10.1109/FPL.2008.4629967},
  abstract  = {Due to continuous improvements in the resources available on FPGAs, it is becoming increasingly possible to accelerate floating point algorithms. The solution of a system of linear equations forms the basis of many problems in engineering and science, but its calculation is highly time consuming. The minimum residual algorithm (MINRES) is one method to solve this problem, and is highly effective provided the matrix exhibits certain characteristics. This paper examines an IEEE 754 single precision floating point implementation of the MINRES algorithm on an FPGA. It demonstrates that through parallelisation and heavy pipelining of all floating point components it is possible to achieve a sustained performance of up to 53 GFLOPS on the Virtex5-330T. This compares favourably to other hardware implementations of floating point matrix inversion algorithms, and corresponds to an improvement of nearly an order of magnitude compared to a software implementation.},
  keywords  = {field programmable gate arrays;floating point arithmetic;FPGA-based implementation;IEEE 754;MINRES algorithm;Virtex5-330T;floating point algorithms;floating point matrix inversion;linear equations;minimum residual algorithm;parallelisation;Continuous improvement;Educational institutions;Equations;Field programmable gate arrays;Hardware;Iterative algorithms;Iterative methods;Scientific computing;Sparse matrices;Symmetric matrices},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@InBook{Bosch2005,
  author    = {Robert Bosch and Michael Tick},
  title     = {Integer programming},
  booktitle = {{S}earch {M}ethodologies: {I}ntroductory {T}utorials in {O}ptimization and {D}ecision {S}upport {T}echniques},
  date      = {2005},
  editor    = {Edmund K. Burke and Graham Kendall},
  publisher = {Springer, US},
  chapter   = {9},
  pages     = {69--95},
  doi       = {10.1007/0-387-28356-0_3},
  abstract  = {Over the last 20 years, the combination of faster computers, more reliable data, and improved algorithms has resulted in the near-routine solution of many integer programs of practical interest. Integer programming models are used in a wide variety of applications, including scheduling, resource assignment, planning, supply chain design, auction design, and many, many others. In this tutorial, we outline some of the major themes involved in creating and solving integer programming models.},
  owner     = {andrea},
  timestamp = {2015.04.24},
}

@InProceedings{Boukedjar2012,
  author    = {Abdelamine Boukedjar and Mohammed Esseghir Lalami and Didier El-Baz},
  title     = {Parallel Branch and Bound on a {CPU}--{GPU} System},
  booktitle = {{P}roceedings of the 20th {E}uromicro {I}nternational {C}onference on {P}arallel, {D}istributed and {N}etwork-{B}ased {P}rocessing},
  date      = {2012},
  series    = {PDP '12},
  location  = {Garching, DE},
  month     = feb,
  pages     = {392--398},
  doi       = {10.1109/PDP.2012.23},
  abstract  = {Hybrid implementation via CUDA of a branch and bound method for knapsack problems is proposed. Branch and bound computations can be carried out either on the CPU or on the GPU according to the size of the branch and bound list, i.e. the number of nodes. Tests are carried out on a Tesla C2050 GPU. A first series of computational results showing a substantial speedup is displayed and analyzed.},
  issn      = {1066-6192},
  keywords  = {graphics processing units;knapsack problems;parallel architectures;tree searching;CPU-GPU system;CUDA;knapsack problems;parallel branch and bound;Computer architecture;Graphics processing unit;Instruction sets;Kernel;Optimization;Parallel algorithms;Upper bound;CUDA;branch and bound;combinatorial optimization;computing;hybrid computing;knapsack problems},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Article{Bouwmeester2015,
  author       = {Bouwmeester, H. and Dougherty, B. and Knyazev, A.},
  title        = {Nonsymmetric Preconditioning for Conjugate Gradient and Steepest Descent Methods},
  journaltitle = {Procedia Computer Science},
  date         = {2015},
  volume       = {51},
  pages        = {276--285},
  issn         = {1877-0509},
  doi          = {10.1016/j.procs.2015.05.241},
  abstract     = {We analyze a possibility of turning off post-smoothing (relaxation) in geometric multigrid when used as a preconditioner in preconditioned conjugate gradient (PCG) linear and eigenvalue solvers for the 3D Laplacian. The geometric Semicoarsening Multigrid (SMG) method is provided by the hypre parallel software package. We solve linear systems using two variants (standard and flexible) of PCG and preconditioned steepest descent (PSD) methods. The eigen-value problems are solved using the locally optimal block preconditioned conjugate gradient (LOBPCG) method available in hypre through BLOPEX software. We observe that turning off the post-smoothing in SMG dramatically slows down the standard PCG-SMG. For flexible PCG and LOBPCG, our numerical tests show that removing the post-smoothing results in overall 40--50 percent acceleration, due to the high costs of smoothing and relatively insignificant decrease in convergence speed. We demonstrate that PSD-SMG and flexible PCG-SMG converge similarly if SMG post-smoothing is off. A theoretical justification is provided.},
  keywords     = {linear equations},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@InProceedings{Boyer2013,
  author    = {Vincent Boyer and El Baz, Didier},
  title     = {Recent Advances on {GPU} Computing in Operations Research},
  booktitle = {{P}roceedings of the 27th {IEEE} {I}nternational {S}ymposium on {P}arallel \& {D}istributed {P}rocessing {W}orkshops and {P}h{D} {F}orum},
  date      = {2013},
  series    = {IPDPSW '13},
  publisher = {IEEE Computer Society},
  location  = {Boston, MA, USA},
  month     = may,
  pages     = {1778--1787},
  doi       = {10.1109/IPDPSW.2013.45},
  abstract  = {In the last decade, Graphics Processing Units(GPUs) have gained an increasing popularity as accelerators for High Performance Computing (HPC) applications. Recent GPUs are not only powerful graphics engines but also highly threaded parallel computing processors that can achieve sustainable speedup as compared with CPUs. In this context, researchers try to exploit the capability of this architecture to solve difficult problems in many domains in science and engineering. In this article, we present recent advances on GPU Computing in Operations Research. We focus in particular on Integer Programming and Linear Programming.},
  address   = {Los Alamitos, CA, USA},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@TechReport{Brandes2016,
  Title                    = {The {LAMA} Approach for Writing Portable Applications on Heterogenous Architectures},
  Author                   = {Thomas Brandes and Eric Schricker and Thomas Soddemann},
  Institution              = {Fraunhofer Institute for Algorithms and Scientific Computing},

 abstract = {Ensuring longevity and maintainability of modern software applications is mandatory for a proper return on investment. Since the hardware landscape is changing rapidly and will continue to do so, it is imperative to take on those topics also in the HPC domain where applications traditionally have a long live-span. For recent years, we have observed a trend towards more and more heterogeneous systems. Realizing the performance promises of the hardware vendors is a huge challenge to the software developer. Portability is the second challenge to be met in this context. In this paper we present our library LAMA. We created this library to address both challenges successfully in the realm of linear algebra and numerical mathematics. We introduce our solutions to heterogeneous memory and kernel management as well as our solutions to task parallelism. In the end we do performance and scalability benchmarks drawing a comparison to PETSc for the example of a CG solver.},
  Date                     = {2016},
  Location                 = {Sankt Augustin, Germany,},
  Owner                    = {andrea},
  Timestamp                = {2017.05.09},
  Url                      = {http://www.libama.org/assets/lamawhitepaper.pdf}
}

@InCollection{Braun2001,
  author    = {Braun, Tracy D. and Siegel, Howard Jay and Maciejewski, Anthony A.},
  title     = {Heterogeneous Computing: Goals, Methods, and Open Problems},
  booktitle = {{H}igh {P}erformance {C}omputing ({HiPC} 2001)},
  date      = {2001},
  editor    = {Monien, Burkhard and Prasanna, Viktor K. and Vajapeyam, Sriram},
  language  = {English},
  volume    = {2228},
  series    = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  isbn      = {978-3-540-43009-4},
  pages     = {307--318},
  doi       = {10.1007/3-540-45307-5_27},
  abstract  = {This paper discusses the material tob e presented by H. J. Siegel in his keynote talk. Distributed high-performance heterogeneous computing (HC) environments are composed of machines with varied computational capabilities interconnected by high-speed links. These environments are well suited to meet the computational demands of large, diverse groups of applications. One key factor in achieving the best performance possible from HC environments is the ability to assign effectively the applications to machines and schedule their execution. Several factors must be considered during this assignment. A conceptual model for the automatic decomposition of an application into tasks and assignment of tasks to machines is presented. An example of a static matching and scheduling approach for an HC environment is summarized. Some examples of current HC technology and open research problems are discussed.},
  month     = dec,
  owner     = {andrea},
  timestamp = {2015.07.13},
}

@InProceedings{Buss2010,
  Title                    = {{STAPL}: Standard Template Adaptive Parallel Library},
  Author                   = {Buss, Antal and Harshvardhan and Papadopoulos, Ioannis and Pearce, Olga and Smith, Timmie and Tanase, Gabriel and Thomas, Nathan and Xu, Xiabing and Bianco, Mauro and Amato, Nancy M. and Rauchwerger, Lawrence},
  Booktitle                = {{P}roceedings of the 3rd {A}nnual {H}aifa {E}xperimental {S}ystems {C}onference},

  Address                  = {New York, NY, USA},
  Pages                    = {14:1--14:10},
  Publisher                = {ACM},
  Series                   = {SYSTOR '10},

 abstract = {The Standard Template Adaptive Parallel Library (stapl) is a high-productivity parallel programming framework that extends C++ and stl with unified support for shared and distributed memory parallelism. stapl provides distributed data structures (pContainers) and parallel algorithms (pAlgorithms) and a generic methodology for extending them to provide customized functionality. The stapl runtime system provides the abstraction for communication and program execution. In this paper, we describe the major components of stapl and present performance results for both algorithms and data structures showing scalability up to tens of thousands of processors.},
  Acmid                    = {1815713},
  Articleno                = {14},
  Date                     = {2010},
  Doi                      = {10.1145/1815695.1815713},
  ISBN                     = {978-1-60558-908-4},
  Keywords                 = {high productivity parallel programming, library, parallel data structures},
  Location                 = {Haifa, IL},
  Numpages                 = {10}
}

@Article{Buttari2009,
  author       = {Buttari, A. and Langou, J. and Kurzak, J. and Dongarra, J.},
  title        = {A class of parallel tiled linear algebra algorithms for multicore architectures},
  journaltitle = {Parallel Computing},
  date         = {2009},
  volume       = {35},
  number       = {1},
  pages        = {38--53},
  issn         = {0167-8191},
  doi          = {10.1016/j.parco.2008.10.002},
  abstract     = {As multicore systems continue to gain ground in the high performance computing world, linear algebra algorithms have to be reformulated or new algorithms have to be developed in order to take advantage of the architectural features on these new processors. Fine grain parallelism becomes a major requirement and introduces the necessity of loose synchronization in the parallel execution of an operation. This paper presents algorithms for the Cholesky, LU and QR factorization where the operations can be represented as a sequence of small tasks that operate on square blocks of data. These tasks can be dynamically scheduled for execution based on the dependencies among them and on the availability of computational resources. This may result in out of order execution of tasks which will completely hide the presence of intrinsically sequential tasks in the factorization. Performance comparisons are presented with LAPACK algorithms where parallelism can only be exploited at the level of the BLAS operations and vendor implementations.},
  keywords     = {Linear algebra},
  owner        = {ap8213},
  timestamp    = {2014.10.09},
}

@Article{Cafieri2007,
  Title                    = {On the iterative solution of {KKT} systems in potential reduction software for large-scale quadratic problems},
  Author                   = {Cafieri, S. and D'Apuzzo, M. and De Simone, V. and di Serafino, D.},
  Number                   = {1},
  Pages                    = {27--45},
  Volume                   = {38},

 abstract = {Iterative solvers appear to be very promising in the development of efficient software, based on Interior Point methods, for large-scale nonlinear optimization problems. In this paper we focus on the use of preconditioned iterative techniques to solve the KKT system arising at each iteration of a Potential Reduction method for convex Quadratic Programming. We consider the augmented system approach and analyze the behaviour of the Constraint Preconditioner with the Conjugate Gradient algorithm. Comparisons with a direct solution of the augmented system and with MOSEK show the effectiveness of the iterative approach on large-scale sparse problems.},
  Date                     = {2007},
  Doi                      = {10.1007/s10589-007-9035-y},
  ISSN                     = {1573-2894},
  Journaltitle             = {Computational Optimization and Applications},
  Owner                    = {andrea},
  Timestamp                = {2016.05.27}
}

@Article{Calgaro2010,
  Title                    = {Incremental incomplete {LU} factorizations with applications},
  Author                   = {Calgaro, Caterina and Chehab, Jean-Paul and Saad, Yousef},
  Number                   = {5},
  Pages                    = {811--837},
  Volume                   = {17},

 abstract = {This paper addresses the problem of computing preconditioners for solving linear systems of equations with a sequence of slowly varying matrices. This problem arises in many important applications. For example, a common situation in computational fluid dynamics, is when the equations change only slightly, possibly in some parts of the physical domain. In such situations it is wasteful to recompute entirely any LU or ILU factorizations computed for the previous coefficient matrix. A number of techniques for computing incremental ILU factorizations are examined. For example we consider methods based on approximate inverses as well as alternating techniques for updating the factors L and U of the factorization.},
  Date                     = {2010},
  Doi                      = {10.1002/nla.756},
  ISSN                     = {1099--1506},
  Journaltitle             = {Numerical Linear Algebra with Applications},
  Publisher                = {John Wiley \& Sons, Ltd.}
}

@InProceedings{Candel2015,
  Title                    = {Accurately modeling the {GPU} memory subsystem},
  Author                   = {F. Candel and S. Petit and J. Sahuquillo and J. Duato},
  Booktitle                = {{P}roceedings of the 2015 {I}nternational {C}onference on {H}igh {P}erformance {C}omputing {S}imulation},
  Month                    = jul,
  Pages                    = {179--186},
  Series                   = {HPCS '15},

 abstract = {Nowadays, research on GPU processor architecture is extraordinarily active since these architectures offer much more performance per watt than CPU architectures. This is the main reason why massive deployment of GPU multiprocessors is considered one of the most feasible solutions to attain exascale computing capabilities. In this context, ongoing GPU architecture research is required to improve GPU programmability as well as to integrate CPU and GPU cores in the same die. One of the most important research topics in current GPUs, is the GPU memory hierarchy, since its design goals are very different from those of conventional CPU memory hierarchies. To explore novel designs to better support General Purpose computing in GPUs (GPGPU computing) as well as to improve the performance of GPU and CPU/GPU systems, researchers often require advanced microarchitectural simulators with detailed models of the memory subsystem. Nevertheless, due to fast speed at which current GPU architectures evolve, simulation accuracy of existing state-of-the-art simulators suffers. This paper focuses on accurately modeling the GPU memory subsystem. We identified three main aspects that should be modeled with more accuracy: i) miss status holding registers, ii) coalescing vector memory requests, and iii) non-blocking GPU stores. In this sense, we extend the Multi2Sim heterogeneous CPU/GPU processor simulator to model these aspects with enough accuracy. Experimental results show that if these aspects are not considered in the simulation framework, performance deviations can rise in some applications up to 70\%, 75\%, and 60\%, respectively.},
  Date                     = {2015},
  Doi                      = {10.1109/HPCSim.2015.7237038},
  Keywords                 = {graphics processing units;memory architecture;multiprocessing systems;CPU memory hierarchies;GPGPU computing;GPU cores;GPU memory hierarchy;GPU memory subsystem modeling;GPU multiprocessors;GPU processor architecture;GPU programmability;Multi2Sim heterogeneous CPU-GPU processor simulator;advanced microarchitectural simulators;coalescing vector memory requests;exascale computing capabilities;general purpose computing;miss status holding registers;nonblocking GPU stores;Computational modeling;Computer architecture;Graphics processing units;Load modeling},
  Location                 = {Amsterdam, NL}
}

@Article{Candel2017,
  Title                    = {Accurately modeling the on-chip and off-chip {GPU} memory subsystem},
  Author                   = {Francisco Candel and Salvador Petit and Julio Sahuquillo and  Duato},

 abstract = {Research on GPU architecture is becoming pervasive in both the academia and the industry because these architectures offer much more performance per watt than typical CPU architectures. This is the main reason why massive deployment of GPU multiprocessors is considered one of the most feasible solutions to attain exascale computing capabilities. \\The memory hierarchy of the GPU is a critical research topic, since its design goals widely differ from those of conventional CPU memory hierarchies. Researchers typically use detailed microarchitectural simulators to explore novel designs to better support GPGPU computing as well as to improve the performance of GPU and CPU-GPU systems. In this context, the memory hierarchy is a critical and continuously evolving subsystem. \\Unfortunately, the fast evolution of current memory subsystems deteriorates the accuracy of existing state-of-the-art simulators. This paper focuses on accurately modeling the entire (both on-chip and off-chip) GPU memory subsystem. For this purpose, we identify four main memory related components that impact on the overall performance accuracy. Three of them belong to the on-chip memory hierarchy: (i) memory request coalescing mechanisms, (ii) miss status holding registers, and (iii) cache coherence protocol; while the fourth component refers to the memory controller and GDDR memory working activity. \\To evaluate and quantify our claims, we accurately modeled the aforementioned memory components in an extended version of the state-of-the-art Multi2Sim heterogeneous CPU-GPU processor simulator. Experimental results show important deviations, which can vary the final system performance provided by the simulation framework up to a factor of three. The proposed GPU model has been compared and validated against the original framework and the results from a real AMD Southern-Islands 7870HD GPU.},
  Date                     = {2017},
  Doi                      = {10.1016/j.future.2017.02.012},
  ISSN                     = {0167-739X},
  Journaltitle             = {Future Generation Computer Systems},
  Keywords                 = {Applied modeling and simulation}
}

@InProceedings{Carneiro2011,
  author     = {Tiago Carneiro and Albert Einstein Muritiba and Marcos Negreiros and Gustavo Augusto Lima de Campos},
  title      = {A New Parallel Schema for Branch-and-Bound Algorithms Using {GPGPU}},
  booktitle  = {{P}roceedings of the 23rd {I}nternational {S}ymposium on {C}omputer {A}rchitecture and {H}igh {P}erformance {C}omputing},
  date       = {2011},
  series     = {SBAC-PAD '11},
  location   = {Vitória, Espírito Santo, BR},
  month      = oct,
  pages      = {41--47},
  doi        = {10.1109/SBAC-PAD.2011.20},
  abstract   = {This work presents a new parallel procedure designed to process combinatorial B\&B algorithms using GPGPU. In our schema we dispatch a number of threads that treats intelligently the massively parallel processors of NVIDIA GeForce graphical units. The strategy is to build sequentially a series of initial searches that can map a subspace of the B\&B tree by starting a number of limited threads after achieving a specific level of the tree. The search is then processed massively by DFS. The whole subspace is optimized accordingly to memory and limits of threads and blocks available by the GPU. We compare our results with its OpenMP and Serial versions of the same search schema using explicitly enumeration (all possible solutions) to the Asymmetrical Travelling Salesman Problem's instances. We also show the great superiority of our GPGPU based method.},
  annotation = {{T}he implementation used {CUDA}. {I}t's the depth first search ({DFS}). {S}earch starts after 2 levels of branching. {E}ach thread solves a problem. {E}ach {DFS} generates only one node at the time and if this is pruned, the search goes back to the parent. {E}ach active node is processed by a {GPU} thread. {A}t the end of its processing, it is synchronized with the other threads. {W}hen a node doesn't find a solution, it returns its parent, else it returns the value of the solution. {T}hus, each node is a {DFS} root. {T}he work is tested on randomly generated instances of the asymmetric travelling salesman problem ($c_{ij} \neq c_{ij}$). {T}he solution is found by complete enumeration of all solutions $({N}-1)!$ where ${N}$ is the number of cities. {R}esults are compared against an {O}pen{MP} version of the algorithm. {T}he test environment is an {I}ntel {C}ore i5 750 (2.66 {GH}z, 3.2 {GH}z over demand, 4 {GB} {RAM}), an {U}buntu},
  file       = {:home/ap8213/Documents/PhD/Papers/Carneiro et al. - A new parallel schema for branch-and-bound algorithms using GPGPU.pdf:PDF},
  issn       = {1550-6533},
  owner      = {ap8213},
  timestamp  = {2014.10.09},
}

@InProceedings{Chakroun2012,
  author    = {I. Chakroun and N. Melab},
  title     = {An Adaptive Multi-{GPU} based Branch-and-Bound. A Case Study: the Flow-Shop Scheduling Problem},
  booktitle = {{P}roceedings of the 14th {IEEE} {I}nternational {C}onference on {H}igh {P}erformance {C}omputing and {C}ommunications},
  date      = {2012},
  series    = {HPCC '12},
  location  = {Liverpool, UK},
  month     = jun,
  pages     = {389--395},
  doi       = {10.1109/HPCC.2012.59},
  abstract  = {Solving exactly Combinatorial Optimization Problems (COPs) using a Branch-and-Bound (B\&B) algorithm requires a huge amount of computational resources. Therefore, we recently investigated designing B\&B algorithms on top of graphics processing units (GPUs) using a parallel bounding model. The proposed model assumes parallelizing the evaluation of the lower bounds on pools of sub-problems. The results demonstrated that the size of the evaluated pool has a significant impact on the performance of B\&B and that it depends strongly on the problem instance being solved. In this paper, we design an adaptative parallel B\&B algorithm for solving permutation-based combinatorial optimization problems such as FSP (Flow-shop Scheduling Problem) on GPU accelerators. To do so, we propose a dynamic heuristic for parameter auto-tuning at runtime. Another challenge of this pioneering work is to exploit larger degrees of parallelism by using the combined computational power of multiple GPU devices. The approach has been applied to the permutation flow-shop problem. Extensive experiments have been carried out on well-known FSP benchmarks using an Nvidia Tesla S1070 Computing System equipped with two Tesla T10 GPUs. Compared to a CPU-based execution, accelerations up to 105 are achieved for large problem instances.},
  owner     = {andrea},
  timestamp = {2014.12.11},
}

@Article{Chakroun2013,
  author       = {I. Chakroun and N. Melab and M. Mezmaz and D. Tuyttens},
  title        = {Combining multi-core and {GPU} computing for solving combinatorial optimization problems},
  journaltitle = {Journal of Parallel and Distributed computing},
  date         = {2013},
  volume       = {73},
  number       = {12},
  month        = dec,
  pages        = {1563--1577},
  issn         = {0743-7315},
  doi          = {10.1016/j.jpdc.2013.07.023},
  abstract     = {In this paper, we revisit the design and implementation of Branch-and-Bound (B\&B) algorithms for solving large combinatorial optimization problems on GPU-enhanced multi-core machines. B\&B is a tree-based optimization method that uses four operators (selection, branching, bounding and pruning) to build and explore a highly irregular tree representing the solution space. In our previous works, we have proposed a GPU-accelerated approach in which only a single CPU core is used and only the bounding operator is performed on the GPU device. Here, we extend the approach (LL-GB\&B) in order to minimize the CPU-GPU communication latency and thread divergence. Such an objective is achieved through a GPU-based fine-grained parallelization of the branching and pruning operators in addition to the bounding one. The second contribution consists in investigating the combination of a GPU with multi-core processing. Two scenarios have been explored leading to two approaches: a concurrent (RLL-GB\&B) and a cooperative one (PLL-GB\&B). In the first one, the exploration process is performed concurrently by the GPU and the CPU cores. In the cooperative approach, the CPU cores prepare and off-load to GPU pools of tree nodes using data streaming while the GPU performs the exploration. The different approaches have been extensively experimented on the Flowshop scheduling problem. Compared to a single CPU-based execution, LL-GB\&B allows accelerations up to ($\times$160) for large problem instances. Moreover, when combining multi-core and GPU, we figure out that using RLL-GB\&B is not beneficial while PLL-GB\&B enables an improvement up to 36\% compared to LL-GB\&B.},
  acmid        = {2537492},
  issue_date   = {December, 2013},
  keywords     = {Flowshop scheduling problem, GPU accelerators, Multi-core computing, Parallel branch-and-bound},
  location     = {Orlando, FL, USA},
  numpages     = {15},
  owner        = {ap8213},
  publisher    = {Academic Press, Inc.},
  timestamp    = {2014.10.09},
}

@Article{Chakroun2012a,
  author       = {I. Chakroun and M. Mezmaz and N. Melab and A. Bendjoudi},
  title        = {Reducing thread divergence in a {GPU}-accelerated branch-and-bound algorithm},
  journaltitle = {Concurrency and Computation: Practice and Experience},
  date         = {2012},
  volume       = {25},
  number       = {8},
  month        = sep,
  pages        = {1121--1136},
  doi          = {10.1002/cpe.2931},
  abstract     = {In this paper, we address the design and implementation of graphical processing unit (GPU)-accelerated branch-and-bound algorithms (B\&B) for solving flow-shop scheduling optimization problems (FSP). Such applications are CPU-time consuming and highly irregular. On the other hand, GPUs are massively multithreaded accelerators using the single instruction multiple data model at execution. A major issue that arises when executing on GPU, a B\&B applied to FSP is thread or branch divergence. Such divergence is caused by the lower bound function of FSP that contains many irregular loops and conditional instructions. Our challenge is therefore to revisit the design and implementation of B\&B applied to FSP dealing with thread divergence. Extensive experiments of the proposed approach have been carried out on well-known FSP benchmarks using an Nvidia Tesla (C2050 GPU card). Compared with a CPU-based execution, accelerations up to $\times$ 77.46 are achieved for large problem instances.},
  owner        = {andrea},
  timestamp    = {2014.12.11},
}

@InProceedings{Che2013,
  author    = {Shuai Che and Bradford M. Beckmann and Steven K. Reinhardt and Kevin Skadron},
  title     = {Pannotia: Understanding Irregular {GPGPU} Graph Applications},
  booktitle = {{P}roceedings of the {IEEE} {I}nternational {S}ymposium on {W}orkload {C}haracterization},
  date      = {2013},
  series    = {IISWC '13},
  location  = {Portland, OR, USA},
  month     = sep,
  pages     = {185--195},
  doi       = {10.1109/IISWC.2013.6704684},
  abstract  = {GPUs have become popular recently to accelerate general-purpose data-parallel applications. However, most existing work has focused on GPU-friendly applications with regular data structures and access patterns. While a few prior studies have shown that some irregular workloads can also achieve speedups on GPUs, this domain has not been investigated thoroughly. Graph applications are one such set of irregular workloads, used in many commercial and scientific domains. In particular, graph mining -as well as web and social network analysis- are promising applications that GPUs could accelerate. However, implementing and optimizing these graph algorithms on SIMD architectures is challenging because their data-dependent behavior results in significant branch and memory divergence. To address these concerns and facilitate research in this area, this paper presents and characterizes a suite of GPGPU graph applications, Pannotia, which is implemented in OpenCL and contains problems from diverse and important graph application domains. We perform a first-step characterization and analysis of these benchmarks and study their behavior on real hardware. We also use clustering analysis to illustrate the similarities and differences of the applications in the suite. Finally, we make architectural and scheduling suggestions that will improve their execution efficiency on GPUs.},
  keywords  = {data mining;data structures;graph theory;graphics processing units;parallel processing;pattern clustering;scheduling;GPU-friendly applications;OpenCL;Pannotia;SIMD architectures;Web analysis;access patterns;branch and memory divergence;clustering analysis;commercial domains;data structures;data-dependent behavior;general-purpose data-parallel applications;graph algorithms;graph mining;irregular GPGPU graph applications;scientific domains;social network analysis;Kernel;Labeling;Radiation detectors},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Online{Chen2016,
  author    = {Zhangxin Chen and Hui Liu and Bo Yang},
  title     = {Parallel Triangular Solvers on {GPU}},
  date      = {2016},
  abstract  = {In this paper, we investigate GPU based parallel triangular solvers systematically. The parallel triangular solvers are fundamental to incomplete LU factorization family preconditioners and algebraic multigrid solvers. We develop a new matrix format suitable for GPU devices. Parallel lower triangular solvers and upper triangular solvers are developed for this new data structure. With these solvers, ILU preconditioners and domain decomposition preconditioners are developed. Numerical results show that we can speed triangular solvers around seven times faster.},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl    = {http://dblp2.uni-trier.de/rec/bib/journals/corr/ChenLY16},
  eprint    = {arXiv:1606.00541},
  timestamp = {Fri, 01 Jul 2016 17:39:49 +0200},
  volume    = {abs/1606.00541},
}

@PhdThesis{Choi2006,
  author      = {Choi, S.C.},
  title       = {Iterative methods for singular linear equations and least-square problems},
  institution = {Stanford University},
  date        = {2006},
  url         = {https://web.stanford.edu/group/SOL/dissertations/sou-cheng-choi-thesis.pdf},
  abstract    = {CG, MINRES, and SYMMLQ are Krylov subspace methods for solving large symmetric systems of linear equations. CG (the conjugate-gradient method) is reliable on positive-definite systems, while MINRES and SYMMLQ are designed for indefinite systems. When these methods are applied to an inconsistent system (that is, a singular symmetric least-squares problem), CG could break down and SYMMLQ's solution could explode, while MINRES would give a least-squares solution but not necessarily the minimum-length solution (often called the pseudoinverse solution). This understanding motivates us to design a MINRES-like algorithm to compute minimum-length solutions to singular symmetric systems. \\MINRES uses QR factors of the tridiagonal matrix from the Lanczos process (where R is upper-tridiagonal). Our algorithm uses a QLP decomposition (where rotations on the right reduce R to lower-tridiagonal form), and so we call it MINRES-QLP. On singular or nonsingular systems, MINRES-QLP can give more accurate solutions than MINRES or SYMMLQ. We derive preconditioned MINRES-QLP, new stopping rules, and better estimates of the solution and residual norms, the matrix norm and condition number. \\For a singular matrix of arbitrary shape, we observe that null vectors can be obtained by solving least-squares problems involving the transpose of the matrix. For sparse rectangular matrices, this suggests an application of the iterative solver LSQR. In the square case, MINRES, MINRES-QLP, or LSQR are applicable. Results are given for solving homogeneous systems, computing the stationary probability vector for Markov Chain models, and finding null vectors for sparse systems arising in helioseismology.},
  owner       = {ap8213},
  timestamp   = {2014.03.31},
}

@InProceedings{Choo2014,
  Title                    = {Understanding and Optimizing {GPU} Cache Memory Performance for Compute Workloads},
  Author                   = {Choo, Kyoshin and Panlener, William and Jang, Byunghyun},
  Booktitle                = {{P}roceedings of the 13th {IEEE} {I}nternational {S}ymposium on {P}arallel and {D}istributed {C}omputing},

  Address                  = {Washington, DC, USA},
  Pages                    = {189--196},
  Publisher                = {IEEE Computer Society},
  Series                   = {ISPDC '14},

 abstract = {Processing elements such as CPUs and GPUs depend on cache technology to bridge the classic processor memory subsystem performance gap. As GPUs evolve into general purpose co-processors with CPUs sharing the load, good cache design and use becomes increasingly important. While both CPUs and GPUs must cooperate and perform well, their memory access patterns are very different. On CPUs only a few threads access memory simultaneously. On GPUs, there is significantly higher memory access contention among thousands of threads. Despite such different behavior, there is little research that investigates the behavior and performance of GPU caches in depth. In this paper, we present our extensive study on the characterization and improvement of GPU cache behavior and performance for general-purpose workloads using a cycle-accurate ISA level GPU architectural simulator that models one of the latest GPU architectures, Graphics Core Next (GCN) from AMD. Our study makes the following observations and improvements. First, we observe that L1 vector data cache hit rate is substantially lower when compared to CPU caches. The main culprit is compulsory misses caused by lack of data reuse among massively simultaneous threads. Second, there is significant memory access contention in shared L2 data cache, accounting for up to 19\% of total access for some benchmarks. This high contention remains a main performance barrier in L2 data cache even though its hit rate is high. Third, we demonstrate that memory access coalescing plays a critical role in reducing memory traffic. Finally we found that there exists inter-workgroup locality which can affect the cache behavior and performance. Our experimental results show memory performance can be improved by 1) shared L1 vector data cache where multiple compute units share a single cache to exploit inter-workgroup locality and increase data reusability, and 2) clustered workgroup scheduling where workgroups with consecutive IDs are assigned on the same compute unit.},
  Acmid                    = {2673102},
  Date                     = {2014},
  Doi                      = {10.1109/ISPDC.2014.29},
  ISBN                     = {978-1-4799-5919-8},
  Location                 = {Lymassol, CY},
  Numpages                 = {8},
  Owner                    = {andrea},
  Timestamp                = {2017.05.10}
}

@InProceedings{Christen2009,
  Title                    = {Parallel data-locality aware stencil computations on modern micro-architectures},
  Author                   = {M. Christen and O. Schenk and E. Neufeld and P. Messmer and H. Burkhart},
  Booktitle                = {{P}roceedings of the 2009 {IEEE} {I}nternational {S}ymposium on {P}arallel {D}istributed {P}rocessing},
  Month                    = may,
  Pages                    = {1--10},
  Series                   = {IPDPS '09},

 abstract = {Novel micro-architectures including the Cell Broadband Engine Architecture and graphics processing units are attractive platforms for compute-intensive simulations. This paper focuses on stencil computations arising in the context of a biomedical simulation and presents performance benchmarks on both the Cell BE and GPUs and contrasts them with a benchmark on a traditional CPU system. Due to the low arithmetic intensity of stencil computations, typically only a fraction of the peak performance of the compute hardware is reached. An algorithm is presented, which reduces the bandwidth requirements and thereby improves performance by exploiting temporal locality of the data. We report on performance improvements over CPU implementations.},
  Date                     = {2009},
  Doi                      = {10.1109/IPDPS.2009.5161031},
  ISSN                     = {1530-2075},
  Keywords                 = {coprocessors;digital simulation;medical computing;multiprocessing systems;parallel processing;performance evaluation;Cell Broadband Engine Architecture;biomedical simulation;graphics processing units;modern microarchitectures;parallel data-locality;performance benchmarks;stencil computations;Arithmetic;Biomedical computing;Central Processing Unit;Computational modeling;Computer architecture;Concurrent computing;Context modeling;Engines;Graphics;Hardware},
  Location                 = {Rome, IT}
}

@InProceedings{Cong2008,
  Title                    = {Solving Large, Irregular Graph Problems Using Adaptive Work-Stealing},
  Author                   = {G. Cong and S. Kodali and S. Krishnamoorthy and D. Lea and V. Saraswat and T. Wen},
  Booktitle                = {{P}roceedings of the 37th {I}nternational {C}onference on {P}arallel {P}rocessing},
  Month                    = sep,
  Pages                    = {536--545},
  Series                   = {ICPP '08},

 abstract = {Solving large, irregular graph problems efficiently is challenging. Current software systems and commodity multiprocessors do not support fine-grained, irregular parallelism well. We present XWS, the X10 work stealing framework, an open-source runtime for the parallel programming language X10 and a library to be used directly by application writers. XWS extends the Cilk work-stealing framework with several features necessary to efficiently implement graph algorithms, viz., support for improperly nested procedures, global termination detection, and phased computation. We also present a strategy to adaptively control the granularity of parallel tasks in the work-stealing scheme, depending on the instantaneous size of the work queue. We compare the performance of the XWS implementations of spanning tree algorithms with that of the hand-written C and Cilk implementations using various graph inputs. We show that XWS programs (written in Java) scale and exhibit comparable or better performance.},
  Date                     = {2008},
  Doi                      = {10.1109/ICPP.2008.88},
  ISSN                     = {0190-3918},
  Location                 = {Portland, OR, USA}
}

@Article{Cope2010,
  author       = {Ben Cope and Peter Y. K. Cheung and Wayne Luk and Lee Howes},
  title        = {Performance Comparison of Graphics Processors to Reconfigurable Logic: A Case Study},
  journaltitle = {{IEEE} Transactions on Computers},
  date         = {2010},
  volume       = {59},
  number       = {4},
  month        = apr,
  pages        = {433--448},
  doi          = {10.1109/TC.2009.179},
  abstract     = {A systematic approach to the comparison of the graphics processor (GPU) and reconfigurable logic is defined in terms of three throughput drivers. The approach is applied to five case study algorithms, characterized by their arithmetic complexity, memory access requirements, and data dependence, and two target devices: the nVidia GeForce 7900 GTX GPU and a Xilinx Virtex-4 field programmable gate array (FPGA). Two orders of magnitude speedup, over a general-purpose processor, is observed for each device for arithmetic intensive algorithms. An FPGA is superior, over a GPU, for algorithms requiring large numbers of regular memory accesses, while the GPU is superior for algorithms with variable data reuse. In the presence of data dependence, the implementation of a customized data path in an FPGA exceeds GPU performance by up to eight times. The trends of the analysis to newer and future technologies are analyzed.},
  owner        = {andrea},
  timestamp    = {2014.12.16},
}

@InProceedings{Daga2015,
  author    = {Mayank Daga and Joseph L. Greathouse},
  title     = {Structural Agnostic {SpMV}: Adapting {CSR}-Adaptive for Irregular Matrices},
  booktitle = {{P}roceedings of the 22nd {IEEE} {I}nternational {C}onference on {H}igh {P}erformance {C}omputing},
  date      = {2015},
  series    = {HiPC '15},
  location  = {Bengaluru, IN},
  month     = dec,
  pages     = {64--74},
  doi       = {10.1109/HiPC.2015.55},
  abstract  = {Sparse matrix vector multiplication (SpMV) is an important linear algebra primitive. Recent research has focused on improving the performance of SpMV on GPUs when using compressed sparse row (CSR), the most frequently used matrix storage format on CPUs. Efficient CSR-based SpMV obviates the need for other GPU-specific storage formats, thereby saving runtime and storage overheads. However, existing CSR-based SpMV algorithms on GPUs perform poorly on irregular sparse matrices, limiting their usefulness. We propose a novel approach for SpMV on GPUs which works well for both regular and irregular matrices while keeping the CSR format intact. We start with CSR-Adaptive, which dynamically chooses between two SpMV algorithms depending on the length of each row. We then add a series of performance improvements, such as a more efficient reduction technique. Finally, we add a third algorithm which uses multiple parallel execution units when operating on irregular matrices with very long rows. Our implementation dynamically assigns the best algorithm to sets of rows in order to ensure that the GPU is efficiently utilized. We effectively double the performance of CSR-Adaptive, which had previously demonstrated better performance than algorithms that use other storage formats. In addition, our implementation is 36\% faster than CSR5, the current state of the art for SpMV on GPUs.},
  owner     = {andrea},
  timestamp = {2016.05.27},
}

@Article{Dantzig1949,
  author              = {Dantzig, G.B.},
  title               = {Programming of Interdependent Activities: {II} Mathematical Model},
  journaltitle        = {Econometrica},
  date                = {1949},
  language            = {English},
  volume              = {17},
  number              = {3/4},
  pages               = {200--211},
  issn                = {0012-9682},
  jstor_articletype   = {research-article},
  jstor_formatteddate = {Jul. - Oct., 1949},
  owner               = {ap8213},
  publisher           = {The Econometric Society},
  timestamp           = {2014.10.09},
}

@Book{Davis2006,
  author    = {Davis, Timothy A.},
  title     = {Direct Methods for Sparse Linear Systems},
  date      = {2006},
  volume    = {2},
  series    = {Fundamentals of Algorithms},
  publisher = {Society for Industrial and Applied Mathematics},
  location  = {Philadelphia, PA, USA},
  isbn      = {0898716136},
  owner     = {ap8213},
  timestamp = {2014.10.09},
}

@Article{Davis1997,
  author       = {Timothy A. Davis and Iain S. Duff},
  title        = {An Unsymmetric-Pattern Multifrontal Method for Sparse {LU} Factorization},
  journaltitle = {{SIAM} Journal on Matrix Analysis and Applications},
  date         = {1997},
  volume       = {18},
  number       = {1},
  pages        = {140--158},
  doi          = {10.1137/S0895479894246905},
  abstract     = {Sparse matrix factorization algorithms for general problems are typically characterized by irregular memory access patterns that limit their performance on parallel-vector supercomputers. For symmetric problems, methods such as the multifrontal method avoid indirect addressing in the innermost loops by using dense matrix kernels. However, no efficient LU factorization algorithm based primarily on dense matrix kernels exists for matrices whose pattern is very unsymmetric. We address this deficiency and present a new unsymmetric-pattern multifrontal method based on dense matrix kernels. As in the classical multifrontal method, advantage is taken of repetitive structure in the matrix by factorizing more than one pivot in each frontal matrix, thus enabling the use of Level 2 and Level 3 BLAS. The performance is compared with the classical multifrontal method and other unsymmetric solvers on a CRAY C-98.},
  owner        = {andrea},
  timestamp    = {2014.12.13},
}

@Article{Davis1999,
  author       = {Davis, Timothy A. and Duff, Iain S.},
  title        = {A Combined Unifrontal/Multifrontal Method for Unsymmetric Sparse Matrices},
  journaltitle = {{ACM} Transactions on Mathematical Software},
  date         = {1999},
  volume       = {25},
  number       = {1},
  month        = mar,
  pages        = {1--20},
  issn         = {0098-3500},
  doi          = {10.1145/305658.287640},
  abstract     = {We discuss the organization of frontal matrices in multifrontal methods for the solution of large sparse sets of unsymmetric linear equations. In the multifrontal method, work on a frontal matrix can be suspended, the frontal matrix can be stored for later reuse, and a new frontal matrix can be generated. There are thus several frontal matrices stored during the factorization, and one or more of these are assembled (summed) when creating a new frontal matrix. Although this means that arbitrary sparsity patterns can be handled efficiently, extra work is required to sum the frontal matrices together and can be costly because indirect addressing is requred. The (uni)frontal method avoids this extra work by factorizing the matrix with a single frontal matrix. Rows and columns are added to the frontal matrix, and pivot rows and columns are removed. Data movement is simpler, but higher fill-in can result if the matrix cannot be permuted into a variable-band form with small profile. We consider a combined unifrontal/multifrontal algorithm to enable general fill-in reduction orderings to be applied without the data movement of previous multifrontal approaches. We discuss this technique in the context of a code designed for the solution of sparse systems with unsymmetric pattern.},
  acmid        = {287640},
  issue_date   = {March 1999},
  keywords     = {frontal methods, linear equations, multifrontal methods, sparse unsymmetric matrices},
  location     = {New York, NY, USA},
  numpages     = {20},
  owner        = {andrea},
  publisher    = {ACM},
  timestamp    = {2017.05.08},
}

@Article{Davis2011,
  author       = {Davis, Timothy A. and Hu, Yifan},
  title        = {The {U}niversity of {F}lorida Sparse Matrix Collection},
  journaltitle = {{ACM} Transactions on Mathematical Software},
  date         = {2011},
  volume       = {38},
  number       = {1},
  month        = dec,
  pages        = {1--25},
  issn         = {0098-3500},
  doi          = {10.1145/2049662.2049663},
 abstract = {We describe the University of Florida Sparse Matrix Collection, a large and actively growing set of sparse matrices that arise in real applications. The Collection is widely used by the numerical linear algebra community for the development and performance evaluation of sparse matrix algorithms. It allows for robust and repeatable experiments: robust because performance results with artificially generated matrices can be misleading, and repeatable because matrices are curated and made publicly available in many formats. Its matrices cover a wide spectrum of domains, include those arising from problems with underlying 2D or 3D geometry (as structural engineering, computational fluid dynamics, model reduction, electromagnetics, semiconductor devices, thermodynamics, materials, acoustics, computer graphics/vision, robotics/kinematics, and other discretizations) and those that typically do not have such geometry (optimization, circuit simulation, economic and financial modeling, theoretical and quantum chemistry, chemical process simulation, mathematics and statistics, power networks, and other networks and graphs). We provide software for accessing and managing the Collection, from MATLAB, Mathematica, Fortran, and C, as well as an online search capability. Graph visualization of the matrices is provided, and a new multilevel coarsening scheme is proposed to facilitate this task.},
  acmid        = {2049663},
  articleno    = {1},
  issue_date   = {November 2011},
  keywords     = {Graph drawing, multilevel algorithms, performance evaluation, sparse matrices},
  location     = {New York, NY, USA},
  numpages     = {25},
  owner        = {andrea},
  publisher    = {ACM},
  timestamp    = {2015.09.07},
}

@Article{Davis2010,
  author       = {Davis, Timothy A. and Palamadai Natarajan, Ekanathan},
  title        = {Algorithm 907: {KLU}, A Direct Sparse Solver for Circuit Simulation Problems},
  journaltitle = {{ACM} Transactions on Mathematical Software},
  date         = {2010},
  volume       = {37},
  number       = {3},
  month        = sep,
  pages        = {1--17},
  issn         = {0098-3500},
  doi          = {10.1145/1824801.1824814},
 abstract = {KLU is a software package for solving sparse unsymmetric linear systems of equations that arise in circuit simulation applications. It relies on a permutation to Block Triangular Form (BTF), several methods for finding a fill-reducing ordering (variants of approximate minimum degree and nested dissection), and Gilbert/Peierls' sparse left-looking LU factorization algorithm to factorize each block. The package is written in C and includes a MATLAB interface. Performance results comparing KLU with SuperLU, Sparse 1.3, and UMFPACK on circuit simulation matrices are presented. KLU is the default sparse direct solver in the XyceTMcircuit simulation package developed by Sandia National Laboratories.},
  acmid        = {1824814},
  articleno    = {36},
  issue_date   = {September 2010},
  keywords     = {LU factorization, circuit simulation, sparse matrices},
  location     = {New York, NY, USA},
  numpages     = {17},
  owner        = {andrea},
  publisher    = {ACM},
  timestamp    = {2016.11.07},
}

@Article{Demidov2013,
  author       = {Denis Demidov and Karsten Ahnert and Karl Rupp and Peter Gottschling},
  title        = {Programming {CUDA} and {OpenCL}: A Case Study Using Modern {C++} Libraries},
  journaltitle = {{SIAM} {J}ournal on {S}cientific {C}omputing},
  date         = {2013},
  volume       = {35},
  number       = {5},
  pages        = {C453--C472},
  doi          = {10.1137/120903683},
 abstract = {We present a comparison of several modern C++ libraries providing high-level interfaces for programming multi- and many-core architectures on top of CUDA or OpenCL. The comparison focuses on the solution of ordinary differential equations (ODEs) and is based on odeint, a framework for the solution of systems of ODEs. Odeint is designed in a very flexible way and may be easily adapted for effective use of libraries such as MTL4, VexCL, or ViennaCL, using CUDA or OpenCL technologies. We found that CUDA and OpenCL work equally well for problems of large sizes, while OpenCL has higher overhead for smaller problems. Furthermore, we show that modern high-level libraries allow us to effectively use the computational resources of many-core GPUs or multicore CPUs without much knowledge of the underlying technologies.},
}

@InProceedings{Dieguez2015,
  author    = {Adrián Pérez Diéguez and Margarita Amor and Ramon Doallo},
  title     = {New Tridiagonal Systems Solvers on {GPU} Architectures},
  booktitle = {{P}roceedings of the 22nd {IEEE} {I}nternational {C}onference on {H}igh {P}erformance {C}omputing},
  date      = {2015},
  series    = {HiPC '15},
  location  = {Bengaluru, IN},
  month     = dec,
  pages     = {85--94},
  doi       = {10.1109/HiPC.2015.17},
  abstract  = {Modern GPUs (Graphics Processing Units) offer very high computing power at relatively low cost. Nevertheless, designing efficient algorithms for the GPUs usually requires additional time and effort, even for experienced programmers. On the other hand, tridiagonal systems solvers are an important building block for a wide range of applications. In this paper, we present a new tuning parallel proposal in order to generate new tridiagonal systems solvers. This proposal is based on the combination of a new reduction algorithm (Redundant Reduction-RR) with a tuning proposal to generate efficient parallel prefix algorithms on the GPU. Specifically, we present two new solvers combining RR with two GPU efficient parallel prefix patterns. The performance of the resulting proposals was analyzed using three different CUDA GPUs, obtaining an improvement of up to 20.5$\times$ over the CUSPARSE library and 28.9$\times$ over CUDPP.},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Article{Ding1999,
  author       = {Ding, Chen and Kennedy, Ken},
  title        = {Improving Cache Performance in Dynamic Applications Through Data and Computation Reorganization at Run Time},
  journaltitle = {{ACM} {SIGPLAN} Notices},
  date         = {1999},
  volume       = {34},
  number       = {5},
  month        = may,
  pages        = {229--241},
  issn         = {0362-1340},
  doi          = {10.1145/301631.301670},
 abstract = {With the rapid improvement of processor speed, performance of the memory hierarchy has become the principal bottleneck for most applications. A number of compiler transformations have been developed to improve data reuse in cache and registers, thus reducing the total number of direct memory accesses in a program. Until now, however, most data reuse transformations have been static---applied only at compile time. As a result, these transformations cannot be used to optimize irregular and dynamic applications, in which the data layout and data access patterns remain unknown until run time and may even change during the computation.In this paper, we explore ways to achieve better data reuse in irregular and dynamic applications by building on the inspector-executor method used by Saltz for run-time parallelization. In particular, we present and evaluate a dynamic approach for improving both computation and data locality in irregular programs. Our results demonstrate that run-time program transformations can substantially improve computation and data locality and, despite the complexity and cost involved, a compiler can automate such transformations, eliminating much of the associated run-time overhead.},
  acmid        = {301670},
  issue_date   = {May 1999},
  location     = {New York, NY, USA},
  numpages     = {13},
  publisher    = {ACM},
}

@Article{Doggett2012,
  author       = {M. Doggett},
  title        = {Texture Caches},
  journaltitle = {{IEEE} {M}icro},
  date         = {2012},
  volume       = {32},
  number       = {3},
  month        = may,
  pages        = {136--141},
  issn         = {0272-1732},
  doi          = {10.1109/MM.2012.44},
 abstract = {This column examines the texture cache, an essential component of modern GPUs that plays an important role in achieving real-time performance when generating realistic images. GPUs have many components and the texture cache is only one of them. But it has a real impact on the performance of the GPU if rasterization and memory tiling are set up correctly.},
  keywords     = {cache storage;graphics processing units;image texture;GPU;memory tiling;real-time performance;realistic images;texture caches;Cache memory;Computer graphics;Games;Graphics processing unit;Image processing;Real time systems;GPU;gaming;graphics;rasterization;texture cache},
}

@InProceedings{Domahidi2012,
  author    = {Alexander Domahidi and Aldo U Zgraggen and Melanie Nicole Zeilinger and Manfred Morari and Colin Jones},
  title     = {Efficient Interior Point Methods for Multistage Problems Arising in Receding Horizon Control},
  booktitle = {{P}roceedings of the 51st {IEEE} {C}onference on {D}ecision and {C}ontrol},
  date      = {2012},
  series    = {CDC '12},
  location  = {Maui, HI, USA},
  month     = dec,
  pages     = {668--674},
  doi       = {10.1109/CDC.2012.6426855},
  abstract  = {Receding horizon control requires the solution of an optimization problem at every sampling instant. We present efficient interior point methods tailored to convex multistage problems, a problem class which most relevant MPC problems with linear dynamics can be cast in, and specify important algorithmic details required for a high speed implementation with superior numerical stability. In particular, the presented approach allows for quadratic constraints, which is not supported by existing fast MPC solvers. A categorization of widely used MPC problem formulations into classes of different complexity is given, and we show how the computational burden of certain quadratic or linear constraints can be decreased by a low rank matrix forward substitution scheme. Implementation details are provided that are crucial to obtain high speed solvers. We present extensive numerical studies for the proposed methods and compare our solver to three well-known solver packages, outperforming the fastest of these by a factor 2-5 in speed and 3-70 in code size. Moreover, our solver is shown to be very efficient for large problem sizes and for quadratically constrained QPs, extending the set of systems amenable to advanced MPC formulations on low-cost embedded hardware.},
  address   = {Maui, HI, USA},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Book{Dongarra1998,
  Title                    = {Numerical Linear Algebra for High-Performance Computers},
  Author                   = {Dongarra, J. and Duff, I. and Sorensen, D. and van der Vorst, H.},
  Publisher                = {Society for Industrial and Applied Mathematics},

  Date                     = {1998},
  Doi                      = {10.1137/1.9780898719611},
  Eprint                   = {http://epubs.siam.org/doi/pdf/10.1137/1.9780898719611},
  Owner                    = {andrea},
  Timestamp                = {2016.09.07}
}

@Manual{Eaton2015,
  Title                    = {{GNU} Octave version 4.0.0 manual: a high-level interactive language for numerical computations},
  Author                   = {John W. Eaton and David Bateman and Søren Hauberg and Rik Wehbring},
  Note                     = {Accessed 20 July 2016},

  Date                     = {2015},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07},
  Url                      = {http://www.gnu.org/software/octave/doc/interpreter}
}

@Article{Ehrenberg2015,
  author       = {Nils Ehrenberg},
  title        = {Heading for Urban Energy Internets},
  journaltitle = {Pictures of the Future},
  date         = {2015},
  month        = jun,
  note         = {Accessed online on September 28th, 2015},
  url          = {http://www.siemens.com/innovation/en/home/pictures-of-the-future/infrastructure-and-finance/smart-cities-smart-buildings.html},
  howpublished = {Online},
  owner        = {andrea},
  timestamp    = {2015.09.28},
}

@InProceedings{Elteir2011,
  author    = {Marwa Elteir and Heshan Lin and Wu-chun Feng},
  title     = {Performance Characterization and Optimization of Atomic Operations on {AMD} {GPU}s},
  booktitle = {{P}roceedings of the 2011 {IEEE} {I}nternational {C}onference on {C}luster {C}omputing},
  date      = {2011},
  series    = {CLUSTER '11},
  location  = {Austin, TX, US},
  month     = sep,
  pages     = {234--243},
  doi       = {10.1109/CLUSTER.2011.34},
  abstract  = {Atomic operations are important building blocks in supporting general-purpose computing on graphics processing units (GPUs). For instance, they can be used to coordinate execution between concurrent threads, and in turn, assist in constructing complex data structures such as hash tables or implementing GPU-wide barrier synchronization. While the performance of atomic operations has improved substantially on the latest NVIDIA Fermi-based GPUs, system-provided atomic operations still incur significant performance penalties on AMD GPUs. A memory-bound kernel on an AMD GPU, for example, can suffer severe performance degradation when including an atomic operation, even if the atomic operation is never executed. In this paper, we first quantify the performance impact of atomic instructions to application kernels on AMD GPUs. We then propose a novel software-based implementation of atomic operations that can significantly improve the overall kernel performance. We evaluate its performance against the system-provided atomic using two micro-benchmarks and four real applications. The results show that using our software based atomic operations on an AMD GPU can speedup an application kernel by 67-fold over the same application kernel but with the (default) system-provided atomic operations.},
  keywords  = {coprocessors;data structures;synchronisation;AMD GPU;GPU-wide barrier synchronization;NVIDIA Fermi-based GPU;application kernels;atomic instructions;complex data structure construction;concurrent threads;four real applications;general-purpose computing;graphics processing units;hash tables;kernel performance;memory-bound kernel;micro-benchmarks;optimization;performance characterization;performance degradation;software based atomic operations;software-based implementation;system-provided atomic operations;Arrays;Graphics processing unit;High definition video;Instruction sets;Kernel;Synchronization;GPGPU;GPU;MapReduce;atomic operations;heterogeneous computing},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@TechReport{Feldman2015,
  Title                    = {Accelerated computing: a tipping point for {HPC}},
  Author                   = {Michael Feldman and Addison Snell},
  Institution              = {Intersect360 Research},
  Month                    = nov,
  Note                     = {Accessed 21 July 2016},

  Date                     = {2015},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07},
  Url                      = {http://images.nvidia.com/content/pdf/tesla/accelerated-computing-at-a-tipping-point.pdf}
}

@Article{Filippone2017,
  author       = {Filippone, Salvatore and Cardellini, Valeria and Barbieri, Davide and Fanfarillo, Alessandro},
  title        = {Sparse Matrix-Vector Multiplication on {GPGPUs}},
  journaltitle = {{ACM} Transactions on Mathematical Software},
  date         = {2017},
  volume       = {43},
  number       = {4},
  month        = jan,
  pages        = {30:1--30:49},
  issn         = {0098-3500},
  doi          = {10.1145/3017994},
 abstract = {The multiplication of a sparse matrix by a dense vector (SpMV) is a centerpiece of scientific computing applications: it is the essential kernel for the solution of sparse linear systems and sparse eigenvalue problems by iterative methods. The efficient implementation of the sparse matrix-vector multiplication is therefore crucial and has been the subject of an immense amount of research, with interest renewed with every major new trend in high-performance computing architectures. The introduction of General-Purpose Graphics Processing Units (GPGPUs) is no exception, and many articles have been devoted to this problem. \\With this article, we provide a review of the techniques for implementing the SpMV kernel on GPGPUs that have appeared in the literature of the last few years. We discuss the issues and tradeoffs that have been encountered by the various researchers, and a list of solutions, organized in categories according to common features. We also provide a performance comparison across different GPGPU models and on a set of test matrices coming from various application domains.},
  acmid        = {3017994},
  articleno    = {30},
  issue_date   = {March 2017},
  keywords     = {GPU programming, Sparse matrices},
  location     = {New York, NY, USA},
  numpages     = {49},
  publisher    = {ACM},
}

@Article{Flynn1972,
  Title                    = {Some Computer Organizations and Their Effectiveness},
  Author                   = {Flynn, Michael J.},

  Month                    = sep,
  Number                   = {9},
  Pages                    = {948--960},
  Volume                   = {C-21},

  Date                     = {1972},
  Doi                      = {10.1109/TC.1972.5009071},
  ISSN                     = {0018-9340},
  Journaltitle             = {{IEEE} Transactions on Computers},
  Keywords                 = {Automata;Computer aided instruction;Concurrent computing;Parallel processing;Performance evaluation;Time sharing computer systems;Transmission electron microscopy;Computer organization;instruction stream;overlapped;parallel processors;resource hierarchy},
  Owner                    = {andrea},
  Timestamp                = {2016.09.07}
}

@Manual{Forrest2004,
  author       = {John Forrest and David de la Nuez and Robin Lougee-Heimer},
  title        = {{CLP} User Guide},
  date         = {2004},
  organization = {IBM Research},
  url          = {http://www.coin-or.org/Clp/userguide/index.html},
  owner        = {andrea},
  timestamp    = {2014.12.14},
}

@Article{Forrest1972,
  Title                    = {Updated triangular factors of the basis to maintain sparsity in the product form simplex method},
  Author                   = {Forrest, J. J. H. and Tomlin, J. A.},
  Number                   = {1},
  Pages                    = {263--278},
  Volume                   = {2},

  Date                     = {1972},
  Doi                      = {10.1007/BF01584548},
  ISSN                     = {1436-4646},
  Journaltitle             = {Mathematical Programming}
}

@InProceedings{Fraguela1998,
  Title                    = {Modeling Set Associative Caches Behavior for Irregular Computations},
  Author                   = {Fraguela, Basilio B. and Ramón Doallo and Zapata, Emilio L.},
  Booktitle                = {{P}roceedings of the 1998 {ACM SIGMETRICS} {J}oint {I}nternational {C}onference on {M}easurement and {M}odeling of {C}omputer {S}ystems},

  Address                  = {New York, NY, USA},
  Pages                    = {192--201},
  Publisher                = {ACM},
  Series                   = {SIGMETRICS '98/PERFORMANCE '98},

 abstract = {While much work has been devoted to the study of cache behavior during the execution of codes with regular access patterns, little attention has been paid to irregular codes. An important portion of these codes are scientific applications that handle compressed sparse matrices. In this work a probabilistic model for the prediction of the number of misses on a K-way associative cache memory considering sparse matrices with a uniform or banded distribution is presented. Two different irregular kernels are considered: the sparse matrix-vector product and the transposition of a sparse matrix. The model was validated with simulations on synthetic uniform matrices and banded matrices from the Harwell-Boeing collection.},
  Acmid                    = {277910},
  Date                     = {1998},
  Doi                      = {10.1145/277851.277910},
  ISBN                     = {0-89791-982-3},
  Location                 = {Madison, Wisconsin, USA},
  Numpages                 = {10},
  Owner                    = {andrea},
  Timestamp                = {2017.05.09}
}

@InProceedings{Gabriel2004,
  author    = {Edgar Gabriel and Graham E. Fagg and George Bosilca and Thara Angskun and Jack J. Dongarra and Jeffrey M. Squyres and Vishal Sahay and Prabhanjan Kambadur and Brian Barrett and Andrew Lumsdaine and Ralph H. Castain and David J. Daniel and Richard L. Graham and Timothy S. Woodall},
  title     = {Open {MPI}: Goals, Concept, and Design of a Next Generation {MPI} Implementation},
  booktitle = {{P}roceedings of the 11th {E}uropean {PVM/MPI} {U}sers' {G}roup {M}eeting},
  date      = {2004},
  location  = {Budapest, HUN},
  month     = sep,
  pages     = {97--104},
}

@Manual{Galassi2016,
  Title                    = {{GNU} Scientific Library},
  Author                   = {Galassi, Mark and Davies, Jim and Theiler, James and Gough, Brian and Jungman, Gerard and Alken, Patrick and Booth, Michael and Rossi, Fabrice and Ulerich, Rhys},
  Edition                  = {2.3 for {GSL} vesion 2.3},

  Date                     = {2016},
  Keywords                 = {dblp},
  Timestamp                = {2011-07-02T11:38:40.000+0200},
  Url                      = {https://www.gnu.org/software/gsl/manual/gsl-ref.pdf}
}

@Article{Gamrath2015,
  Title                    = {Progress in presolving for mixed integer programming},
  Author                   = {Gamrath, Gerald and Koch, Thorsten and Martin, Alexander and Miltenberger, Matthias and Weninger, Dieter},
  Number                   = {4},
  Pages                    = {367--398},
  Volume                   = {7},

 abstract = {This paper describes three presolving techniques for solving mixed integer programming problems (MIPs) that were implemented in the academic MIP solver SCIP. The task of presolving is to reduce the problem size and strengthen the formulation, mainly by eliminating redundant information and exploiting problem structures. The first method fixes continuous singleton columns and extends results known from duality fixing. The second analyzes and exploits pairwise dominance relations between variables, whereas the third detects isolated subproblems and solves them independently. The performance of the presented techniques is demonstrated on two MIP test sets. One contains all benchmark instances from the last three MIPLIB versions, while the other consists of real-world supply chain management problems. The computational results show that the combination of all three presolving techniques almost halves the solving time for the considered supply chain management problems. For the MIPLIB instances we obtain a speedup of 20\% on affected instances while not degrading the performance on the remaining problems.},
  Date                     = {2015},
  Doi                      = {10.1007/s12532-015-0083-5},
  ISSN                     = {1867--2957},
  Journaltitle             = {Mathematical Programming Computation},
  Owner                    = {andrea},
  Timestamp                = {2017.04.23}
}

@Article{Garland2008,
  author       = {Garland, Michael and Le Grand, Scott and Nickolls, John and Anderson, Joshua and Hardwick, Jim and Morton, Scott and Phillips, Everett and Zhang, Yao and Volkov, Vasily},
  title        = {Parallel Computing Experiences with {CUDA}},
  journaltitle = {{IEEE} Micro},
  date         = {2008},
  volume       = {28},
  number       = {4},
  month        = jul,
  pages        = {13--27},
  issn         = {0272-1732},
  doi          = {10.1109/MM.2008.57},
 abstract = {The CUDA programming model provides a straightforward means of describing inherently parallel computations, and NVIDIA's Tesla GPU architecture delivers high computational throughput on massively parallel problems. This article surveys experiences gained in applying CUDA to a diverse set of problems and the parallel speedups over sequential codes running on traditional CPU architectures attained by executing key computations on the GPU.},
  acmid        = {1442820},
  issue_date   = {July 2008},
  location     = {Los Alamitos, CA, USA},
  numpages     = {15},
  publisher    = {IEEE Computer Society Press},
}

@Article{Gay1985,
  author       = {Gay, D. M},
  title        = {Electronic mail distribution of linear programming test problems},
  journaltitle = {Mathematical Programming Society {COAL} Newsletter},
  date         = {1985},
  volume       = {13},
  pages        = {10--12},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@Online{Gay2005,
  Title                    = {Netlib {LP} benchmark documentation},
  Author                   = {David M. Gay},
  Date                     = {2005},
  Month                    = aug,
  Url                      = {http://www.netlib.org/lp/data/readme},

  Note                     = {Accessed on 7 November 2014},

  Owner                    = {andrea},
  Timestamp                = {2014.11.07}
}

@InProceedings{Ghose2016,
  Title                    = {Divergence Aware Automated Partitioning of {OpenCL} Workloads},
  Author                   = {Ghose, Anirban and Dey, Soumyajit and Mitra, Pabitra and Chaudhuri, Mainak},
  Booktitle                = {{P}roceedings of the 9th {I}ndia {S}oftware {E}ngineering {C}onference},

  Address                  = {New York, NY, USA},
  Pages                    = {131--135},
  Publisher                = {ACM},
  Series                   = {ISEC '16},

 abstract = {Heterogeneous partitioning is a key step for efficient mapping and scheduling of data parallel applications on multi-core computing platforms involving both CPUs and GPUs. Over the last few years, several automated partitioning methodologies, both static as well as dynamic, have been proposed for this purpose. The present work provides an in-depth analysis of control flow divergence and its impact on the quality of such program partitions. We characterize the amount of divergence in a program as an important performance feature and train suitable Machine Learning (ML) based classifiers which statically decide the partitioning of an OpenCL workload for a heterogeneous platform involving a single CPU and a single GPU. Our approach reports improved partitioning results with respect to timing performance when compared with existing approaches for ML based static partitioning of data parallel workloads.},
  Acmid                    = {2856639},
  Date                     = {2016},
  Doi                      = {10.1145/2856636.2856639},
  ISBN                     = {978-1-4503-4018-2},
  Keywords                 = {Control Flow Divergence, Feature Extraction, OpenCL},
  Location                 = {Goa, India},
  Numpages                 = {5}
}

@InProceedings{Gilbert2006,
  Title                    = {High-performance Graph Algorithms from Parallel Sparse Matrices},
  Author                   = {Gilbert, John R. and Reinhardt, Steve and Shah, Viral B.},
  Booktitle                = {{P}roceedings of the 8th {I}nternational {C}onference on {A}pplied {P}arallel {C}omputing: {S}tate of the {A}rt in {S}cientific {C}omputing},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {260--269},
  Publisher                = {Springer-Verlag},
  Series                   = {PARA '06},

 abstract = {Large-scale computation on graphs and other discrete structures is becoming increasingly important in many applications, including computational biology, web search, and knowledge discovery. High-performance combinatorial computing is an infant field, in sharp contrast with numerical scientific computing. \\We argue that many of the tools of high-performance numerical computing - in particular, parallel algorithms and data structures for computation with sparse matrices - can form the nucleus of a robust infrastructure for parallel computing on graphs. We demonstrate this with an implementation of a graph analysis benchmark using the sparse matrix infrastructure in Star-P, our parallel dialect of the MATLAB programming language.},
  Acmid                    = {1775097},
  Date                     = {2006},
  ISBN                     = {978-3-540-75754-2},
  Location                 = {Umeå, SE},
  Numpages                 = {10},
  Url                      = {http://dl.acm.org/citation.cfm?id=1775097}
}

@TechReport{Gleixner2012a,
  author      = {Ambros M. Gleixner},
  title       = {Factorization and update of a reduced basis matrix for the revised simplex method},
  institution = {Konrad-Zuse-Zentrum für Informationstechnik Berlin},
  date        = {2012},
  language    = {eng},
  number      = {12--36},
  location    = {Takustr, 7, 14195 Berlin},
  url         = {https://opus4.kobv.de/opus4-zib/files/1634/ZR-12-36.pdf},
  abstract    = {In this paper, we describe a method to enhance the FTRAN and BTRAN operations in the revised simplex algorithm by using a reduced basis matrix defined by basic columns and nonbasic rows. This submatrix of the standard basis matrix is potentially much smaller, but may change its dimension dynamically from iteration to iteration. \\For the classical product form update (eta updates), the idea has been noted already by Zoutendijk, but only preliminarily tested by Powell in the early 1970s. We extend these ideas to Forrest-Tomlin type update formulas for an LU factorization of the reduced basis matrix, which are suited for efficient implementation within a state-of-the-art simplex solver. The computational advantages of the proposed method apply to pure LP solving as well as to LP-based branch-cut-and-price algorithms. It can easily be integrated into existing simplex codes.},
  owner       = {andrea},
  timestamp   = {2017.05.08},
  urn         = {urn:nbn:de:0297-zib-16349},
}

@InProceedings{Gleixner2012,
  author    = {Ambros M. Gleixner and Daniel E. Steffy and Kati Wolter},
  title     = {Improving the Accuracy of Linear Programming Solvers with Iterative Refinement},
  booktitle = {{P}roceedings of the 37th {I}nternational {S}ymposium on {S}ymbolic and {A}lgebraic {C}omputation},
  date      = {2012},
  series    = {ISSAC '12},
  publisher = {ACM},
  location  = {Grenoble, FR},
  month     = jul,
  isbn      = {978-1-4503-1269-1},
  pages     = {187--194},
  doi       = {10.1145/2442829.2442858},
  abstract  = {We describe an iterative refinement procedure for computing extended precision or exact solutions to linear programming problems (LPs). Arbitrarily precise solutions can be computed by solving a sequence of closely related LPs with limited precision arithmetic. The LPs solved share the same constraint matrix as the original problem instance and are transformed only by modification of the objective function, right-hand side, and variable bounds. Exact computation is used to compute and store the exact representation of the transformed problems, while numeric computation is used for solving LPs. At all steps of the algorithm the LP bases encountered in the transformed problems correspond directly to LP bases in the original problem description. \\We demonstrate that this algorithm is effective in practice for computing extended precision solutions and that this leads to direct improvement of the best known methods for solving LPs exactly over the rational numbers.},
  acmid     = {2442858},
  address   = {Grenoble, FR},
  keywords  = {iterative refinement, linear programming, optimization},
  numpages  = {8},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Book{Golub1996,
  author    = {Gene H. Golub and Van Loan, Charles F.},
  title     = {Matrix Computations},
  date      = {1996},
  edition   = {3},
  publisher = {Johns Hopkins University Press},
  location  = {Baltimore, MD, USA},
  isbn      = {0-8018-5414-8},
  owner     = {andrea},
  timestamp = {2015.09.27},
}

@InProceedings{Gonzalez2012,
  Title                    = {{PowerGraph}: Distributed Graph-parallel Computation on Natural Graphs},
  Author                   = {Gonzalez, Joseph E. and Low, Yucheng and Gu, Haijie and Bickson, Danny and Guestrin, Carlos},
  Booktitle                = {{P}roceedings of the 10th {USENIX} {C}onference on {O}perating {S}ystems {D}esign and {I}mplementation},

  Address                  = {Berkeley, CA, USA},
  Pages                    = {17--30},
  Publisher                = {USENIX Association},
  Series                   = {OSDI '12},

 abstract = {Large-scale graph-structured computation is central to tasks ranging from targeted advertising to natural language processing and has led to the development of several graph-parallel abstractions including Pregel and GraphLab. However, the natural graphs commonly found in the real-world have highly skewed power-law degree distributions, which challenge the assumptions made by these abstractions, limiting performance and scalability. \\In this paper, we characterize the challenges of computation on natural graphs in the context of existing graph-parallel abstractions. We then introduce the PowerGraph abstraction which exploits the internal structure of graph programs to address these challenges. Leveraging the PowerGraph abstraction we introduce a new approach to distributed graph placement and representation that exploits the structure of power-law graphs. We provide a detailed analysis and experimental evaluation comparing PowerGraph to two popular graph-parallel systems. Finally, we describe three different implementation strategies for PowerGraph and discuss their relative merits with empirical evaluations on large-scale real-world problems demonstrating order of magnitude gains.},
  Acmid                    = {2387883},
  Date                     = {2012},
  ISBN                     = {978-1-931971-96-6},
  Location                 = {Hollywood, CA, USA},
  Numpages                 = {14},
  Url                      = {http://dl.acm.org/citation.cfm?id=2387880}
}

@Online{Gottschling2013,
  Title                    = {{CUDA-MTL4} manual},
  Author                   = {Peter Gottschling},
  Date                     = {2013},
  Url                      = {http://www.simunova.com/node/300},

  Note                     = {Accessed on 10 May 2017},
  Organization             = {SimuNova UG},

 abstract = {Many things can be realized on a computer very elegantly and efficiently today thanks to progress in software and programming languages. One thing that cannot be done elegantly on a computer is computing. At least not computing fast. \\In the Matrix Template Library 4 we aim for a natural mathematical notation without sacrifying performance. You can write an expression like $x = y * z$ and the library will perform the according operation: scaling a vector, multiplying a sparse matrix with a dense vector or two sparse matrices. Some operations like dense matrix product use tuned BLAS implementation. In parallel, all described operations in this manual are also realized in C++ so that the library can be used without BLAS and is not limited to types supported by BLAS. For short, general applicability is combined with maximal available performance. We developed new techniques to allow for (1) Unrolling of dynamicly sized data with user-define block and tile sizes; (2) Combining multiple vector assignments in a single statement (and more importingly perform them in one single loop); (3) Storing matrices recursively in a never-before realized generality; (4) Performing operations on recursive and non-recursive matrices recursively; (5) Filling compressed sparse matrices efficiently; and much more. \\The manual still not covers all features and techniques of the library. But it should give you enough information to get started.},
  Owner                    = {andrea},
  Timestamp                = {2017.05.10}
}

@InProceedings{Gregor2005,
  Title                    = {The parallel {BGL}: A generic library for distributed graph computations},
  Author                   = {Douglas Gregor and Andrew Lumsdaine},
  Booktitle                = {{P}arallel {O}bject-{O}riented {S}cientific {C}omputing},
  Month                    = jul,
  Series                   = {POOSC '05},

 abstract = {This paper presents the Parallel BGL, a generic C++ library for distributed graph computation. Like the sequential Boost Graph Library (BGL) upon which it is based, the Parallel BGL applies the paradigm of generic programming to the domain of graph computations. Emphasizing efficient generic algorithms and the use of concepts to specify the requirements on type parameters, the Parallel BGL also provides flexible supporting data structures such as distributed adjacency lists and external property maps. The generic programming approach simultaneously stresses flexibility and efficiency, resulting in a parallel graph library that can adapt to various data structures and communication models while retaining the efficiency of equivalent hand-coded programs. Performance data for selected algorithms are provided demonstrating the efficiency and scalability of the Parallel BGL},
  Date                     = {2005},
  Owner                    = {andrea},
  Timestamp                = {2017.05.09},
  Url                      = {http://www.osl.iu.edu/publications/prints/2005/Gregor:POOSC:2005.pdf}
}

@Article{Grigori2007,
  author       = {L. Grigori and J.W. Demmel and X.S. Li},
  title        = {Parallel Symbolic Factorization for Sparse {LU} with Static Pivoting},
  journaltitle = {{SIAM} Journal on Scientific Computing},
  date         = {2007},
  volume       = {29},
  number       = {3},
  pages        = {1289--1314},
  doi          = {10.1137/050638102},
  abstract     = {This paper presents the design and implementation of a memory scalable parallel symbolic factorization algorithm for general sparse unsymmetric matrices. Our parallel algorithm uses a graph partitioning approach, applied to the graph of $|A|+|A|^T$, to partition the matrix in such a way that is good for sparsity preservation as well as for parallel factorization. The partitioning yields a so-called separator tree which represents the dependencies among the computations. We use the separator tree to distribute the input matrix over the processors using a block cyclic approach and a subtree to subprocessor mapping. The parallel algorithm performs a bottom-up traversal of the separator tree. With a combination of right-looking and left-looking partial factorizations, the algorithm obtains one column structure of L and one row structure of U at each step. The algorithm is implemented in C and MPI. From a performance study on large matrices, we show that the parallel algorithm significantly reduces the memory requirement of the symbolic factorization step, as well as the overall memory requirement of the parallel solver. It also often reduces the runtime of the sequential algorithm, which is already relatively small. In general, the parallel algorithm prevents the symbolic factorization step from being a time or memory bottleneck of the parallel solver.},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@Article{Hall2010,
  author       = {J.A.J. Hall},
  title        = {Towards a practical parallelisation of the simplex method},
  journaltitle = {Computational Management Science},
  date         = {2010},
  language     = {English},
  volume       = {7},
  number       = {2},
  pages        = {139-170},
  issn         = {1619--697X},
  doi          = {10.1007/s10287-008-0080-5},
  abstract     = {The simplex method is frequently the most efficient method of solving linear programming (LP) problems. This paper reviews previous attempts to parallelise the simplex method in relation to efficient serial simplex techniques and the nature of practical LP problems. For the major challenge of solving general large sparse LP problems, there has been no parallelisation of the simplex method that offers significantly improved performance over a good serial implementation. However, there has been some success in developing parallel solvers for LPs that are dense or have particular structural properties. As an outcome of the review, this paper identifies scope for future work towards the goal of developing parallel implementations of the simplex method that are of practical value.},
  keywords     = {Linear programming; Simplex method; Sparse; Parallel computing; 90C05},
  owner        = {andrea},
  publisher    = {Springer-Verlag},
  timestamp    = {2017.05.08},
}

@InCollection{Hall2012,
  author    = {Julian Hall and Qi Huangfu},
  title     = {A High Performance Dual Revised Simplex Solver},
  booktitle = {{P}arallel {P}rocessing and {A}pplied {M}athematics},
  date      = {2012},
  editor    = {Wyrzykowski, Roman and Dongarra, Jack and Karczewski, Konrad and Waśniewski, Jerzy},
  language  = {English},
  volume    = {7203},
  series    = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  isbn      = {978-3-642-31463-6},
  pages     = {143--151},
  doi       = {10.1007/978-3-642-31464-3_15},
  abstract  = {When solving families of related linear programming (LP) problems and many classes of single LP problems, the simplex method is the preferred computational technique. Hitherto there has been no efficient parallel implementation of the simplex method that gives good speed-up on general, large sparse LP problems. This paper presents a variant of the dual simplex method and a prototype parallelisation scheme. The resulting implementation, ParISS, is efficient when run in serial and offers modest speed-up for a range of LP test problems.},
  keywords  = {Linear programming; Dual revised simplex method; Parallel algorithms},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@InProceedings{Hamzic2011,
  author    = {Adis Hamzić and Alvin Huseinović and Novica Nosović},
  title     = {Implementation and performance analysis of the Simplex algorithm adapted to run on commodity {OpenCL} enabled graphics processors},
  booktitle = {{P}roceedings of the {XXIII} {I}nternational {S}ymposium on {I}nformation {C}ommunication and {A}utomation {T}echnologies},
  date      = {2011},
  series    = {ICAT '11},
  location  = {Sarajevo, BIH},
  month     = oct,
  pages     = {1--7},
  doi       = {10.1109/ICAT.2011.6102135},
  abstract  = {The Simplex algorithm is commonly used for solving Linear Optimization problems. Linear Optimization methods are used to solve problems in areas such as Economics, Business, Planning and Engineering. Developments of hardware platforms have allowed the use of Linear Optimization methods on problems that presented serious computational challenges in the past. However, solving large optimization problems can be time consuming, which has to be taken into consideration for time-critical applications. With the invention of the GPU assisted computing the situation in this field has progressed. In this paper, implementation and performance analysis of the Simplex algorithm adapted to take the advantage of modern graphics processors versus traditional CPU adapted implementation is presented.},
  keywords  = {computer graphics;graphics processing units;linear programming;CPU adapted implementation;GPU assisted computing;commodity OpenCL enabled graphics processors;hardware platforms;linear optimization methods;linear optimization problems;performance analysis;simplex algorithm;Aggregates;Graphics processing unit;Indexes;Instruction sets;Libraries;Optimization;GPU;Linear optimization;OpenCL;linear programming;simplex},
  owner     = {andrea},
  timestamp = {2014.03.05},
}

@Article{Han2006,
  Title                    = {Exploiting locality for irregular scientific codes},
  Author                   = {Hwansoo Han and Chau-Wen Tseng},

  Month                    = jul,
  Number                   = {7},
  Pages                    = {606--618},
  Volume                   = {17},

 abstract = {Irregular scientific codes experience poor cache performance due to their irregular memory access patterns. In this paper, we present two new locality improving techniques for irregular scientific codes. Our techniques exploit geometric structures hidden in data access patterns and computation structures. Our new data reordering (GPART) finds the graph structure within data accesses and applies hierarchical clustering. Quality partitions are constructed quickly by clustering multiple neighbor nodes with priority on nodes with high degree and repeating a few passes. Overhead is kept low by clustering multiple nodes in each pass and considering only edges between partitions. Our new computation reordering (Z-SORT) treats the values of index arrays as coordinates and reorders corresponding computations in Z-curve order. Applied to dense inputs, Z-SORT achieves performance close to data reordering combined with other computation reordering but without the overhead involved in data reordering. Experiments on irregular scientific codes for a variety of meshes show locality optimization techniques are effective for both sequential and parallelized codes, improving performance by 60-87 percent. GPART achieved within 1-2 percent of the performance of more sophisticated partitioning algorithms, but with one third of the overhead. Z-SORT also yields the performance improvement of 64 percent for dense inputs, which is comparable with data reordering combined with computation reordering},
  Date                     = {2006},
  Doi                      = {10.1109/TPDS.2006.88},
  ISSN                     = {1045-9219},
  Journaltitle             = {{IEEE} Transactions on Parallel and Distributed Systems},
  Keywords                 = {cache storage;data structures;optimising compilers;Z-SORT computation reordering;Z-curve order;data access;data access patterns;data reordering;graph structure;hierarchical clustering;index arrays;irregular scientific codes;locality optimization techniques;Cache memory;Computational fluid dynamics;Computer architecture;Concurrent computing;Data mining;Data structures;Fluid dynamics;Microprocessors;Parallel processing;Partitioning algorithms;Compiler optimization;cache memories;computation reordering.;data reordering;inspector/executor}
}

@InProceedings{Harshvardhan2014,
  Title                    = {{KLA}: A New Algorithmic Paradigm for Parallel Graph Computations},
  Author                   = {Harshvardhan and Fidel, Adam and Amato, Nancy M. and Rauchwerger, Lawrence},
  Booktitle                = {{P}roceedings of the 23rd {I}nternational {C}onference on {P}arallel {A}rchitectures and {C}ompilation},

  Address                  = {New York, NY, USA},
  Pages                    = {27--38},
  Publisher                = {ACM},
  Series                   = {PACT '14},

 abstract = {This paper proposes a new algorithmic paradigm - k-level asynchronous (KLA) - that bridges level-synchronous and asynchronous paradigms for processing graphs. The KLA paradigm enables the level of asynchrony in parallel graph algorithms to be parametrically varied from none (level-synchronous) to full (asynchronous). The motivation is to improve execution times through an appropriate trade-off between the use of fewer, but more expensive global synchronizations, as in level-synchronous algorithms, and more, but less expensive local synchronizations (and perhaps also redundant work), as in asynchronous algorithms. We show how common patterns in graph algorithms can be expressed in the KLA pardigm and provide techniques for determining k, the number of asynchronous steps allowed between global synchronizations. Results of an implementation of KLA in the STAPL Graph Library show excellent scalability on up to 96K cores and improvements of 10$\times$ or more over level-synchronous and asynchronous versions for graph algorithms such as breadth-first search, PageRank, k-core decomposition and others on certain classes of real-world graphs.},
  Acmid                    = {2628091},
  Date                     = {2014},
  Doi                      = {10.1145/2628071.2628091},
  ISBN                     = {978-1-4503-2809-8},
  Keywords                 = {asynchronous graph algorithms, big data, distributed computing, graph analytics, parallel algorithms},
  Location                 = {Edmonton, AB, CA},
  Numpages                 = {12},
  Owner                    = {andrea},
  Timestamp                = {2016.09.07}
}

@Article{Hartley2014,
  author       = {Edward N. Hartley and Juan L. Jerez and Andrea Suardi and Jan M. Macjeowski and Eric C. Kerrigan and George A. Constantinides},
  title        = {Predictive control using an {FPGA} with application to aircraft control},
  journaltitle = {{IEEE} Transactions on Control Systems Technology},
  date         = {2014},
  volume       = {22},
  number       = {3},
  month        = may,
  pages        = {1006--1017},
  issn         = {1063-6536},
  doi          = {10.1109/TCST.2013.2271791},
  abstract     = {Alternative and more efficient computational methods can extend the applicability of model predictive control (MPC) to systems with tight real-time requirements. This paper presents a system-on-a-chip MPC system, implemented on a field-programmable gate array (FPGA), consisting of a sparse structure-exploiting primal dual interior point (PDIP) quadratic program (QP) solver for MPC reference tracking and a fast gradient QP solver for steady-state target calculation. A parallel reduced precision iterative solver is used to accelerate the solution of the set of linear equations forming the computational bottleneck of the PDIP algorithm. A numerical study of the effect of reducing the number of iterations highlights the effectiveness of the approach. The system is demonstrated with an FPGA-in-the-loop testbench controlling a nonlinear simulation of a large airliner. This paper considers many more manipulated inputs than any previous FPGA-based MPC implementation to date, yet the implementation comfortably fits into a midrange FPGA, and the controller compares well in terms of solution quality and latency to state-of-the-art QP solvers running on a standard PC.},
  keywords     = {Aerospace control;field-programmable gate arrays (FPGAs);optimization methods;predictive control.},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@InBook{Hbeika2017,
  author    = {Hbeika, Jad and Kulkarni, Milind},
  title     = {Locality-Aware Task-Parallel Execution on {GPUs}},
  booktitle = {{P}roceedings of the 29th {I}nternational {W}orkshop on {L}anguages and {C}ompilers for {P}arallel {C}omputing},
  date      = {2017},
  editor    = {Ding, Chen and Criswell, John and Wu, Peng},
  series    = {LCPC '16},
  publisher = {Springer International Publishing},
  location  = {Rochester, NY, USA},
  isbn      = {978-3-319-52709-3},
  pages     = {250--264},
  doi       = {10.1007/978-3-319-52709-3_19},
  abstract  = {GPGPUs deliver high speedup for regular applications while remaining energy efficient. In recent years, there has been much focus on tuning irregular, task-parallel applications and/or the GPU architecture in order to achieve similar benefits for irregular applications running on GPUs. While most of the previous works have focused on minimizing the effect of control and memory divergence, which are prominent in irregular applications and which degrade the performance, there has been less attention paid to decreasing cache pressure and hence improving performance of applications given the small cache sizes on GPUs. \\In this paper we tackle two problems. First we extract data parallelism from irregular task parallel applications, which we do by subdividing each task into sub tasks at the CPU side and sending these sub tasks to the GPU for execution. By doing so we take advantage of the massive parallelism provided by the GPU. Second, to mitigate the memory demands of many tasks that access irregular data structures, we schedule these subtasks in a way to minimize the memory footprint of each warp running on the GPU. We use our framework with 3 task-parallel algorithms and show that we can achieve significant speedups over optimized GPU code.},
  owner     = {andrea},
  timestamp = {2017.02.17},
}

@Book{Hennessy2011,
  author    = {Hennessy, John L. and Patterson, David A.},
  title     = {Computer Architecture: A Quantitative Approach},
  date      = {2011},
  edition   = {5th},
  publisher = {Morgan Kaufmann Publishers Inc.},
  location  = {San Francisco, CA, USA},
  isbn      = {012383872X},
  owner     = {andrea},
  timestamp = {2015.10.22},
}

@Article{Hogg2013a,
  author       = {Hogg, Jonathan and Scott, Jennifer},
  title        = {New Parallel Sparse Direct Solvers for Multicore Architectures},
  journaltitle = {{A}lgorithms},
  date         = {2013},
  volume       = {6},
  number       = {4},
  pages        = {702--725},
  issn         = {1999-4893},
  doi          = {10.3390/a6040702},
  url          = {http://www.mdpi.com/1999-4893/6/4/702},
  abstract     = {At the heart of many computations in science and engineering lies the need to efficiently and accurately solve large sparse linear systems of equations. Direct methods are frequently the method of choice because of their robustness, accuracy and potential for use as black-box solvers. In the last few years, there have been many new developments, and a number of new modern parallel general-purpose sparse solvers have been written for inclusion within the HSL mathematical software library. In this paper, we introduce and briefly review these solvers for symmetric sparse systems. We describe the algorithms used, highlight key features (including bit-compatibility and out-of-core working) and then, using problems arising from a range of practical applications, we illustrate and compare their performances. We demonstrate that modern direct solvers are able to accurately solve systems of order 106 in less than 3 minutes on a 16-core machine.},
}

@Article{Hogg2016,
  author       = {Jonathan D. Hogg and Evgueni Ovtchinnikov and Jennifer A. Scott},
  title        = {A Sparse Symmetric Indefinite Direct Solver for {GPU} Architectures},
  journaltitle = {{ACM} Transactions on Mathematical Software},
  date         = {2016},
  volume       = {42},
  number       = {1},
  month        = jan,
  pages        = {1:1--1:25},
  issn         = {0098-3500},
  doi          = {10.1145/2756548},
 abstract = {In recent years, there has been considerable interest in the potential for graphics processing units (GPUs) to speed up the performance of sparse direct linear solvers. Efforts have focused on symmetric positive-definite systems for which no pivoting is required, while little progress has been reported for the much harder indefinite case. We address this challenge by designing and developing a sparse symmetric indefinite solver SSIDS. This new library-quality $LDL^T$ factorization is designed for use on GPU architectures and incorporates threshold partial pivoting within a multifrontal approach. Both the factorize and the solve phases are performed using the GPU. Another important feature is that the solver produces bit-compatible results. Numerical results for indefinite problems arising from a range of practical applications demonstrate that, for large problems, SSIDS achieves performance improvements of up to a factor of 4.6$\times$ compared with a state-of-the-art multifrontal solver on a multicore CPU.},
  acmid        = {2756548},
  articleno    = {1},
  issue_date   = {February 2016},
  location     = {New York, NY, USA},
  numpages     = {25},
  owner        = {andrea},
  publisher    = {ACM},
  timestamp    = {2017.01.05},
}

@InProceedings{Hong2012,
  Title                    = {{Green-Marl}: A {DSL} for Easy and Efficient Graph Analysis},
  Author                   = {Hong, Sungpack and Chafi, Hassan and Sedlar, Edic and Olukotun, Kunle},
  Booktitle                = {{P}roceedings of the {S}eventeenth {I}nternational {C}onference on {A}rchitectural {S}upport for {P}rogramming {L}anguages and {O}perating {S}ystems},

  Address                  = {New York, NY, USA},
  Pages                    = {349--362},
  Publisher                = {ACM},
  Series                   = {ASPLOS XVII},

 abstract = {The increasing importance of graph-data based applications is fueling the need for highly efficient and parallel implementations of graph analysis software. In this paper we describe Green-Marl, a domain-specific language (DSL) whose high level language constructs allow developers to describe their graph analysis algorithms intuitively, but expose the data-level parallelism inherent in the algorithms. We also present our Green-Marl compiler which translates high-level algorithmic description written in Green-Marl into an efficient C++ implementation by exploiting this exposed data-level parallelism. Furthermore, our Green-Marl compiler applies a set of optimizations that take advantage of the high-level semantic knowledge encoded in the Green-Marl DSL. We demonstrate that graph analysis algorithms can be written very intuitively with Green-Marl through some examples, and our experimental results show that the compiler-generated implementation out of such descriptions performs as well as or better than highly-tuned hand-coded implementations.},
  Acmid                    = {2151013},
  Date                     = {2012},
  Doi                      = {10.1145/2150976.2151013},
  ISBN                     = {978-1-4503-0759-8},
  Keywords                 = {domain-specific language, graph, parallel programming},
  Location                 = {London, UK},
  Numpages                 = {14}
}

@InProceedings{Hong2009,
  Title                    = {An Analytical Model for a {GPU} Architecture with Memory-level and Thread-level Parallelism Awareness},
  Author                   = {Hong, Sunpyo and Kim, Hyesoon},
  Booktitle                = {{P}roceedings of the 36th {A}nnual {I}nternational {S}ymposium on {C}omputer {A}rchitecture},

  Address                  = {New York, NY, USA},
  Pages                    = {152--163},
  Publisher                = {ACM},
  Series                   = {ISCA '09},

 abstract = {GPU architectures are increasingly important in the multi-core era due to their high number of parallel processors. Programming thousands of massively parallel threads is a big challenge for software engineers, but understanding the performance bottlenecks of those parallel programs on GPU architectures to improve application performance is even more difficult. Current approaches rely on programmers to tune their applications by exploiting the design space exhaustively without fully understanding the performance characteristics of their applications. \\To provide insights into the performance bottlenecks of parallel applications on GPU architectures, we propose a simple analytical model that estimates the execution time of massively parallel programs. The key component of our model is estimating the number of parallel memory requests (we call this the memory warp parallelism) by considering the number of running threads and memory bandwidth. Based on the degree of memory warp parallelism, the model estimates the cost of memory requests, thereby estimating the overall execution time of a program. Comparisons between the outcome of the model and the actual execution time in several GPUs show that the geometric mean of absolute error of our model on micro-benchmarks is 5.4\% and on GPU computing applications is 13.3\%. All the applications are written in the CUDA programming language.},
  Acmid                    = {1555775},
  Date                     = {2009},
  Doi                      = {10.1145/1555754.1555775},
  ISBN                     = {978-1-60558-526-0},
  Keywords                 = {GPU architecture, analytical model, cuda, memory level parallelism, performance estimation, warp level parallelism},
  Location                 = {Austin, TX, USA},
  Numpages                 = {12}
}

@InProceedings{Hong2010,
  Title                    = {An Integrated {GPU} Power and Performance Model},
  Author                   = {Hong, Sunpyo and Kim, Hyesoon},
  Booktitle                = {{P}roceedings of the 37th {A}nnual {I}nternational {S}ymposium on {C}omputer {A}rchitecture},

  Address                  = {New York, NY, USA},
  Pages                    = {280--289},
  Publisher                = {ACM},
  Series                   = {ISCA '10},

 abstract = {GPU architectures are increasingly important in the multi-core era due to their high number of parallel processors. Performance optimization for multi-core processors has been a challenge for programmers. Furthermore, optimizing for power consumption is even more difficult. Unfortunately, as a result of the high number of processors, the power consumption of many-core processors such as GPUs has increased significantly. \\Hence, in this paper, we propose an integrated power and performance (IPP) prediction model for a GPU architecture to predict the optimal number of active processors for a given application. The basic intuition is that when an application reaches the peak memory bandwidth, using more cores does not result in performance improvement. \\We develop an empirical power model for the GPU. Unlike most previous models, which require measured execution times, hardware performance counters, or architectural simulations, IPP predicts execution times to calculate dynamic power events. We then use the outcome of IPP to control the number of running cores. We also model the increases in power consumption that resulted from the increases in temperature. \\With the predicted optimal number of active cores, we show that we can save up to 22.09\%of runtime GPU energy consumption and on average 10.99\% of that for the five memory bandwidth-limited benchmarks.},
  Acmid                    = {1815998},
  Date                     = {2010},
  Doi                      = {10.1145/1815961.1815998},
  ISBN                     = {978-1-4503-0053-7},
  Keywords                 = {CUDA, GPU architecture, analytical model, energy, performance, power estimation},
  Location                 = {Saint-Malo, France},
  Numpages                 = {10}
}

@Article{Huangfu2015,
  Title                    = {Novel update techniques for the revised simplex method},
  Author                   = {Huangfu, Qi and Hall, Julian},
  Number                   = {3},
  Pages                    = {587--608},
  Volume                   = {60},

 abstract = {This paper introduces three novel techniques for updating the invertible representation of the basis matrix when solving practical sparse linear programming problems using a high performance implementation of the dual revised simplex method, being of particular value when suboptimization is used. Two are variants of the product form update and the other permits multiple Forrest-Tomlin updates to be performed. Computational results show that one of the product form variants is significantly more efficient than the traditional approach, with its performance approaching that of the Forrest-Tomlin update for some problems. The other is less efficient, but valuable in the context of the dual revised simplex method with suboptimization. Results show that the multiple Forrest-Tomlin updates are performed with no loss of serial efficiency.},
  Date                     = {2015},
  Doi                      = {10.1007/s10589-014-9689-1},
  Journaltitle             = {Computational Optimization and Applications},
  Owner                    = {andrea},
  Publisher                = {Springer},
  Timestamp                = {2017.04.08}
}

@InProceedings{Hugues2010,
  author    = {Maxime R. Hugues and Serge G. Petiton},
  title     = {Sparse Matrix Formats Evaluation and Optimization on a {GPU}},
  booktitle = {{P}roceedings of the 12th {IEEE} {I}nternational {C}onference on {H}igh {P}erformance {C}omputing and {C}ommunications},
  date      = {2010},
  series    = {HPCC '10},
  location  = {Melbourne, AUS},
  month     = sep,
  pages     = {122--129},
  doi       = {10.1109/HPCC.2010.85},
  abstract  = {The data parallel programming model comes back with massive multicore architectures. The GPU is one of these and offers important possibilities to accelerate linear algebra. However, the irregular structure of sparse matrix operations generates problems with this programming model to obtain efficient performance. This depends on the used format to store values and the matrix structure. The sparse matrix-vector product (SpMV) is one of the most used kernel in scientific computing and is the main performance source of iterative methods. We propose an evaluation and optimization of several sparse formats for the SpMV kernel which have succeeded at the time of data parallel computer. This study is realized by analyzing the performances following the distribution of the non zeros values in the matrix to determine the best and the worst reachable value. The results show that all sparse formats converge to the same efficiency and perform poorly with a strong distribution of elements.},
  keywords  = {computer graphic equipment;coprocessors;iterative methods;multiprocessing systems;parallel programming;sparse matrices;GPU;SpMV kernel;data parallel programming model;iterative method;linear algebra;massive multicore;sparse matrix format evaluation;sparse matrix format optimization;sparse matrix vector product;Data Parallel Programming;GPU;Many-Core;SpMV;Sparse Format},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Article{Jacomy2014,
  author       = {Mathieu Jacomy and Tommaso Venturini and Sebastien Heymann and Mathieu Bastian},
  title        = {{ForceAtlas2}, a Continuous Graph Layout Algorithm for Handy Network Visualization Designed for the Gephi Software},
  journaltitle = {{PL}oS {ONE}},
  date         = {2014},
  volume       = {9},
  number       = {6},
  month        = jun,
  doi          = {10.1371/journal.pone.0098679},
  abstract     = {Gephi is a network visualization software used in various disciplines (social network analysis, biology, genomics). One of its key features is the ability to display the spatialization process, aiming at transforming the network into a map, and ForceAtlas2 is its default layout algorithm. The latter is developed by the Gephi team as an all-around solution to Gephi users' typical networks (scale-free, 10 to 10,000 nodes). We present here for the first time its functioning and settings. ForceAtlas2 is a force-directed layout close to other algorithms used for network spatialization. We do not claim a theoretical advance but an attempt to integrate different techniques such as the Barnes Hut simulation, degree-dependent repulsive force, and local and global adaptive temperatures. It is designed for the Gephi user experience (it is a continuous algorithm), and we explain which constraints it implies. The algorithm benefits from much feedback and is developed in order to provide many possibilities through its settings. We lay out its complete functioning for the users who need a precise understanding of its behaviour, from the formulas to graphic illustration of the result. We propose a benchmark for our compromise between performance and quality. We also explain why we integrated its various features and discuss our design choices.},
  owner        = {andrea},
  timestamp    = {2015.01.18},
}

@Article{Jang2011,
  author       = {B. Jang and D. Schaa and P. Mistry and D. Kaeli},
  title        = {Exploiting Memory Access Patterns to Improve Memory Performance in Data-Parallel Architectures},
  journaltitle = {{IEEE} {T}ransactions on {P}arallel and {D}istributed {S}ystems},
  date         = {2011},
  volume       = {22},
  number       = {1},
  month        = jan,
  pages        = {105--118},
  issn         = {1045--9219},
  doi          = {10.1109/TPDS.2010.107},
 abstract = {The introduction of General-Purpose computation on GPUs (GPGPUs) has changed the landscape for the future of parallel computing. At the core of this phenomenon are massively multithreaded, data-parallel architectures possessing impressive acceleration ratings, offering low-cost supercomputing together with attractive power budgets. Even given the numerous benefits provided by GPGPUs, there remain a number of barriers that delay wider adoption of these architectures. One major issue is the heterogeneous and distributed nature of the memory subsystem commonly found on data-parallel architectures. Application acceleration is highly dependent on being able to utilize the memory subsystem effectively so that all execution units remain busy. In this paper, we present techniques for enhancing the memory efficiency of applications on data-parallel architectures, based on the analysis and characterization of memory access patterns in loop bodies; we target vectorization via data transformation to benefit vector-based architectures (e.g., AMD GPUs) and algorithmic memory selection for scalar-based architectures (e.g., NVIDIA GPUs). We demonstrate the effectiveness of our proposed methods with kernels from a wide range of benchmark suites. For the benchmark kernels studied, we achieve consistent and significant performance improvements (up to 11.4$\times$ and 13.5$\times$ over baseline GPU implementations on each platform, respectively) by applying our proposed methodology.},
  keywords     = {computer graphic equipment;coprocessors;multi-threading;parallel architectures;GPU;algorithmic memory selection;low-cost supercomputing;massive multithreaded data-parallel architectures;memory access patterns;memory subsystem;parallel computing;power budgets;scalar-based architectures;vector-based architectures;GPU computing;General-purpose computation on GPUs (GPGPUs);data parallelism;data-parallel architectures.;memory access pattern;memory coalescing;memory optimization;memory selection;vectorization},
}

@Article{Jerez2012a,
  author       = {J.L. Jerez and K.-V. Ling and G.A. Constantinides E.C. and Kerrigan},
  title        = {Model predictive control for deeply pipelined field-programmable gate array implementation: algorithms and circuitry},
  journaltitle = {Control Theory Applications, {IET}},
  date         = {2012},
  volume       = {6},
  number       = {8},
  month        = may,
  pages        = {1029--1041},
  issn         = {1751-8644},
  doi          = {10.1049/iet-cta.2010.0441},
  abstract     = {Model predictive control (MPC) is an optimisation-based scheme that imposes a real-time constraint on computing the solution of a quadratic programming (QP) problem. The implementation of MPC in fast embedded systems presents new technological challenges. In this paper we present a parameterised field-programmable gate array implementation of a customised QP solver for optimal control of linear processes with constraints, which can achieve substantial acceleration over a general purpose microprocessor, especially as the size of the optimisation problem grows. The focus is on exploiting the structure and accelerating the computational bottleneck in a primal-dual interior-point method. We then introduce a new MPC formulation that can take advantage of the novel computational opportunities, in the form of parallel computational channels, offered by the proposed pipelined architecture to improve performance even further. This highlights the importance of the interaction between the control theory and digital system design communities for the success of MPC in fast embedded systems.},
  keywords     = {field programmable gate arrays;pipeline processing;predictive control;quadratic programming;customised QP solver;deeply pipelined field-programmable gate array implementation;digital system design;fast embedded systems;general purpose microprocessor;linear processes;model predictive control;optimal control;optimisation-based scheme;parallel computational channels;pipelined architecture;primal-dual interior-point method;quadratic programming problem;real-time constraint},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@InProceedings{Jerez2011a,
  author    = {Juan L. Jerez and George A. Constantinides and Eric C. Kerrigan},
  title     = {An {FPGA} Implementation of a Sparse Quadratic Programming Solver for Constrained Predictive Control},
  booktitle = {{P}roceedings of the 19th {ACM}/{SIGDA} {I}nternational {S}ymposium on {F}ield {P}rogrammable {G}ate {A}rrays},
  date      = {2011},
  series    = {FPGA '11},
  publisher = {ACM},
  location  = {Monterey, CA, USA},
  isbn      = {978-1-4503-0554-9},
  pages     = {209--218},
  doi       = {10.1145/1950413.1950454},
  abstract  = {Model predictive control (MPC) is an advanced industrial control technique that relies on the solution of a quadratic programming (QP) problem at every sampling instant to determine the input action required to control the current and future behaviour of a physical system. Its ability in handling large multiple input multiple output (MIMO) systems with physical constraints has led to very successful applications in slow processes, where there is sufficient time for solving the optimization problem between sampling instants. The application of MPC to faster systems, which adds the requirement of greater sampling frequencies, relies on new ways of finding faster solutions to QP problems. Field-programmable gate arrays (FPGAs) are specially well suited for this application due to the large amount of computation for a small amount of I/O. In addition, unlike a software implementation, an FPGA can provide the precise timing guarantees required for interfacing the controller to the physical system. We present a high-throughput floating-point FPGA implementation that exploits the parallelism inherent in interior-point optimization methods. It is shown that by considering that the QPs come from a control formulation, it is possible to make heavy use of the sparsity in the problem to save computations and reduce memory requirements by 75\%. The implementation yields a 6.5$\times$ improvement in latency and a 51$\times$ improvement in throughput for large problems over a software implementation running on a general purpose microprocessor.},
  acmid     = {1950454},
  address   = {New York, NY, USA},
  keywords  = {interior-point, model predictive control, optimization},
  numpages  = {10},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@InProceedings{Jerez2012,
  author    = {Juan L. Jerez and George A. Constantinides and Eric C. Kerrigan},
  title     = {Towards a Fixed Point {QP} Solver for Predictive Control},
  booktitle = {{P}roceedings of the 51st {IEEE} {A}nnual {C}onference on {D}ecision and {C}ontrol},
  date      = {2012},
  series    = {CDC '12},
  location  = {Maui, HI, USA},
  month     = dec,
  pages     = {675--680},
  doi       = {10.1109/CDC.2012.6427015},
  abstract  = {There is a need for high speed, low cost and low energy solutions for convex quadratic programming to enable model predictive control (MPC) to be implemented in a wider set of applications than is currently possible. For most quadratic programming (QP) solvers the computational bottleneck is the solution of systems of linear equations, which we propose to solve using a fixed-point implementation of an iterative linear solver to allow for fast and efficient computation in parallel hardware. However, fixed point arithmetic presents additional challenges, such as having to bound peak values of variables and constrain their dynamic ranges. For these types of algorithms the problems cannot be automated by current tools. We employ a preconditioner in a novel manner to allow us to establish tight analytical bounds on all the variables of the Lanczos process, the heart of modern iterative linear solving algorithms. The proposed approach is evaluated through the implementation of a mixed precision interior-point controller for a Boeing 747 aircraft. The numerical results show that there does not have to be a loss of control quality by moving from floating-point to fixed-point.},
  issn      = {0743-1546},
  keywords  = {aircraft control;fixed point arithmetic;iterative methods;predictive control;quadratic programming;Boeing 747 aircraft;Lanczos process;MPC;control quality;convex quadratic programming;fixed point QP solver;fixed point arithmetic;fixed-point implementation;iterative linear solver;iterative linear solving algorithms;linear equations;mixed precision interior-point controller;model predictive control;parallel hardware;Dynamic range;Equations;Hardware;Heuristic algorithms;Mathematical model;Optimization;Symmetric matrices},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@InProceedings{Jerez2012c,
  author    = {Juan L. Jerez and George A. Constantinides and Eric C. Kerrigan},
  title     = {Fixed Point Lanczos: Sustaining {TFLOP}-equivalent Performance in {FPGAs} for Scientific Computing},
  booktitle = {{P}roceedings of the 20th {IEEE} {A}nnual {I}nternational {S}ymposium on {F}ield-{P}rogrammable {C}ustom {C}omputing {M}achines},
  date      = {2012},
  series    = {FCCM '12},
  location  = {Toronto, ON, CA},
  month     = apr,
  pages     = {53--60},
  doi       = {10.1109/FCCM.2012.19},
  abstract  = {We consider the problem of enabling fixed-point implementations of linear algebra kernels to match the strengths of the field-programmable gate array (FPGA). Algorithms for solving linear equations, finding eigen values or finding singular values are typically nonlinear and recursive making the problem of establishing analytical bounds on variable dynamic range non-trivial. Current approaches fail to provide tight bounds for this type of algorithms. We use as a case study one of the most important kernels in scientific computing, the Lanczos iteration, which lies at the heart of well known methods such as conjugate gradient and minimum residual, and we show how we can modify the algorithm to allow us to apply standard linear algebra analysis to prove tight analytical bounds on all variables of the process, regardless of the properties of the original matrix. It is shown that the numerical behaviour of fixed-point implementations of the modified problem can be chosen to be at least as good as a double precision floating point implementation. Using this approach it is possible to get sustained FPGA performance very close to the peak general-purpose graphics processing unit (GPGPU) performance in FPGAs of comparable size when solving a single problem. If there are several independent problems to solve simultaneously it is possible to exceed the peak floating-point performance of a GPGPU, obtaining approximately 1, 2 or 4 TFLOPs for error tolerances of $10^-7$, $10^-5$ and $10^-3$, respectively, in a large Virtex 7 FPGA.},
  keywords  = {conjugate gradient methods;eigenvalues and eigenfunctions;field programmable gate arrays;fixed point arithmetic;graphics processing units;iterative methods;FPGA;GPGPU;Lanczos iteration;TFLOP-equivalent performance;conjugate gradient;double precision floating point;eigenvalues;error tolerance;field-programmable gate array;fixed point Lanczos;general-purpose graphics processing unit;linear algebra kernel;linear equation;minimum residual;peak floating-point;scientific computing;Accuracy;Dynamic range;Eigenvalues and eigenfunctions;Field programmable gate arrays;Kernel;Linear algebra;Symmetric matrices;Field programmable gate arrays;Fixed-point arithmetic;High performance computing;Iterative algorithms;Scientific computing},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@InProceedings{Jerez2011,
  author    = {Juan L. Jerez and George A. Constantinides and Eric C. Kerrigan and Keck-Voon Ling},
  title     = {Parallel {MPC} for Real-Time {FPGA}-based Implementation},
  booktitle = {{P}roceedings of the 18th {IFAC} {W}orld {C}ongress},
  date      = {2011},
  volume    = {18},
  location  = {Milan, IT},
  month     = sep,
  pages     = {1338--1345},
  doi       = {10.3182/20110828-6-IT-1002.01392},
  abstract  = {The succesful application of model predictive control (MPC) in fast embedded systems relies on faster and more energy efficient ways of solving complex optimization problems. A custom quadratic programming (QP) solver implementation on a field-programmable gate array (FPGA) can provide substantial acceleration by exploiting the parallelism inherent in some optimization algorithms, apart from providing novel computational opportunities arising from deep pipelining. This paper presents a new MPC algorithm based on multiplexed MPC that can take advantage of the full potential of an existing FPGA design by utilizing the provided free parallel computational channels arising from such pipelining. The result is greater acceleration over a conventional MPC implementation and reduced silicon usage. The FPGA implementation is shown to be approximately 200$\times$ more energy efficient than a high performance general purpose processor (GPP) for large control problems.},
  owner     = {andrea},
  timestamp = {2014.12.12},
}

@InProceedings{Jerez2013,
  author    = {Juan L. Jerez and Paul J. Goulart and Stefan Richter and George A. Constantinides and Eric C. Kerrigan and Manfred Morari},
  title     = {Embedded Predictive Control on an {FPGA} using the Fast Gradient Method},
  booktitle = {{P}roceedings of the 2013 {E}uropean {C}ontrol {C}onference},
  date      = {2013},
  series    = {ECC '13},
  location  = {Zurich, CH},
  month     = jul,
  isbn      = {978-3-033-03962-9},
  pages     = {3614--3620},
  url       = {http://ieeexplore.ieee.org/document/6669598/},
  abstract  = {Model predictive control (MPC) in resource-constrained embedded platforms requires faster, cheaper and more power-efficient solvers for convex programs than is currently offered by software-based solutions. In this paper we present the first field programmable gate array (FPGA) implementation of a fast gradient solver for linear-quadratic MPC problems with input constraints. We use fixed-point arithmetic to exploit the characteristics of the computing platform and provide analytical guarantees ensuring no overflow errors occur during operation. We further prove that the arithmetic errors due to round-off can lead only to reduced accuracy, but not instability, of the fast gradient method. The results are demonstrated on a model of an industrial atomic force microscope (AFM) where we show that, on a low-end FPGA, satisfactory control performance at a sample rate beyond 1 MHz is achievable, opening up new possibilities for the application of MPC.},
  keywords  = {control engineering computing;convex programming;embedded systems;field programmable gate arrays;gradient methods;linear quadratic control;predictive control;AFM;FPGA;arithmetic errors;convex programs;embedded predictive control;fast gradient method;fast gradient solver;field programmable gate array;fixed-point arithmetic;industrial atomic force microscope;linear-quadratic MPC problems;model predictive control;resource-constrained embedded platforms;satisfactory control performance;Computer architecture;Convergence;Field programmable gate arrays;Gradient methods;Hardware;Upper bound;Vectors},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Article{Jerez2014,
  author       = {Juan L. Jerez and Paul J. Goulart and Stefan Richter and George A. Constantinides and Eric C. Kerrigan and Manfred Morari},
  title        = {Embedded Online Optimization for Model Predictive Control at Megahertz Rates},
  journaltitle = {{IEEE} Transactions on Automatic Control},
  date         = {2014},
  volume       = {59},
  number       = {12},
  month        = dec,
  pages        = {3238--3251},
  issn         = {0018-9286},
  doi          = {10.1109/TAC.2014.2351991},
  abstract     = {Faster, cheaper, and more power efficient optimization solvers than those currently possible using general-purpose techniques are required for extending the use of model predictive control (MPC) to resource-constrained embedded platforms. We propose several custom computational architectures for different first-order optimization methods that can handle linear-quadratic MPC problems with input, input-rate, and soft state constraints. We provide analysis ensuring the reliable operation of the resulting controller under reduced precision fixed-point arithmetic. Implementation of the proposed architectures in FPGAs shows that satisfactory control performance at a sample rate beyond 1 MHz is achievable even on low-end devices, opening up new possibilities for the application of MPC on embedded systems.},
  keywords     = {constraint theory;field programmable gate arrays;fixed point arithmetic;linear quadratic control;optimisation;predictive control;FPGA;custom computational architectures;embedded online optimization;first-order optimization method;general-purpose techniques;input-rate constraint;linear-quadratic MPC problem;megahertz rates;model predictive control;power efficient optimization solver;reduced precision fixed-point arithmetic;resource-constrained embedded platform;satisfactory control performance;soft state constraint;Computer architecture;Convergence;Gradient methods;Hardware;Indexes;Mathematical model;Embedded systems;optimization algorithms;predictive control of linear systems},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@Article{Jerez2012b,
  author       = {Juan L. Jerez and Eric C. Kerrigan and George A. Constantinides},
  title        = {A sparse and condensed {QP} formulation for predictive control of {LTI} systems},
  journaltitle = {Automatica},
  date         = {2012},
  volume       = {48},
  number       = {5},
  pages        = {999--1002},
  issn         = {0005-1098},
  doi          = {10.1016/j.automatica.2012.03.010},
  abstract     = {The computational burden that model predictive control (MPC) imposes depends to a large extent on the way the optimal control problem is formulated as an optimization problem. We present a formulation where the input is expressed as an affine function of the state such that the closed-loop dynamics matrix becomes nilpotent. Using this approach and removing the equality constraints leads to a compact and sparse optimization problem to be solved at each sampling instant. The problem can be solved with a cost per interior-point iteration that is linear with respect to the horizon length, when this is bigger than the controllability index of the plant. The computational complexity of existing condensed approaches grow cubically with the horizon length, whereas existing non-condensed and sparse approaches also grow linearly, but with a greater proportionality constant than with the method presented here.},
  keywords     = {Predictive control},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@InProceedings{Jones2010,
  author    = {David H. Jones and Adam Powell and Christos-Savvas Bouganis Peter Y. K. Cheung},
  title     = {{GPU} Versus {FPGA} for High Productivity Computing},
  booktitle = {{P}roceedings of the 2010 {I}nternational {C}onference on {F}ield {P}rogrammable {L}ogic and {A}pplications},
  date      = {2010},
  series    = {FPL '10},
  publisher = {IEEE Computer Society},
  location  = {Milan, IT},
  isbn      = {978-0-7695-4179-2},
  pages     = {119--124},
  doi       = {10.1109/FPL.2010.32},
  abstract  = {Heterogeneous or co-processor architectures are becoming an important component of high productivity computing systems (HPCS). In this work the performance of a GPU based HPCS is compared with the performance of a commercially available FPGA based HPC. Contrary to previous approaches that focussed on specific examples, a broader analysis is performed by considering processes at an architectural level. A set of benchmarks is employed that use different process architectures in order to exploit the benefits of each technology. These include the asynchronous pipelines common to "map" tasks, a partially synchronous tree common to "reduce" tasks and a fully synchronous, fully connected mesh. We show that the GPU is more productive than the FPGA architecture for most of the benchmarks and conclude that FPGA-based HPCS is being marginalised by GPUs.},
  acmid     = {1933774},
  address   = {Washington, DC, USA},
  keywords  = {High Productivity Computing, GPU, FPGA},
  numpages  = {6},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Article{Jung2008,
  author       = {Jin Hyuk Jung and Dianne P. O'Leary},
  title        = {Implementing an interior point method for linear programs on a {CPU}-{GPU} system.},
  journaltitle = {Electronic Transactions on Numerical Analysis},
  date         = {2008},
  language     = {eng},
  volume       = {28},
  pages        = {174--189},
  url          = {http://eudml.org/doc/117656},
  abstract     = {Graphics processing units (GPUs), present in every laptop and desktop computer, are potentially powerful computational engines for solving numerical problems. We present a mixed precision CPU-GPU algorithm for solving linear programming problems using interior point methods. This algorithm, based on the rectangular-packed matrix storage scheme of Gunnels and Gustavson, uses the GPU for computationally intensive tasks such as matrix assembly, Cholesky factorization, and forward and back substitution. Comparisons with a CPU implementation demonstrate that we can improve performance by using the GPU for sufficiently large problems. Since GPU architectures and programming languages are rapidly evolving, we expect that GPUs will be an increasingly attractive tool for matrix computation in the future},
  keywords     = {Cholesky factorization; matrix decomposition; forward and back substitution; rectangular packed format},
  owner        = {andrea},
  publisher    = {Kent State University, Department of Mathematics and Computer Science},
  timestamp    = {2014.12.12},
}

@Article{Kabir2015,
  author       = {Khairul Kabir and Azzam Haidar and Stanimire Tomov and Jack Dongarra},
  title        = {Performance Analysis and Optimisation of Two-Sided Fractorization Algorithms for Heterogeneous Platform},
  journaltitle = {Procedia Computer Science},
  date         = {2015},
  volume       = {51},
  pages        = {180--190},
  doi          = {10.1016/j.procs.2015.05.222},
  abstract     = {Many applications, ranging from big data analytics to nanostructure designs, require the solution of large dense singular value decomposition (SVD) or eigenvalue problems. A first step in the solution methodology for these problems is the reduction of the matrix at hand to condensed form by two-sided orthogonal transformations. This step is standardly used to significantly accelerate the solution process. We present a performance analysis of the main two-sided factorizations used in these reductions: the bidiagonalization, tridiagonalization, and the upper Hessenberg factorizations on heterogeneous systems of multicore CPUs and Xeon Phi coprocessors. We derive a performance model and use it to guide the analysis and to evaluate performance. We develop optimized implementations for these methods that get up to 80\% of the optimal performance bounds. Finally, we describe the heterogeneous multicore and coprocessor development considerations and the techniques that enable us to achieve these high-performance results. The work here presents the first highly optimized implementation of these main factorizations for Xeon Phi coprocessors. Compared to the LAPACK versions optmized by Intel for Xeon Phi (in MKL), we achieve up to 50\% speedup.},
  owner        = {andrea},
  timestamp    = {2016.05.27},
}

@InProceedings{Kaleem2016,
  Title                    = {Synchronization Trade-Offs in {GPU} Implementations of Graph Algorithms},
  Author                   = {Rashid Kaleem and Anand Venkat and Sreepathi Pai and Mary Hall and Keshav Pingali},
  Booktitle                = {{P}roceedings of the 30th {I}nternational {P}arallel and {D}istributed {P}rocessing {S}ymposium},
  Month                    = may,
  Pages                    = {514--523},
  Series                   = {IPDPS '16},

 abstract = {Although there is an extensive literature on GPU implementations of graph algorithms, we do not yet have a clear understanding of how implementation choices impact performance. As a step towards this goal, we studied how the choice of synchronization mechanism affects the end-to-end performance of complex graph algorithms, using stochastic gradient descent (SGD) as an exemplar. We implemented seven synchronization strategies for this application and evaluated them on two GPU platforms, using both road networks and social network graphs as inputs. Our experiments showed that although none of the seven strategies dominates the rest, it is possible to use properties of the platform and input graph to predict the best strategy.},
  Date                     = {2016},
  Doi                      = {10.1109/IPDPS.2016.106},
  ISSN                     = {1530-2075},
  Keywords                 = {gradient methods;graph theory;graphics processing units;stochastic processes;synchronisation;GPU implementations;SGD;graph algorithms;graphics processing unit;road networks;social network graphs;stochastic gradient descent;synchronization trade-offs;Graphics processing units;Instruction sets;Motion pictures;Roads;Schedules;Sparse matrices;Synchronization;Edge-coloring;GPGPU;Scheduling;Stochastic Gradient Descent},
  Location                 = {Chicago, IL, USA}
}

@TechReport{Kamvar2003,
  Title                    = {Exploiting the Block Structure of the Web for Computing PageRank},
  Author                   = {Sepandar Kamvar and Taher Haveliwala and Christopher Manning and Gene Golub},
  Institution              = {InfoLab, Stanford University},
  Number                   = {2003--17},

 abstract = {The web link graph has a nested block structure: the vast majority of hyperlinks link pages on a host to other pages on the same host, and many of those that do not link pages within the same domain. We show how to exploit this structure to speed up the computation of PageRank by a 3-stage algorithm whereby (1)\textasciitilde{}the local PageRanks of pages for each host are computed independently using the link structure of that host, (2)\textasciitilde{}these local PageRanks are then weighted by the ``importance'' of the corresponding host, and (3)\textasciitilde{}the standard PageRank algorithm is then run using as its starting vector the weighted aggregate of the local PageRanks. Empirically, this algorithm speeds up the computation of PageRank by a factor of 2 in realistic scenarios. Further, we develop a variant of this algorithm that efficiently computes many different ``personalized'' PageRanks, and a variant that efficiently recomputes PageRank after node updates.},
  Date                     = {2003},
  Publisher                = {Stanford},
  Url                      = {http://ilpubs.stanford.edu:8090/579/}
}

@Article{Karypis1999,
  author       = {George Karypis and Vipin Kumar},
  title        = {A fast and high quality multilevel scheme for partitioning irregular graphs},
  journaltitle = {{SIAM} Journal on scientific Computing},
  date         = {1999},
  volume       = {20},
  number       = {1},
  pages        = {359--392},
  doi          = {10.1137/S1064827595287997},
  abstract     = {Recently, a number of researchers have investigated a class of graph partitioning algorithms that reduce the size of the graph by collapsing vertices and edges, partition the smaller graph, and then uncoarsen it to construct a partition for the original graph [Bui and Jones, Proc. of the 6th SIAM Conference on Parallel Processing for Scientific Computing, 1993, 445--452; Hendrickson and Leland, A Multilevel Algorithm for Partitioning Graphs, Tech. report SAND 93-1301, Sandia National Laboratories, Albuquerque, NM, 1993]. From the early work it was clear that multilevel techniques held great promise; however, it was not knownif they can be made to consistently produce high quality partitions for graphs arising in a wide range of application domains. We investigate the effectiveness of many different choices for all three phases: coarsening, partition of the coarsest graph, and refinement. In particular, we present a new coarsening heuristic (called heavy-edge heuristic) for which the size of the partition of the coarse graph is within a small factor of the size of the final partition obtained after multilevel refinement. We also present a much faster variation of the Kernighan--Lin (KL) algorithm for refining during uncoarsening. We test our scheme on a large number of graphs arising in various domains including finite element methods, linear programming, VLSI, and transportation. Our experiments show that our scheme produces partitions that are consistently better than those produced by spectral partitioning schemes in substantially smaller time. Also, when our scheme is used to compute fill-reducing orderings for sparse matrices, it produces orderings that have substantially smaller fill than the widely used multiple minimum degree algorithm.},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@InProceedings{Kayiran2013,
  author    = {Kayıran, Onur and Jog, Adwait and Kandemir, Mahmut Taylan and Das, Chita Ranjan},
  title     = {Neither More nor Less: Optimizing Thread-level Parallelism for {GPGPU}s},
  booktitle = {{P}roceedings of the 22nd {I}nternational {C}onference on {P}arallel {A}rchitectures and {C}ompilation {T}echniques},
  date      = {2013},
  series    = {PACT '13},
  publisher = {IEEE Press},
  location  = {Edinburgh, UK},
  isbn      = {978-1-4799-1021-2},
  pages     = {157--166},
  url       = {http://dl.acm.org/citation.cfm?id=2523721.2523745},
  abstract  = {General-purpose graphics processing units (GPGPUs) are at their best in accelerating computation by exploiting abundant thread-level parallelism (TLP) offered by many classes of HPC applications. To facilitate such high TLP, emerging programming models like CUDA and OpenCL allow programmers to create work abstractions in terms of smaller work units, called cooperative thread arrays (CTAs). CTAs are groups of threads and can be executed in any order, thereby providing ample opportunities for TLP. The state-of-the-art GPGPU schedulers allocate maximum possible CTAs per-core (limited by available on-chip resources) to enhance performance by exploiting TLP. However, we demonstrate in this paper that executing the maximum possible number of CTAs on a core is not always the optimal choice from the performance perspective. High number of concurrently executing threads might cause more memory requests to be issued, and create contention in the caches, network and memory, leading to long stalls at the cores. To reduce resource contention, we propose a dynamic CTA scheduling mechanism, called DYNCTA, which modulates the TLP by allocating optimal number of CTAs, based on application characteristics. To minimize resource contention, DYNCTA allocates fewer CTAs for applications suffering from high contention in the memory sub-system, compared to applications demonstrating high throughput. Simulation results on a 30-core GPGPU platform with 31 applications show that the proposed CTA scheduler provides 28\% average improvement in performance compared to the existing CTA scheduler.},
  acmid     = {2523745},
  address   = {Piscataway, NJ, USA},
  keywords  = {GPGPUs, scheduling, thread-level parallelism},
  numpages  = {10},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@InProceedings{Kelman2011,
  author    = {Kelman, A. and Borrelli, F.},
  title     = {Bilinear Model Predictive Control of a HVAC System Using Sequential Quadratic Programming},
  booktitle = {{P}roceedings of the 18th {IFAC} {W}orld {C}ongress},
  date      = {2011},
  series    = {IFAC '11},
  location  = {Milan, IT},
  doi       = {10.3182/20110828-6-IT-1002.03811},
  abstract  = {We study the problem of heating, ventilation, and air conditioning (HVAC) control in a typical commercial building. We propose a model predictive control (MPC) approach which minimizes energy use while satisfying occupant comfort constraints. A sequential quadratic programming algorithm is used to efficiently solve the resulting bilinear optimization problem. This paper presents the control design approach and the procedure for computing its solution. Extensive numerical simulations show the effectiveness of the proposed approach. In particular, the MPC is able to systematically reproduce a variety of well-known commercial solutions for energy savings, which include demand response, economizer mode and precooling/preheating.},
  owner     = {ap8213},
  timestamp = {2014.05.18},
}

@InProceedings{Kerrigan2015,
  author    = {Eric C. Kerrigan},
  title     = {Feedback and Time are Important for the Optimal Control of Computing Systems},
  booktitle = {{P}roceedings of the 5th {IFAC} {C}onference on {N}onlinear {M}odel {P}redictive {C}ontrol},
  date      = {2015},
  series    = {NMPC '15},
  location  = {Seville, ES},
  month     = sep,
  doi       = {10.1016/j.ifacol.2015.11.309},
  abstract  = {The performance, reliability, cost, size and energy usage of computing systems can be improved by one or more orders of magnitude by the systematic use of modern control and optimization methods. Computing systems rely on the use of feedback algorithms to schedule tasks, data and resources, but the models that are used to design these algorithms are validated using open-loop metrics. By using closed-loop metrics instead, such as the gap metric developed in the control community, it should be possible to develop improved scheduling algorithms and computing systems that have not been over-engineered. Furthermore, scheduling problems are most naturally formulated as constraint satisfaction or mathematical optimization problems, but these are seldom implemented using state of the art numerical methods, nor do they explicitly take into account the fact that the scheduling problem itself takes time to solve. This paper makes the case that recent results in real-time model predictive control, where optimization problems are solved in order to control a process that evolves in time, are likely to form the basis of scheduling algorithms of the future. We therefore outline some of the research problems and opportunities that could arise by explicitly considering feedback and time when designing optimal scheduling algorithms for computing systems.},
  owner     = {andrea},
  timestamp = {2015.04.24},
}

@InProceedings{Khorasani2014,
  Title                    = {{CuSha}: Vertex-centric Graph Processing on {GPUs}},
  Author                   = {Khorasani, Farzad and Vora, Keval and Gupta, Rajiv and Bhuyan, Laxmi N.},
  Booktitle                = {{P}roceedings of the 23rd {I}nternational {S}ymposium on {H}igh-performance {P}arallel and {D}istributed {C}omputing},

  Address                  = {New York, NY, USA},
  Pages                    = {239--252},
  Publisher                = {ACM},
  Series                   = {HPDC '14},

 abstract = {Vertex-centric graph processing is employed by many popular algorithms (e.g., PageRank) due to its simplicity and efficient use of asynchronous parallelism. The high compute power provided by SIMT architecture presents an opportunity for accelerating these algorithms using GPUs. Prior works of graph processing on a GPU employ Compressed Sparse Row (CSR) form for its space-efficiency; however, CSR suffers from irregular memory accesses and GPU underutilization that limit its performance. In this paper, we present CuSha, a CUDA-based graph processing framework that overcomes the above obstacle via use of two novel graph representations: G-Shards and Concatenated Windows (CW). G-Shards uses a concept recently introduced for non-GPU systems that organizes a graph into autonomous sets of ordered edges called shards. CuSha's mapping of GPU hardware resources on to shards allows fully coalesced memory accesses. CW is a novel representation that enhances the use of shards to achieve higher GPU utilization for processing sparse graphs. Finally, CuSha fully utilizes the GPU power by processing multiple shards in parallel on GPU's streaming multiprocessors. For ease of programming, CuSha allows the user to define the vertex-centric computation and plug it into its framework for parallel processing of large graphs. Our experiments show that CuSha provides significant speedups over the state-of-the-art CSR-based virtual warp-centric method for processing graphs on GPUs.},
  Acmid                    = {2600227},
  Date                     = {2014},
  Doi                      = {10.1145/2600212.2600227},
  ISBN                     = {978-1-4503-2749-7},
  Keywords                 = {coalesced memory accesses, concatenated windows, g-shards, gpu, graph representation},
  Location                 = {Vancouver, BC, CA},
  Numpages                 = {14}
}

@TechReport{Knijnenburg1994,
  Title                    = {On Improving Data Locality in Sparse Matrix Computations},
  Author                   = {Peter M. W Knijnenburg and Harry A. G. Wijshoff},
  Institution              = {High Performance Computing Division, Dept. of Computer Science, Leiden University},

 abstract = {Sparse matrix computations and irregular type computations show poor data locality behavior. Recently compiler optimizations techniques have been proposed to improve the data locality for regular type loop structures. Sparse matrix computations do not fall into this categorie of computations and the issue of compiler optimizations for sparse computations is merely understood. In this paper we describe how compiler optimizations based on pattern matching techniques can be used to improve the data locality behavior for sparse computations.},
  Date                     = {1994},
  Url                      = {http://liacs.leidenuniv.nl/assets/PDF/TechRep/tr94-15.pdf}
}

@Article{Knyazev2007,
  author       = {Knyazev, Andrew V and Lashuk, Ilya},
  title        = {Steepest descent and conjugate gradient methods with variable preconditioning},
  journaltitle = {{SIAM} Journal on Matrix Analysis and Applications},
  date         = {2007},
  volume       = {29},
  number       = {4},
  pages        = {1267--1280},
  doi          = {10.1137/060675290},
  abstract     = {We analyze the conjugate gradient (CG) method with variable preconditioning for solving a linear system with a real symmetric positive definite (SPD) matrix of coefficients A. We assume that the preconditioner is SPD on each step, and that the condition number of the preconditioned system matrix is bounded above by a constant independent of the step number. We show that the CG method with variable preconditioning under this assumption may not give improvement, compared to the steepest descent (SD) method. We describe the basic theory of CG methods with variable preconditioning with the emphasis on worst case scenarios, and provide complete proofs of all facts not available in the literature. We give a new elegant geometric proof of the SD convergence rate bound. Our numerical experiments, comparing the preconditioned SD and CG methods, not only support and illustrate our theoretical findings, but also reveal two surprising and potentially practically important effects. First, we analyze variable preconditioning in the form of inner-outer iterations. In previous such tests, the unpreconditioned CG inner iterations are applied to an artificial system with some fixed preconditioner as a matrix of coefficients. We test a different scenario, where the unpreconditioned CG inner iterations solve linear systems with the original system matrix A. We demonstrate that the CG-SD inner-outer iterations perform as well as the CG-CG inner-outer iterations in these tests. Second, we compare the CG methods using a two-grid preconditioning with fixed and randomly chosen coarse grids, and observe that the fixed preconditioner method is twice as slow as the method with random preconditioning.},
  owner        = {andrea},
  publisher    = {SIAM},
  timestamp    = {2017.05.08},
}

@Article{Koch2011,
  Title                    = {{MIPLIB} 2010},
  Author                   = {Thorsten Koch and Tobias Achterberg and Erling Andersen and Oliver Bastert and Timo Berthold and Robert E. Bixby and Emilie Danna and Gerald Gamrath and Ambros M. Gleixner and Stefan Heinz and Andrea Lodi and Hans Mittelmann and Ted Ralphs and Domenico Salvagnin and Daniel E. Steffy and Kati Wolter},
  Number                   = {2},
  Pages                    = {103--163},
  Volume                   = {3},

 abstract = {This paper reports on the fifth version of the Mixed Integer Programming Library. The miplib 2010 is the first miplib release that has been assembled by a large group from academia and from industry, all of whom work in integer programming. There was mutual consent that the concept of the library had to be expanded in order to fulfill the needs of the community. The new version comprises 361 instances sorted into several groups. This includes the main benchmark test set of 87 instances, which are all solvable by today's codes, and also the challenge test set with 164 instances, many of which are currently unsolved. For the first time, we include scripts to run automated tests in a predefined way. Further, there is a solution checker to test the accuracy of provided solutions using exact arithmetic.},
  Date                     = {2011},
  Doi                      = {10.1007/s12532-011-0025-9},
  Journaltitle             = {Mathematical Programming Computation},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07}
}

@Article{Koch2012,
  Title                    = {Could we use a million cores to solve an integer program?},
  Author                   = {Koch, Thorsten and Ralphs, Ted and Shinano, Yuji},
  Number                   = {1},
  Pages                    = {67--93},
  Volume                   = {76},

 abstract = {Given the steady increase in cores per CPU, it is only a matter of time before supercomputers will have a million or more cores. In this article, we investigate the opportunities and challenges that will arise when trying to utilize this vast computing power to solve a single integer linear optimization problem. We also raise the question of whether best practices in sequential solution of ILPs will be effective in massively parallel environments.},
  Date                     = {2012},
  Doi                      = {10.1007/s00186-012-0390-9},
  ISSN                     = {1432-5217},
  Journaltitle             = {Mathematical Methods of Operations Research}
}

@Article{Kreutzer2014,
  Title                    = {A Unified Sparse Matrix Data Format for Efficient General Sparse Matrix-Vector Multiplication on Modern Processors with Wide {SIMD} Units},
  Author                   = {Moritz Kreutzer and Georg Hazen and Gerhard Wellein and Holger Fehske and Alan R. Bishop},
  Number                   = {5},
  Pages                    = {C401--C423},
  Volume                   = {36},

 abstract = {Sparse matrix-vector multiplication (spMVM) is the most time-consuming kernel in many numerical algorithms and has been studied extensively on all modern processor and accelerator architectures. However, the optimal sparse matrix data storage format is highly hardware-specific, which could become an obstacle when using heterogeneous systems. Also, it is as yet unclear how the wide single instruction multiple data (SIMD) units in current multi- and many-core processors should be used most efficiently if there is no structure in the sparsity pattern of the matrix. We suggest SELL-$C$-$\sigma$, a variant of Sliced ELLPACK, as a SIMD-friendly data format which combines long-standing ideas from general-purpose graphics processing units and vector computer programming. We discuss the advantages of SELL-$C$-$\sigma$ compared to established formats like Compressed Row Storage and ELLPACK and show its suitability on a variety of hardware platforms (Intel Sandy Bridge, Intel Xeon Phi, and Nvidia Tesla K20) for a wide range of test matrices from different application areas. Using appropriate performance models we develop deep insight into the data transfer properties of the SELL-$C$-$\sigma$ spMVM kernel. SELL-$C$-$\sigma$ comes with two tuning parameters whose performance impact across the range of test matrices is studied and for which reasonable choices are proposed. This leads to a hardware-independent (``catch-all'') sparse matrix format, which achieves very high efficiency for all test matrices across all hardware platforms.},
  Date                     = {2014},
  Doi                      = {10.1137/130930352},
  Journaltitle             = {{SIAM} Journal on Scientific Computing},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07}
}

@Article{Kreutzer2016,
  Title                    = {{GHOST}: Building Blocks for High Performance Sparse Linear Algebra on Heterogeneous Systems},
  Author                   = {Kreutzer, Moritz and Thies, Jonas and Röhrig-Zöllner, Melven and Pieper, Andreas and Shahzad, Faisal and Galgon, Martin and Basermann, Achim and Fehske, Holger and Hager, Georg and Wellein, Gerhard},
  Pages                    = {1--27},

 abstract = {While many of the architectural details of future exascale-class high performance computer systems are still a matter of intense research, there appears to be a general consensus that they will be strongly heterogeneous, featuring standard as well as accelerated resources. Today, such resources are available as multicore processors, graphics processing units (GPUs), and other accelerators such as the Intel Xeon Phi. Any software infrastructure that claims usefulness for such environments must be able to meet their inherent challenges: massive multi-level parallelism, topology, asynchronicity, and abstraction. The General, Hybrid, and Optimized Sparse Toolkit (GHOST) is a collection of building blocks that targets algorithms dealing with sparse matrix representations on current and future large-scale systems. It implements the MPI+X paradigm, has a pure C interface, and provides hybrid-parallel numerical kernels, intelligent resource management, and truly heterogeneous parallelism for multicore CPUs, Nvidia GPUs, and the Intel Xeon Phi. We describe the details of its design with respect to the challenges posed by modern heterogeneous supercomputers and recent algorithmic developments. Implementation details which are indispensable for achieving high efficiency are pointed out and their necessity is justified by performance measurements or predictions based on performance models. We also provide instructions on how to make use of GHOST in existing software packages, together with a case study which demonstrates the applicability and performance of GHOST as a component within a larger software stack. The library code and several applications are available as open source.},
  Date                     = {2016},
  Doi                      = {10.1007/s10766-016-0464-z},
  ISSN                     = {1573-7640},
  Journaltitle             = {International Journal of Parallel Programming},
  Owner                    = {andrea},
  Timestamp                = {2017.05.02}
}

@InProceedings{Kulkarni2009a,
  Title                    = {Lonestar: A suite of parallel irregular programs},
  Author                   = {M. Kulkarni and M. Burtscher and C. Cascaval and K. Pingali},
  Booktitle                = {{P}roceedings of the 2009 {IEEE} {I}nternational {S}ymposium on {P}erformance {A}nalysis of {S}ystems and {S}oftware},
  Month                    = apr,
  Pages                    = {65--76},
  Series                   = {ISPASS '09},

 abstract = {Until recently, parallel programming has largely focused on the exploitation of data-parallelism in dense matrix programs. However, many important application domains, including meshing, clustering, simulation, and machine learning, have very different algorithmic foundations: they require building, computing with, and modifying large sparse graphs. In the parallel programming literature, these types of applications are usually classified as irregular applications, and relatively little attention has been paid to them. To study and understand the patterns of parallelism and locality in sparse graph computations better, we are in the process of building the Lonestar benchmark suite. In this paper, we characterize the first five programs from this suite, which target domains like data mining, survey propagation, and design automation. We show that even such irregular applications often expose large amounts of parallelism in the form of amorphous data-parallelism. Our speedup numbers demonstrate that this new type of parallelism can successfully be exploited on modern multi-core machines.},
  Date                     = {2009},
  Doi                      = {10.1109/ISPASS.2009.4919639},
  Keywords                 = {data mining;graph theory;parallel programming;Lonestar;amorphous data-parallelism;data mining;design automation;parallel irregular programming;sparse graph;survey propagation;Buildings;Clustering algorithms;Computational modeling;Concurrent computing;Data mining;Machine learning;Machine learning algorithms;Parallel processing;Parallel programming;Sparse matrices},
  Location                 = {Boston, MA, USA}
}

@InProceedings{Kulkarni2009,
  Title                    = {How Much Parallelism is There in Irregular Applications?},
  Author                   = {Kulkarni, Milind and Burtscher, Martin and Inkulu, Rajeshkar and Pingali, Keshav and Caşcaval, Călin},
  Booktitle                = {{P}roceedings of the 14th {ACM SIGPLAN} {S}ymposium on {P}rinciples and {P}ractice of {P}arallel {P}rogramming},

  Address                  = {New York, NY, USA},
  Pages                    = {3--14},
  Publisher                = {ACM},
  Series                   = {PPoPP '09},

 abstract = {Irregular programs are programs organized around pointer-based data structures such as trees and graphs. Recent investigations by the Galois project have shown that many irregular programs have a generalized form of data-parallelism called amorphous data-parallelism. However, in many programs, amorphous data-parallelism cannot be uncovered using static techniques, and its exploitation requires runtime strategies such as optimistic parallel execution. This raises a natural question: how much amorphous data-parallelism actually exists in irregular programs? \\In this paper, we describe the design and implementation of a tool called ParaMeter that produces parallelism profiles for irregular programs. Parallelism profiles are an abstract measure of the amount of amorphous data-parallelism at different points in the execution of an algorithm, independent of implementation-dependent details such as the number of cores, cache sizes, load-balancing, etc. ParaMeter can also generate constrained parallelism profiles for a fixed number of cores. We show parallelism profiles for seven irregular applications, and explain how these profiles provide insight into the behavior of these applications.},
  Acmid                    = {1504181},
  Date                     = {2009},
  Doi                      = {10.1145/1504176.1504181},
  ISBN                     = {978-1-60558-397-6},
  Keywords                 = {optimistic parallelism, parallelism profiles, profiling},
  Location                 = {Raleigh, NC, USA},
  Numpages                 = {12}
}

@Article{Kurzak2013,
  author       = {Kurzak, J. and Luszczek, P. and Faverge, M. and Dongarra, J.},
  title        = {{LU} Factorization with Partial Pivoting for a Multicore System with Accelerators},
  journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
  date         = {2013},
  volume       = {24},
  number       = {8},
  month        = aug,
  pages        = {1613--1621},
  issn         = {1045-9219},
  doi          = {10.1109/TPDS.2012.242},
  abstract     = {LU factorization with partial pivoting is a canonical numerical procedure and the main component of the high performance LINPACK benchmark. This paper presents an implementation of the algorithm for a hybrid, shared memory, system with standard CPU cores and GPU accelerators. The difficulty of implementing the algorithm for such a system lies in the disproportion between the computational power of the CPUs, compared to the GPUs, and in the meager bandwidth of the communication link between their memory systems. An additional challenge comes from the complexity of the memory-bound and synchronization-rich nature of the panel factorization component of the block LU algorithm, imposed by the use of partial pivoting. The challenges are tackled with the use of a data layout geared toward complex memory hierarchies, autotuning of GPU kernels, fine-grain parallelization of memory-bound CPU operations and dynamic scheduling of tasks to different devices. Performance in excess of one TeraFLOPS is achieved using four AMD Magny Cours CPUs and four NVIDIA Fermi GPUs.},
  keywords     = {graphics processing units;multiprocessing systems;parallel processing;scheduling;shared memory systems;AMD Magny Cours CPU;CPU core;GPU accelerator;LU factorization;NVIDIA Fermi GPU;block LU algorithm;canonical numerical procedure;data layout;dynamic task scheduling;fine-grain parallelization;graphics processing unit;high performance LINPACK benchmark;memory hierarchy;memory-bound CPU operation;multicore system;panel factorization component;partial pivoting;shared memory system;Dynamic scheduling;Graphics processing unit;Kernel;Layout;Libraries;Plasmas;Tiles;Dynamic scheduling;GPU;Gaussian elimination;Graphics processing unit;Kernel;LU factorization;Layout;Libraries;Plasmas;Tiles;accelerator;manycore;multicore;partial pivoting},
  owner        = {ap8213},
  timestamp    = {2014.10.09},
}

@InProceedings{Lain1995,
  Title                    = {Exploiting Spatial Regularity in Irregular Iterative Applications},
  Author                   = {Lain, Antonio and Banerjee, Prithviraj},
  Booktitle                = {{P}roceedings of the 9th {I}nternational {S}ymposium on {P}arallel {P}rocessing},

  Address                  = {Washington, DC, USA},
  Pages                    = {820--826},
  Publisher                = {{IEEE} Computer Society},
  Series                   = {IPPS '95},

 abstract = {The increasing gap between the speed of microprocessors and memory subsystems makes it imperative to exploit locality of reference in sequential irregular applications. The parallelization of such applications requires special considerations. Current RTS (Run-Time Support) for irregular computations fails to exploit the fine grain regularity present in these applications, producing unnecessary time and memory overheads. PILAR (Parallel Irregular Library with Application of Regularity) is a new RTS for irregular computations that provides a variety of internal representations of communication patterns based on their regularity; allowing for the efficient support of a wide spectrum of regularity under a common framework. Experimental results on the IBM SP-1 and Intel Paragon demonstrate the validity of our approach.},
  Acmid                    = {663225},
  Date                     = {1995},
  ISBN                     = {0-8186-7074-6},
  Keywords                 = {IBM SP-1, Intel Paragon, PILAR, Parallel Irregular Library, Run-Time Support, communication patterns, computational geometry, irregular iterative applications, parallel processing, performance evaluation, sequential irregular applications, spatial regularity},
  Location                 = {Santa Barbara, CA, USA},
  Numpages                 = {7},
  Url                      = {http://dl.acm.org/citation.cfm?id=645605.663225&preflayout=tabs}
}

@InProceedings{Lalami2011a,
  author     = {Mohammed Esseghir Lalami and Vincent Boyer and Didier El-Baz},
  title      = {Efficient Implementation of the Simplex Method on a {CPU}--{GPU} System},
  booktitle  = {{P}roceedings of the 2011 {IEEE} {I}nternational {P}arallel and {D}istributed {P}rocessing {S}ymposium},
  date       = {2011},
  series     = {IPDPS '11},
  location   = {Anchorage, AL, USA},
  month      = may,
  isbn       = {978-1-61284-425-1},
  pages      = {1999--2006},
  doi        = {10.1109/IPDPS.2011.362},
  abstract   = {The Simplex algorithm is a well known method to solve linear programming (LP) problems. In this paper, we propose a parallel implementation of the Simplex on a CPU-GPU systems via CUDA. Double precision implementation is used in order to improve the quality of solutions. Computational tests have been carried out on randomly generated instances for non-sparse LP problems. The tests show a maximum speedup of 12:5 on a GTX 260 board.},
  annotation = {{I}n this paper the authors present their implementation of the revised tableau simplex method with {CUDA}, which does not use existing libraries. {T}he basic idea of the work is to decompose the tableau into blocks, in such a way that each block is assigned to a thread block (or work-group, in {O}pen{CL} jargon) during the pivoting phase. {T}he software is tested on randomly generated instances of a size up to $4000$ constraints and $4000$ variables. {B}ecause of the size of problems and the employment of double precision data representation, it takes more to determine the pivot element on the {GPU} than on the {CPU}. {C}ommunication between the host and the accelerator is done using page-locked host memory. {T}he test environment is an {I}ntel {X}eon {CPU} ($\unit[3.0]{GHz}$) and an {N}vidia {GTX} 260 {GPU}. {T}he achieved speedup with respect to the same algorithm implemented on {CPU} is about $12$.},
  file       = {:home/andrea/Dropbox/PhD/Papers/Lalami et al. - Efficient Implementation of the Simplex Method on a CPU-GPU system.pdf:PDF},
  owner      = {ap8213},
  timestamp  = {2014.10.09},
}

@InProceedings{Lalami2012,
  author    = {Mohammed Esseghir Lalami and Didier El-Baz},
  title     = {{GPU} Implementation of the Branch and Bound Method for Knapsack Problems},
  booktitle = {{P}roceedings of the 26th {IEEE} {I}nternational {P}arallel and {D}istributed {P}rocessing {S}ymposium {W}orkshops and {P}h{D} {F}orum},
  date      = {2012},
  series    = {IPDPSW '12},
  location  = {Shanghai, CN},
  pages     = {1769--1777},
  doi       = {10.1109/IPDPSW.2012.219},
  abstract  = {In this paper, we propose an efficient implementation of the branch and bound method for knapsack problems on a CPU-GPU system via CUDA. Branch and bound computations can be carried out either on the CPU or on a GPU according to the size of the branch and bound list. A better management of GPUs memories, less GPU-CPU communications and better synchronization between GPU threads are proposed in this new implementation in order to increase efficiency. Indeed, a series of computational results is displayed and analyzed showing a substantial speedup on a Tesla C2050 GPU.},
  keywords  = {graphics processing units;knapsack problems;parallel architectures;tree searching;CPU-GPU system;CUDA;GPU-CPU communications;Tesla C2050 GPU;branch and bound method;knapsack problems;Central Processing Unit;Computer architecture;Graphics processing unit;Instruction sets;Kernel;Optimization;Upper bound;CUDA;GPU computing;branch and bound method;combinatorial optimization;hybrid computing;knapsack problems},
  owner     = {ap8213},
  timestamp = {2014.10.09},
}

@InProceedings{Lalami2011,
  author    = {Mohammed Esseghir Lalami and Didier El-Baz and Vincent Boyer},
  title     = {Multi {GPU} Implementation of the Simplex Algorithm},
  booktitle = {{P}roceedings of the 13th {IEEE} {I}nternational {C}onference on {H}igh {P}erformance {C}omputing and {C}ommunications},
  date      = {2011},
  series    = {HPCC '11},
  location  = {Banff, AB, CA},
  month     = sep,
  pages     = {179--186},
  doi       = {10.1109/HPCC.2011.32},
  abstract  = {The Simplex algorithm is a well known method to solve linear programming (LP) problems. In this paper, we propose an implementation via CUDA of the Simplex method on a multi GPU architecture. Computational tests have been carried out on randomly generated instances for non-sparse LP problems. The tests show a maximum speedup of 24.5 with two Tesla C2050 boards.},
  keywords  = {computer graphic equipment;coprocessors;linear programming;multiprocessing systems;parallel architectures;CUDA;Tesla C2050 boards;computational tests;linear programming;multi GPU architecture;nonsparse LP problem;randomly generated instances;simplex method;Computer architecture;Graphics processing unit;Indexes;Instruction sets;Kernel;Linear programming;Synchronization;CUDA;GPU computing;Simplex method;hybrid computing;linear programming;parallel computing},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Article{Langr2016,
  author       = {Langr, Daniel and Tvrdik, Pavel},
  title        = {Evaluation Criteria for Sparse Matrix Storage Formats},
  journaltitle = {{IEEE}Transactions on Parallel and Distributed Systems},
  date         = {2016},
  volume       = {27},
  number       = {2},
  month        = feb,
  pages        = {428--440},
  issn         = {1045-9219},
  doi          = {10.1109/TPDS.2015.2401575},
 abstract = {When authors present new storage formats for sparse matrices, they usually focus mainly on a single evaluation criterion, which is the performance of sparse matrix-vector multiplication (SpMV) in FLOPS. Though such an evaluation is essential, it does not allow to directly compare the presented format with its competitors. Moreover, in case that matrices are within an HPC application constructed in different formats, this criterion alone is not sufficient for the key decision whether or not to convert them into the presented format for the SpMV-based application phase. We establish ten evaluation criteria for sparse matrix storage formats, discuss their advantages and disadvantages, and provide general suggestions for format authors/evaluators to make their work more valuable for the HPC community.},
  acmid        = {2914075},
  issue_date   = {February 2016},
  location     = {Piscataway, NJ, USA},
  numpages     = {13},
  publisher    = {IEEE Press},
}

@Book{Lawson1995,
  Title                    = {Solving Least Squares Problems},
  Author                   = {Lawson, C. and Hanson, R.},
  Publisher                = {Society for Industrial and Applied Mathematics},

  Date                     = {1995},
  Doi                      = {10.1137/1.9781611971217},
  Eprint                   = {http://epubs.siam.org/doi/pdf/10.1137/1.9781611971217}
}

@InProceedings{Lee2014,
  Title                    = {{CAWS}: Criticality-aware Warp Scheduling for {GPGPU} Workloads},
  Author                   = {Lee, Shin-Ying and Wu, Carole-Jean},
  Booktitle                = {{P}roceedings of the 23rd {I}nternational {C}onference on {P}arallel {A}rchitectures and {C}ompilation},

  Address                  = {New York, NY, USA},
  Pages                    = {175--186},
  Publisher                = {ACM},
  Series                   = {PACT '14},

 abstract = {The ability to perform fast context-switching and massive multi-threading is the forte of modern GPU architectures, which have emerged as an efficient alternative to traditional chip-multiprocessors for parallel workloads. One of the main benefits of such architecture is its latency-hiding capability. However, the efficacy of GPU's latency-hiding varies significantly across GPGPU applications. \\To investigate this, this paper first proposes a new algorithm that profiles execution behavior of GPGPU applications. We characterize latencies caused by various pipeline hazards, memory accesses, synchronization primitives, and the warp scheduler. Our results show that the current round-robin warp scheduler works well in overlapping various latency stalls with the execution of other available warps for only a few GPGPU applications. For other applications, there is an excessive latency stall that cannot be hidden by the scheduler effectively. With the latency characterization insight, we observe a significant execution time disparity for warps within the same thread block, which causes sub-optimal performance, called the warp criticality problem. \\To tackle the warp criticality problem, we design a family of criticality-aware warp scheduling (CAWS) policies by scheduling the critical warp(s) more frequently than other warps. Our results on the breadth-first-search, B+tree search, two point angular correlation function, and K-means clustering show that, with oracle knowledge of warp criticality, our best-performing scheduling policy can improve GPGPU applications' performance by 17\% on average. With our designed criticality predictor, the various scheduling policies can improve performance by 10-21\% on breadth-first-search. To our knowledge, this is the first paper to characterize warp criticality and explore different criticality-aware warp scheduling policies for GPGPU workloads.},
  Acmid                    = {2628107},
  Date                     = {2014},
  Doi                      = {10.1145/2628071.2628107},
  ISBN                     = {978-1-4503-2809-8},
  Keywords                 = {gpgpu, gpu performance characterization, warp/wavefront scheduling},
  Location                 = {Edmonton, AB, CA},
  Numpages                 = {12},
  Owner                    = {andrea},
  Timestamp                = {2016.09.07}
}

@InProceedings{Lee2010,
  Title                    = {Debunking the 100X {GPU} vs. {CPU} Myth: An Evaluation of Throughput Computing on {CPU} and {GPU}},
  Author                   = {Lee, Victor W. and Kim, Changkyu and Chhugani, Jatin and Deisher, Michael and Kim, Daehyun and Nguyen, Anthony D. and Satish, Nadathur and Smelyanskiy, Mikhail and Chennupaty, Srinivas and Hammarlund, Per and Singhal, Ronak and Dubey, Pradeep},
  Booktitle                = {{P}roceedings of the 37th {A}nnual {I}nternational {S}ymposium on {C}omputer {A}rchitecture},

  Address                  = {New York, NY, USA},
  Pages                    = {451--460},
  Publisher                = {ACM},
  Series                   = {ISCA '10},

 abstract = {Recent advances in computing have led to an explosion in the amount of data being generated. Processing the ever-growing data in a timely manner has made throughput computing an important aspect for emerging applications. Our analysis of a set of important throughput computing kernels shows that there is an ample amount of parallelism in these kernels which makes them suitable for today's multi-core CPUs and GPUs. In the past few years there have been many studies claiming GPUs deliver substantial speedups (between 10$\times$ and 1000$\times$) over multi-core CPUs on these kernels. To understand where such large performance difference comes from, we perform a rigorous performance analysis and find that after applying optimizations appropriate for both CPUs and GPUs the performance gap between an Nvidia GTX280 processor and the Intel Core i7-960 processor narrows to only 2.5$\times$ on average. In this paper, we discuss optimization techniques for both CPU and GPU, analyze what architecture features contributed to performance differences between the two architectures, and recommend a set of architectural features which provide significant improvement in architectural efficiency for throughput kernels.},
  Acmid                    = {1816021},
  Date                     = {2010},
  Doi                      = {10.1145/1815961.1816021},
  ISBN                     = {978-1-4503-0053-7},
  Keywords                 = {cpu architecture, gpu architecture, performance analysis, performance measurement, software optimization, throughput computing},
  Location                 = {Saint-Malo, FR},
  Numpages                 = {10},
  Owner                    = {andrea},
  Timestamp                = {2016.09.07}
}

@InProceedings{LiC2015,
  Title                    = {Locality-Driven Dynamic {GPU} Cache Bypassing},
  Author                   = {Li, Chao and Song, Shuaiwen Leon and Dai, Hongwen and Sidelnik, Albert and Hari, Siva Kumar Sastry and Zhou, Huiyang},
  Booktitle                = {{P}roceedings of the 29th {ACM} {I}nternational {C}onference on {S}upercomputing},

  Address                  = {New York, NY, USA},
  Pages                    = {67--77},
  Publisher                = {ACM},
  Series                   = {ICS '15},

 abstract = {This paper presents novel cache optimizations for massively parallel, throughput-oriented architectures like GPUs. L1 data caches (L1 D-caches) are critical resources for providing high-bandwidth and low-latency data accesses. However, the high number of simultaneous requests from single-instruction multiple-thread (SIMT) cores makes the limited capacity of L1 D-caches a performance and energy bottleneck, especially for memory-intensive applications. We observe that the memory access streams to L1 D-caches for many applications contain a significant amount of requests with low reuse, which greatly reduce the cache efficacy. Existing GPU cache management schemes are either based on conditional/reactive solutions or hit-rate based designs specifically developed for CPU last level caches, which can limit overall performance. \\To overcome these challenges, we propose an efficient locality monitoring mechanism to dynamically filter the access stream on cache insertion such that only the data with high reuse and short reuse distances are stored in the L1 D-cache. Specifically, we present a design that integrates locality filtering based on reuse characteristics of GPU workloads into the decoupled tag store of the existing L1 D-cache through simple and cost-effective hardware extensions. Results show that our proposed design can dramatically reduce cache contention and achieve up to 56.8\% and an average of 30.3\% performance improvement over the baseline architecture, for a range of highly-optimized cache-unfriendly applications with minor area overhead and better energy efficiency. Our design also significantly outperforms the state-of-the-art CPU and GPU bypassing schemes (especially for irregular applications), without generating extra L2 and DRAM level contention.},
  Acmid                    = {2751237},
  Date                     = {2015},
  Doi                      = {10.1145/2751205.2751237},
  ISBN                     = {978-1-4503-3559-1},
  Location                 = {Newport Beach, CA, USA},
  Numpages                 = {11}
}

@InProceedings{LiD2015,
  Title                    = {Nested Parallelism on {GPU}: Exploring Parallelization Templates for Irregular Loops and Recursive Computations},
  Author                   = {D. Li and H. Wu and M. Becchi},
  Booktitle                = {{P}roceedings of the 44th {I}nternational {C}onference on {P}arallel {P}rocessing},
  Month                    = sep,
  Pages                    = {979--988},
  Series                   = {ICPP '15},

 abstract = {The effective deployment of applications exhibiting irregular nested parallelism on GPUs is still an open problem. A naive mapping of irregular code onto the GPU hardware often leads to resource underutilization and, thereby, limited performance. In this work, we focus on two computational patterns exhibiting nested parallelism: irregular nested loops and parallel recursive computations. In particular, we focus on recursive algorithms operating on trees and graphs. We propose different parallelization templates aimed to increase the GPU utilization of these codes. Specifically, we investigate mechanisms to effectively distribute irregular work to streaming multiprocessors and GPU cores. Some of our parallelization templates rely on dynamic parallelism, a feature recently introduced by Nvidia in their Kepler GPUs and announced as part of the Open CL 2.0 standard. We propose mechanisms to maximize the work performed by nested kernels and minimize the overhead due to their invocation. Our results show that the use of our parallelization templates on applications with irregular nested loops can lead to a 2-6$\times$ speedup over baseline GPU codes that do not include load balancing mechanisms. The use of nested parallelism-based parallelization templates on recursive tree traversal algorithms can lead to substantial speedups (up to 15-24$\times$) over optimized CPU implementations. However, the benefits of nested parallelism are still unclear in the presence of recursive applications operating on graphs, especially when recursive code variants require expensive synchronization. In these cases, a flat parallelization of iterative versions of the considered algorithms may be preferable.},
  Date                     = {2015},
  Doi                      = {10.1109/ICPP.2015.107},
  ISSN                     = {0190-3918},
  Keywords                 = {graphics processing units;iterative methods;multiprocessing systems;parallel processing;program control structures;resource allocation;synchronisation;trees (mathematics);GPU cores;GPU hardware;GPU utilization;Kepler GPUs;Nvidia;OpenCL 2.0 standard;baseline GPU codes;computational patterns;dynamic parallelism;graphs;irregular code;irregular nested loops;load balancing mechanisms;multiprocessors cores;naive mapping;nested parallelism-based parallelization templates;optimized CPU implementation;parallel recursive computations;recursive algorithms;recursive code variants;recursive tree traversal algorithms;resource underutilization;trees;Graphics processing units;Hardware;Heuristic algorithms;Instruction sets;Kernel;Load management;Parallel processing},
  Location                 = {Beijing, CN}
}

@InCollection{Li2011,
  author    = {Jianming Li and Renping Lv and Xiangpei Hu and Zhongqiang Jiang},
  title     = {A {GPU}-Based Parallel Algorithm for Large Scale Linear Programming Problem},
  booktitle = {{I}ntelligent {D}ecision {T}echnologies},
  date      = {2011},
  editor    = {Watada, J. and Phillips-Wren, G. and Jain, L. and Howlett, R. J.},
  volume    = {10},
  series    = {Smart Innovation, Systems and Technologies},
  publisher = {Springer Berlin Heidelberg},
  isbn      = {978-3-642-22193-4},
  pages     = {37--46},
  doi       = {10.1007/978-3-642-22194-1_4},
  abstract  = {A GPU-based parallel algorithm to solve large scale linear programming problem is proposed in this research. It aims to improve the computing efficiency when the linear programming problem becomes sufficiently large scale or more complicated. This parallel algorithm, based on Gaussian elimination, uses the GPU (Graphics Processing Unit) for computationally intensive tasks such as basis matrix operation, canonical form transformation and entering variable selection. At the same time, CPU is used to control the iteration. Experimental results show that the algorithm is competitive with CPU algorithm and can greatly reduce the computing time, so the GPU-based parallel algorithm is an effective way to solve large scale linear programming problem.},
  keywords  = {Linear Programming; Parallel Algorithm; GPU; CUDA (Compute Unified Device Architecture)},
  owner     = {ap8213},
  timestamp = {2014.10.09},
}

@InProceedings{Li2016,
  Title                    = {A data locality-aware design framework for reconfigurable sparse matrix-vector multiplication kernel},
  Author                   = {Sicheng Li and Y. Wang and Wujie Wen and Y. Wang and Yiran Chen and Hai Li},
  Booktitle                = {2016 {IEEE}/{ACM} {I}nternational {C}onference on {C}omputer-{A}ided {D}esign ({ICCAD})},
  Month                    = nov,
  Pages                    = {1--6},

 abstract = {Sparse matrix-vector multiplication (SpMV) is an important computational kernel in many applications. For performance improvement, software libraries designated for SpMV computation have been introduced, e.g., MKL library for CPUs and cuSPARSE library for GPUs. However, the computational throughput of these libraries is far below the peak floating-point performance offered by hardware platforms, because the efficiency of SpMV kernel is greatly constrained by the limited memory bandwidth and irregular data access patterns. In this work, we propose a data locality-aware design framework for FPGA-based SpMV acceleration. We first include the hardware constraints in sparse matrix compression at software level to regularize the memory allocation and accesses. Moreover, a distributed architecture composed of processing elements is developed to improve the computation parallelism. We implement the reconfigurable SpMV kernel on Convey HC-2ex and conduct the evaluation by using the University of Florida sparse matrix collection. The experiments demonstrate an average computational efficiency of 48.2\%, which is a lot better than those of CPU and GPU implementations. Our FPGA-based kernel has a comparable runtime as GPU, and achieves 2.1$\times$ reduction than CPU. Moreover, our design obtains substantial saving in energy consumption, say, 9.3$\times$ and 5.6$\times$ better than the implementations on CPU and GPU, respectively.},
  Date                     = {2016},
  Doi                      = {10.1145/2966986.2966987},
  Keywords                 = {energy consumption;field programmable gate arrays;floating point arithmetic;graphics processing units;mathematics computing;matrix multiplication;power aware computing;reconfigurable architectures;software libraries;sparse matrices;storage allocation;vectors;CPU implementations;CPU library;Convey HC-2ex;FPGA-based SpMV acceleration;FPGA-based kernel;GPU implementations;MKL library;SpMV kernel;University of Florida sparse matrix collection;computation parallelism;computational kernel;cuSPARSE library;data access patterns;data locality-aware design;distributed architecture;energy consumption;floating-point performance;hardware constraints;memory accesses;memory allocation;reconfigurable SpMV kernel;reconfigurable sparse matrix-vector multiplication kernel;software libraries;sparse matrix compression;Bandwidth;Hardware;Kernel;Libraries;Memory management;Runtime;Sparse matrices},
  Location                 = {Austin, TX, US}
}

@InProceedings{Liu2014,
  author    = {Junyi Liu and Helfried Peyril and Andreas Burg and George A. Constantinides},
  title     = {{FPGA}Implementation of An Interior Point Method For High-speed Model Predictive Control},
  booktitle = {{P}roceedings of the 24th {I}nternational {C}onference on {F}ield {P}rogrammable {L}ogic and {A}pplications},
  date      = {2014},
  series    = {FPL '14},
  location  = {Munich, GER},
  month     = sep,
  pages     = {1--8},
  doi       = {10.1109/FPL.2014.6927473},
  abstract  = {In this paper, we present a hardware architecture for implementing an interior point method for model predictive control (MPC) on field programmable gate arrays (FPGA). The FPGA implementation allows the solution of quadratic programs occurring in MPC at very high speed. Experiments show that our hardware implementation is able to outperform an software implementation running on a high-end CPU while consuming significantly less power making it well-suited for embedded industrial control applications. In contrast to existing FPGA implementations, the proposed solution exploits the MPC-specific problem structure with the direct linear equation solver and uses an efficient predictor-corrector algorithm. Moreover, the modular design of the architecture simplifies customization or extension to special control problem classes. The proposed FPGA solution can broaden the applicability of solving complex or large MPC problems in embedded computing platforms that were so far considered out of reach.},
  keywords  = {control system synthesis;embedded systems;field programmable gate arrays;predictive control;predictor-corrector methods;quadratic programming;velocity control;FPGA implementation;MPC-specific problem structure;direct linear equation solver;embedded computing platforms;embedded industrial control applications;hardware architecture;high-end CPU;high-speed model predictive control;interior point method;modular design;predictor-corrector algorithm;quadratic programs;Computer architecture;Equations;Field programmable gate arrays;Hardware;Optimization;Pipelines;Vectors},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Article{Liu2012,
  author       = {Liu, Li and Liu, Li and Yang, Guangwen},
  title        = {A Higly Efficient {CPU-GPU} Hybrid Parallel Implementation of Sparse {LU} Factorization},
  journaltitle = {Chinese Journal of Electronics},
  date         = {2012},
  volume       = {21},
  number       = {1},
  month        = jan,
  pages        = {7--12},
  url          = {http://www.ejournal.org.cn/Jweb_cje/CN/abstract/abstract916.shtml},
  abstract     = {In this paper, we try to accelerate sparse LU factorization on GPU. We present a tiled storage format and a parallel algorithm to improve the memory access pattern, and a register blocking method to compress the on-chip working set. The OPENMP implementation of our algorithm gives more stable performance over different matrices, and outperforms SuperLU and KLU by 1.88\textasciitilde{}6 times on an Intel 8-core CPU (Central processing unit) for matrices from the Florida matrix collection. Based on this algorithm, we further propose a GPU-CPU hybrid pipelined scheme to overlap computations on CPU with computations on GPU. Compared to the better of SuperLU and KLU on an Intel 8-core CPU, our algorithm achieves 1.1\textasciitilde{}19.7-fold speedup on GPU for double precision. Compared to the OPENMP implementation of our algorithm on an Intel 8-core CPU, our GPU implementation gets a 2-fold speedup for the best cases.},
  annotation   = {{T}he authors present two implementations of the right-looking {LU} decomposition on {O}pen{MP} and {C}+{CUDA}. {F}irst, the matrix is permuted into diagonal blocks, then it is factorised rowwise and columnwise starting from the diagonal element. {F}inally, on all the obtained blocks a right-looking update is performed. {T}he data format used is a modified version of the blocked compressed sparse column ({BCSC}) format, but for each block also a {CSR} version is stored in memory since it is convenient for the columnwise factorisation. {E}ach block is composed of 16$\times$16 entries, thus it can be associated to a {CUDA} thread block while each column or row can be processed by a half warp. {F}urther memory optimisations reduce the amount of used shared memory. {E}xperiments show that the right-looking update is the most consuming algorithmic step, so in order to obtain the best speedup two solutions are proposed. {I}n the first one every step is parallelised on multicore systems by using {O}pen{MP}, while in the second solution only the right-looking update is performed on the {GPU} and everything else is done on the {CPU} host with maximum overlap between the computations. {E}xperimental results show that performance is very sensitive with respect to the matrix in hand, but in general parallelism the performance is far from the theoretical peak flops of the machine.},
  file         = {:home/ap8213/Documents/PhD/Papers/Li et al. - A Highly Efficient GPU-CPU Hybrid Parallel Implementation of Sparse LU Factorization.pdf:PDF},
  owner        = {andrea},
  timestamp    = {2014.11.13},
}

@Article{Low2012,
  author       = {Low, Yucheng and Bickson, Danny and Gonzalez, Joseph and Guestrin, Carlos and Kyrola, Aapo and Hellerstein, Joseph M.},
  title        = {Distributed {GraphLab}: A Framework for Machine Learning and Data Mining in the Cloud},
  journaltitle = {{P}roc. {VLDB} {E}ndow.},
  date         = {2012},
  volume       = {5},
  number       = {8},
  month        = apr,
  pages        = {716--727},
  issn         = {2150-8097},
  doi          = {10.14778/2212351.2212354},
 abstract = {While high-level data parallel frameworks, like MapReduce, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the GraphLab abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the GraphLab framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees. \\We develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations.},
  acmid        = {2212354},
  issue_date   = {April 2012},
  numpages     = {12},
  publisher    = {VLDB Endowment},
}

@Article{Ma2012,
  author       = {Ma, Y. and Borrelli, F. and Hencey, B. and Coffey, B. and Bengea, S. and Haves, P.},
  title        = {Model Predictive Control for the Operation of Building Cooling Systems},
  journaltitle = {{IEEE} Transactions on Control Systems Technology},
  date         = {2012},
  volume       = {20},
  number       = {3},
  month        = may,
  pages        = {796--803},
  doi          = {10.1109/TCST.2011.2124461},
  abstract     = {This brief presents a model-based predictive control (MPC) approach to building cooling systems with thermal energy storage. We focus on buildings equipped with a water tank used for actively storing cold water produced by a series of chillers. First, simplified models of chillers, cooling towers, thermal storage tanks, and buildings are developed and validated for the purpose of model-based control design. Then an MPC for the chilling system operation is proposed to optimally store the thermal energy in the tank by using predictive knowledge of building loads and weather conditions. This brief addresses real-time implementation and feasibility issues of the MPC scheme by using a simplified hybrid model of the system, a periodic robust invariant set as terminal constraints, and a moving window blocking strategy. The controller is experimentally validated at the University of California, Merced. The experiments show a reduction in the central plant electricity cost and an improvement of its efficiency.},
  owner        = {ap8213},
  publisher    = {Institute of Electrical and Electronics Engineers},
  timestamp    = {2014.10.09},
}

@Article{Muller2009,
  author       = {C. Müller and S. Frey and M. Strengert and C. Dachsbacher and T. Ertl},
  title        = {A Compute Unified System Architecture for Graphics Clusters Incorporating Data Locality},
  journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
  date         = {2009},
  volume       = {15},
  number       = {4},
  month        = jul,
  pages        = {605--617},
  issn         = {1077--2626},
  doi          = {10.1109/TVCG.2008.188},
 abstract = {We present a development environment for distributed GPU computing targeted for multi-GPU systems, as well as graphics clusters. Our system is based on CUDA and logically extends its parallel programming model for graphics processors to higher levels of parallelism, namely, the PCI bus and network interconnects. While the extended API mimics the full function set of current graphics hardware-including the concept of global memory-on all distribution layers, the underlying communication mechanisms are handled transparently for the application developer. To allow for high scalability, in particular for network-interconnected environments, we introduce an automatic GPU-accelerated scheduling mechanism that is aware of data locality. This way, the overall amount of transmitted data can be heavily reduced, which leads to better GPU utilization and faster execution. We evaluate the performance and scalability of our system for bus and especially network-level parallelism on typical multi-GPU systems and graphics clusters.},
  comment      = {Scheduling mechanism that is aware of data-locality. Very verbose, little maths.},
}

@Article{Munz2015,
  Title                    = {Overview of recent control technologies for future power systems: An industry perspective},
  Author                   = {Ulrich Münz and Michael Metzger and Andrei Szabo and Markus Reischböck and Florian Steinke and Philipp Wolfrum and Rudolf Sollacher and Dragan Obradovic and Michael Buhl and Thomas Lehmann and Mathias Duckheim and Stefan Langemeyer},

  Month                    = nov,
  Pages                    = {869--882},

  Date                     = {2015},
  Doi                      = {10.1515/auto-2015-0047},
  Issue                    = {11},
  Journaltitle             = {Automatisierungstechnik},
  Owner                    = {andrea},
  Timestamp                = {2015.09.28}
}

@InProceedings{Malewicz2010,
  Title                    = {Pregel: A System for Large-scale Graph Processing},
  Author                   = {Malewicz, Grzegorz and Austern, Matthew H. and Bik, Aart J.C and Dehnert, James C. and Horn, Ilan and Leiser, Naty and Czajkowski, Grzegorz},
  Booktitle                = {{P}roceedings of the 2010 {ACM SIGMOD} {I}nternational {C}onference on {M}anagement of {D}ata},

  Address                  = {New York, NY, USA},
  Pages                    = {135--146},
  Publisher                = {ACM},
  Series                   = {SIGMOD '10},

 abstract = {Many practical computing problems concern large graphs. Standard examples include the Web graph and various social networks. The scale of these graphs - in some cases billions of vertices, trillions of edges - poses challenges to their efficient processing. In this paper we present a computational model suitable for this task. Programs are expressed as a sequence of iterations, in each of which a vertex can receive messages sent in the previous iteration, send messages to other vertices, and modify its own state and that of its outgoing edges or mutate graph topology. This vertex-centric approach is flexible enough to express a broad set of algorithms. The model has been designed for efficient, scalable and fault-tolerant implementation on clusters of thousands of commodity computers, and its implied synchronicity makes reasoning about programs easier. Distribution-related details are hidden behind an abstract API. The result is a framework for processing large graphs that is expressive and easy to program.},
  Acmid                    = {1807184},
  Date                     = {2010},
  Doi                      = {10.1145/1807167.1807184},
  ISBN                     = {978-1-4503-0032-2},
  Keywords                 = {distributed computing, graph algorigthms},
  Location                 = {Indianapolis, IN, USA},
  Numpages                 = {12}
}

@Article{Markowitz1957,
  author       = {Markowitz, Harry M.},
  title        = {The Elimination Form of the Inverse and Its Application to Linear Programming},
  journaltitle = {Management Science},
  date         = {1957},
  volume       = {3},
  number       = {3},
  month        = apr,
  pages        = {255--269},
  issn         = {0025-1909},
  doi          = {10.1287/mnsc.3.3.255},
  acmid        = {2769307},
  issue_date   = {April 1957},
  location     = {Institute for Operations Research and the Management Sciences (INFORMS), Linthicum, Maryland, USA},
  numpages     = {15},
  publisher    = {INFORMS},
}

@Book{Maros2003,
  Title                    = {Computational Techniques of the Simplex Method},
  Author                   = {István Maros},
  Editor                   = {Springer},
  Publisher                = {Kluwer Academic},
  Series                   = {International Series in Operations Research \& Management Science},
  Volume                   = {61},

  Date                     = {2003},
  Owner                    = {andrea},
  Timestamp                = {2014.03.05}
}

@Misc{Matlab2017a,
  author    = {{MATLAB}},
  title     = {version 9.2.0.538062 64-bit (R2017a)},
  date      = {2017},
  location  = {Natick, Massachusetts},
  publisher = {The MathWorks Inc.},
}

@Article{Mattingley2012,
  author       = {Jacob Mattingley and Stephen Boyd},
  title        = {{CVXGEN}: a code generator for embedded convex optimization},
  journaltitle = {Optimization Engineering},
  date         = {2012},
  language     = {English},
  volume       = {13},
  number       = {1},
  pages        = {1--27},
  issn         = {1389-4420},
  doi          = {10.1007/s11081-011-9176-9},
  abstract     = {CVXGEN is a software tool that takes a high level description of a convex optimization problem family, and automatically generates custom C code that compiles into a reliable, high speed solver for the problem family. The current implementation targets problem families that can be transformed, using disciplined convex programming techniques, to convex quadratic programs of modest size. CVXGEN generates simple, flat, library-free code suitable for embedding in real-time applications. The generated code is almost branch free, and so has highly predictable run-time behavior. The combination of regularization (both static and dynamic) and iterative refinement in the search direction computation yields reliable performance, even with poor quality data. In this paper we describe how CVXGEN is implemented, and give some results on the speed and reliability of the automatically generated solvers.},
  keywords     = {Convex optimization; Code generation; Embedded optimization},
  owner        = {ap8213},
  publisher    = {Springer US},
  timestamp    = {2014.10.09},
}

@Article{Mayer2009,
  author       = {Mayer, Jan},
  title        = {Parallel algorithms for solving linear systems with sparse triangular matrices},
  journaltitle = {Computing},
  date         = {2009},
  volume       = {86},
  number       = {4},
  month        = sep,
  pages        = {291--312},
  issn         = {0010-485X},
  doi          = {10.1007/s00607-009-0066-3},
 abstract = {In this article, we present two new algorithms for solving given triangular systems in parallel on a shared memory architecture. Multilevel incomplete LU factorization based preconditioners, which have been very successful for solving linear systems iteratively, require these triangular solves. Hence, the algorithms presented here can be seen as parallelizing the application of these preconditioners. The first algorithm solves the triangular matrix by block anti-diagonals. The drawback of this approach is that it can be difficult to choose an appropriate block structure. On the other hand, if a good block partition can be found, this algorithm can be quite effective. The second algorithm takes a hybrid approach by solving the triangular system by block columns and anti-diagonals. It is usually as effective as the first algorithm, but the block structure can be chosen in a nearly optimal manner. Although numerical results indicate that the speed-up can be fairly good, systems with matrices having a strong diagonal structure or narrow bandwidth cannot be solved effectively in parallel. Hence, for these matrices, the results are disappointing. On the other hand, the results are better for matrices having a more uniform distribution of non-zero elements. Although not discussed in this article, these algorithms can possibly be adapted for distributed memory architectures.},
  keywords     = {Preconditioning; Iterative methods; Sparse linear systems; Parallelization; 65F10; 65F50; 65Y05},
  owner        = {ap8213},
  publisher    = {Springer Vienna},
  timestamp    = {2015.07.22},
}

@Article{Mehrotra1992,
  author       = {Sanjay Mehrotra},
  title        = {On the Implementation of a Primal-Dual Interior Point Method},
  journaltitle = {{SIAM} Journal on Optimization},
  date         = {1992},
  volume       = {2},
  number       = {4},
  pages        = {575--601},
  doi          = {10.1137/0802028},
  abstract     = {This paper gives an approach to implementing a second-order primal-dual interior point method. It uses a Taylor polynomial of second order to approximate a primal-dual trajectory. The computations for the second derivative are combined with the computations for the centering direction. Computations in this approach do not require that primal and dual solutions be feasible. Expressions are given to compute all the higher-order derivatives of the trajectory of interest. The implementation ensures that a suitable potential function is reduced by a constant amount at each iteration. \\There are several salient features of this approach. An adaptive heuristic for estimating the centering parameter is given. The approach used to compute the step length is also adaptive. A new practical approach to compute the starting point is given. This approach treats primal and dual problems symmetrically. \\Computational results on a subset of problems available from netlib are given. On mutually tested problems the results show that the proposed method requires approximately 40 percent fewer iterations than the implementation proposed in Lustig, Marsten, and Shanno [Tech. Rep. TR J-89-11, Georgia Inst. of Technology, Atlanta, 1989]. It requires approximately 50 percent fewer iterations than the dual affine scaling method in Adler, Karmarkar, Resende, and Veiga [Math. Programming, 44 (1989), pp. 297-336], and 35 percent fewer iterations than the second-order dual affine scaling method in the same paper. The new approach for estimating the centering parameter and finding the step length and the starting point have contributed to the reduction in the number of iterations. However, the contribution due to the use of second derivative is most significant. \\On the tested problems, on the average the implementation shown was found to be approximately two times faster than OBl (version 02/90) described in Lustig, Marsten, and Shanno and 2.5 times faster than MINOS 5.3 described in Murtagh and Saunders [Tech. Rep. SOL 83-20, Dept. of Operations Research, Stanford Univ., Stanford, CA, 1983].},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@InProceedings{Melab2012,
  author    = {Melab, N. and Chakroun, I. and Mezmaz, M. and Tuyttens, D.},
  title     = {A {GPU}-accelerated Branch-and-Bound Algorithm for the Flow-Shop Scheduling Problem},
  booktitle = {{IEEE} {I}nt. {C}onf. {C}luster {C}omputing},
  date      = {2012},
  series    = {CLUSTER '12},
  location  = {Beijing, CN},
  month     = sep,
  pages     = {10--17},
  doi       = {10.1109/CLUSTER.2012.18},
  abstract  = {Branch-and-Bound (B\&B) algorithms are time-intensive tree-based exploration methods for solving to optimality combinatorial optimization problems. In this paper, we investigate the use of GPU computing as a major complementary way to speed up those methods. The focus is put on the bounding mechanism of B\&B algorithms, which is the most time consuming part of their exploration process. We propose a parallel B\&B algorithm based on a GPU-accelerated bounding model. The proposed approach concentrate on optimizing data access management to further improve the performance of the bounding mechanism which uses large and intermediate data sets that do not completely fit in GPU memory. Extensive experiments of the contribution have been carried out on well-known FSP benchmarks using an Nvidia Tesla C2050 GPU card. We compared the obtained performances to a single and a multithreaded CPU-based execution. Accelerations up to $\times$100 are achieved for large problem instances.},
  owner     = {ap8213},
  timestamp = {2014.10.09},
}

@Article{Mellor-Crummey2001,
  author       = {Mellor-Crummey, John and Whalley, David and Kennedy, Ken},
  title        = {Improving Memory Hierarchy Performance for Irregular Applications Using Data and Computation Reorderings},
  journaltitle = {International Journal of Parallel Programming},
  date         = {2001},
  volume       = {29},
  number       = {3},
  month        = jun,
  pages        = {217--247},
  issn         = {0885-7458},
  doi          = {10.1023/A:1011119519789},
 abstract = {The performance of irregular applications on modern computer systems is hurt by the wide gap between CPU and memory speeds because these applications typically under-utilize multi-level memory hierarchies, which help hide this gap. This paper investigates using data and computation reorderings to improve memory hierarchy utilization for irregular applications. We evaluate the impact of reordering on data reuse at different levels in the memory hierarchy. We focus on coordinated data and computation reordering based on space-filling curves and we introduce a new architecture-independent multi-level blocking strategy for irregular applications. For two particle codes we studied, the most effective reorderings reduced overall execution time by a factor of two and four, respectively. Preliminary experience with a scatter benchmark derived from a large unstructured mesh application showed that careful data and computation ordering reduced primary cache misses by a factor of two compared to a random ordering.},
  acmid        = {608774},
  issue_date   = {June 2001},
  keywords     = {computation reordering, data reordering, memory hierarchy optimization, multi-level blocking, space-filling curves},
  location     = {Norwell, MA, USA},
  numpages     = {31},
  publisher    = {Kluwer Academic Publishers},
}

@Article{Merrill2012,
  author       = {Merrill, Duane and Garland, Michael and Grimshaw, Andrew},
  title        = {Scalable {GPU} Graph Traversal},
  journaltitle = {{ACM SIGPLAN} Notices},
  date         = {2012},
  volume       = {47},
  number       = {8},
  month        = feb,
  pages        = {117--128},
  issn         = {0362-1340},
  doi          = {10.1145/2370036.2145832},
 abstract = {Breadth-first search (BFS) is a core primitive for graph traversal and a basis for many higher-level graph analysis algorithms. It is also representative of a class of parallel computations whose memory accesses and work distribution are both irregular and data-dependent. Recent work has demonstrated the plausibility of GPU sparse graph traversal, but has tended to focus on asymptotically inefficient algorithms that perform poorly on graphs with non-trivial diameter. \\We present a BFS parallelization focused on fine-grained task management constructed from efficient prefix sum that achieves an asymptotically optimal $O(|V|+|E|)$ work complexity. Our implementation delivers excellent performance on diverse graphs, achieving traversal rates in excess of 3.3 billion and 8.3 billion traversed edges per second using single and quad-GPU configurations, respectively. This level of performance is several times faster than state-of-the-art implementations both CPU and GPU platforms.},
  acmid        = {2145832},
  issue_date   = {August 2012},
  keywords     = {GPU, breadth-first search, cooperative allocation, graph algorithms, graph traversal, parallel algorithms, prefix sum, sparse graph},
  location     = {New York, NY, USA},
  numpages     = {12},
  publisher    = {ACM},
}

@InProceedings{Meyer2011,
  author    = {Xavier Meyer and Paul Albuquerque and Bastien Chopard},
  title     = {A multi-{GPU} implementation and performance model for the standard simplex method},
  booktitle = {{P}roceedings of the 1st {I}nternational {S}ymposium and 10th {B}alkan {C}onference on {O}perational {R}esearch},
  date      = {2011},
  series    = {BALCOR '11},
  location  = {Thessaloniki, GR},
  month     = sep,
  pages     = {312--319},
  url       = {http://spc.unige.ch/lib/exe/fetch.php?media=pub:sgpu_europar2011.pdf},
  abstract  = {The standard simplex method is a well-known optimization algorithm for solving linear programming models in the field of operational research. It is part of software that is often employed by businesses for solving scheduling or assignment problems. But their always increasing complexity and size drives the demand for more computational power.In the past few years, GPUs have gained a lot of popularity as they offer an opportunity to accelerate many algorithms. In this paper we present a mono and a multi-GPU implementation of the standard simplex method, which is based on CUDA. Measurements show that it outperforms the CLP solver provided the problem size is large enough. We also derive a performance model and establish its accurateness. To our knowledge, only the revised simplex method has so far been implemented on a GPU.},
  file      = {:home/andrea/Dropbox/PhD/Papers/Meyer et al. - A multi-GPU implementation and performance model for the standard simplex method.pdf:PDF},
  owner     = {ap8213},
  timestamp = {2014.03.27},
}

@InBook{Meyer2013,
  author    = {Xavier Meyer and Bastien Chopard and Paul Albuquerque},
  title     = {Linear programming on a {GPU}: a case study},
  booktitle = {{D}esigning {S}cientific {A}pplications on {GPU}s},
  date      = {2013},
  editor    = {Raphaël Couturier},
  series    = {Numerical Analysis and Scientific Computing},
  publisher = {Chapman \& Hall/CRC Press},
  isbn      = {9781466571624},
  chapter   = {10},
  pages     = {215--249},
  file      = {:home/andrea/Dropbox/PhD/Papers/Meyer et al. - Linear programming on GPUs A case of study - 2013.pdf:PDF},
  owner     = {ap8213},
  timestamp = {2014.03.27},
}

@Book{Mitchell1998,
  author    = {Mitchell, M.},
  title     = {An introduction to genetic algorithms},
  date      = {1998},
  publisher = {The {MIT} Press},
  owner     = {ap8213},
  timestamp = {2014.03.25},
}

@InProceedings{Mocanu2013,
  author    = {Adrian Mocanu and Nicolae Ţăpuş},
  title     = {Sparse matrix permutations to a Block Triangular Form in a distributed environment},
  booktitle = {{IEEE} {I}nternational {C}onference on {I}ntelligent {C}omputer {C}ommunication and {P}rocessing},
  date      = {2013},
  series    = {ICCP '13},
  location  = {Lyon, FR},
  month     = sep,
  pages     = {331--338},
  doi       = {10.1109/ICCP.2013.6646131},
  abstract  = {Arranging the sparse circuit matrix into a diagonal block upper triangular form is the first step of the KLU algorithm. This paper presents the two steps of the parallel algorithm, running in a distributed environment, that performs unsymmetric and symmetric permutations of the matrix's rows. First, using the [Duff] maximum transversal algorithm and performing asymmetrical permutations, the matrix is shaped to achieve a zero free diagonal. Then, searching the strongly connected components of the associated matrix's graph, and performing symmetric permutation, the sparse matrix is shaped in a diagonal block upper triangular form. Both algorithm and architecture are presented.},
  keywords  = {graph theory;parallel algorithms;sparse matrices;Duff maximum transversal algorithm;KLU algorithm;associated matrix graph;asymmetrical permutation;diagonal block upper triangular form;distributed environment;parallel algorithm;sparse circuit matrix permutation;symmetric permutation;unsymmetric permutation;Algorithm design and analysis;Bipartite graph;Computer architecture;Mathematical model;Matrix converters;Sparse matrices;Symmetric matrices},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@InProceedings{Monakov2010,
  Title                    = {Automatically Tuning Sparse Matrix-Vector Multiplication for {GPU} Architectures},
  Author                   = {Monakov, Alexander and Lokhmotov, Anton and Avetisyan, Arutyun},
  Booktitle                = {{H}igh {P}erformance {E}mbedded {A}rchitectures and {C}ompilers},

  Address                  = {Berlin, Heidelberg},
  Editor                   = {Patt, Yale N. and Foglia, Pierfrancesco and Duesterwald, Evelyn and Faraboschi, Paolo and Martorell, Xavier},
  Pages                    = {111--125},
  Publisher                = {Springer Berlin Heidelberg},
  Series                   = {Lecture Notes in Computer Science},

 abstract = {Graphics processors are increasingly used in scientific applications due to their high computational power, which comes from hardware with multiple-level parallelism and memory hierarchy. Sparse matrix computations frequently arise in scientific applications, for example, when solving PDEs on unstructured grids. However, traditional sparse matrix algorithms are difficult to efficiently parallelize for GPUs due to irregular patterns of memory references. In this paper we present a new storage format for sparse matrices that better employs locality, has low memory footprint and enables automatic specialization for various matrices and future devices via parameter tuning. Experimental evaluation demonstrates significant speedups compared to previously published results.},
  Booksubtitle             = {HiPEAC '10},
  Date                     = {2010},
  Doi                      = {10.1007/978-3-642-11515-8_10},
  ISBN                     = {978-3-642-11515-8},
  Location                 = {Pisa, IT},
  Url                      = {http://dx.doi.org/10.1007/978-3-642-11515-8_10}
}

@Online{Mujtaba2015,
  Title                    = {{NVIDIA} Pascal {GPU}'s Double Precision Performance Rated at Over 4 {TFLOPs}, 16nm {FinFET} Architecture Confirmed -- Volta {GPU} Peaks at Over 7 {TFLOPs}, 1.2 {TB/s} {HBM2}},
  Author                   = {Hassan Mujtaba},
  Date                     = {2015},
  Month                    = nov,
  Url                      = {http://wccftech.com/nvidia-pascal-volta-gpus-sc15/},

  Note                     = {Accessed 20 July 2016},

  Journaltitle             = {WCCFtech.com},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07}
}

@Online{Mujtaba2016,
  Title                    = {{NVIDIA} Pascal {GP100} {GPU} Expected To Feature 12 {TFLOPs} of Single Precision Compute, 4 {TFLOPs} of Double Precision Compute Performance},
  Author                   = {Hassan Mujtaba},
  Date                     = {2016},
  Month                    = feb,
  Url                      = {http://wccftech.com/nvidia-pascal-gp100-gpu-compute-performance/},

  Note                     = {Accessed 20 July 2016},

  Journaltitle             = {WCCFtech.com},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07}
}

@InProceedings{Mukherjee1995,
  Title                    = {Efficient Support for Irregular Applications on Distributed-memory Machines},
  Author                   = {Mukherjee, Shubhendu S. and Sharma, Shamik D. and Hill, Mark D. and Larus, James R. and Rogers, Anne and Saltz, Joel},
  Booktitle                = {{P}roceedings of the {F}ifth {ACM SIGPLAN} {S}ymposium on {P}rinciples and {P}ractice of {P}arallel {P}rogramming},

  Address                  = {New York, NY, USA},
  Pages                    = {68--79},
  Publisher                = {ACM},
  Series                   = {PPoPP '95},

 abstract = {Irregular computation problems underlie many important scientific applications. Although these problems are computationally expensive, and so would seem appropriate for parallel machines, their irregular and unpredictable run-time behavior makes this type of parallel program difficult to write and adversely affects run-time performance.This paper explores three issues partitioning, mutual exclusion, and data transfer crucial to the efficient execution of irregular problems on distributed-memory machines. Unlike previous work, we studied the same programs running in three alternative systems on the same hardware base (a Thinking Machines CM-5): the CHAOS irregular application library, Transparent Shared Memory (TSM), and eXtensible Shared Memory (XSM). CHAOS and XSM performed equivalently for all three applications. Both systems were somewhat (13\%) to significantly faster (991\%) than TSM.},
  Acmid                    = {209945},
  Date                     = {1995},
  Doi                      = {10.1145/209936.209945},
  ISBN                     = {0-89791-700-6},
  Location                 = {Santa Barbara, CA, USA},
  Numpages                 = {12}
}

@InProceedings{Munawar2011,
  author    = {Asim Munawar and Mohamed Wahib and Mahasaru Munetomo and Kiyoshi Akama},
  title     = {Advanced Genetic Algorithm to solve {MINLP} problems over {GPU}},
  booktitle = {{P}roceedings of the {IEEE} {C}ongress on {E}volutionary {C}omputation},
  date      = {2011},
  series    = {CEC '11},
  location  = {New Orleans, LA, USA},
  month     = jun,
  pages     = {318--325},
  doi       = {10.1109/CEC.2011.5949635},
  abstract  = {In this paper we propose a many-core implementation of evolutionary computation for GPGPU (General-Purpose Graphic Processing Unit) to solve non-convex Mixed Integer Non-Linear Programming (MINLP) and non-convex Non Linear Programming (NLP) problems using a stochastic algorithm. Stochastic algorithms being random in their behavior are difficult to implement over GPU like architectures. In this paper we not only succeed in implementation of a stochastic algorithm over GPU but show considerable speedups over CPU implementations. The stochastic algorithm considered for this paper is an adaptive resolution approach to genetic algorithm (arGA), developed by the authors of this paper. The technique uses the entropy measure of each variable to adjust the intensity of the genetic search around promising individuals. Performance is further improved by hybridization with adaptive resolution local search (arLS) operator. In this paper, we describe the challenges and design choices involved in parallelization of this algorithm to solve complex MINLPs over a commodity GPU using Compute Unified Device Architecture (CUDA) programming model. Results section shows several numerical tests and performance measurements obtained by running the algorithm over an nVidia Fermi GPU. We show that for difficult problems we can obtain a speedup of up to 20$\times$ with double precision and up to 42$\times$ with single precision.},
  keywords  = {computer graphic equipment;coprocessors;genetic algorithms;integer programming;nonlinear programming;parallel algorithms;parallel architectures;stochastic processes;CPU implementations;GPGPU;GPU like architectures;MINLP problems;adaptive resolution local search operator;advanced genetic algorithm;compute unified device architecture programming model;evolutionary computation;general-purpose graphic processing unit;many-core implementation;nVidia Fermi GPU;nonconvex mixed integer nonlinear programming;parallelization;stochastic algorithm;Algorithm design and analysis;Entropy;Genetic algorithms;Genetics;Graphics processing unit;Kernel;Stochastic processes;Adaptive Resolution Genetic Algorithm;Compute Unified Device Architecture (CUDA);General-Purpose computation on Graphics Processing Units (GPGPU);Parallel Genetic Algorithms},
  owner     = {ap8213},
  timestamp = {2014.10.09},
}

@InProceedings{Nasre2013,
  author    = {Nasre, Rupesh and Burtscher, Martin and Pingali, Keshav},
  title     = {Atomic-free Irregular Computations on {GPUs}},
  booktitle = {{P}roceedings of the 6th {W}orkshop on {G}eneral {P}urpose {P}rocessor {U}sing {G}raphics {P}rocessing {U}nits},
  date      = {2013},
  series    = {GPGPU-6},
  publisher = {ACM},
  location  = {Houston, Texas, USA},
  isbn      = {978-1-4503-2017-7},
  pages     = {96--107},
  doi       = {10.1145/2458523.2458533},
 abstract = {Atomic instructions are a key ingredient of codes that operate on irregular data structures like trees and graphs. It is well known that atomics can be expensive, especially on massively parallel GPUs, and are often on the critical path of a program. In this paper, we present two high-level methods to eliminate atomics in irregular programs. The first method advocates synchronous processing using barriers. We illustrate how to exploit synchronous processing to avoid atomics even when the threads' memory accesses conflict with each other. The second method is based on exploiting algebraic properties of algorithms to elide atomics. Specifically, we focus on three key properties: monotonicity, idempotency and associativity, and show how each of them enables an atomic-free implementation. We illustrate the generality of the two methods by applying them to five irregular graph applications: breadth-first search, single-source shortest paths computation, Delaunay mesh refinement, pointer analysis and survey propagation, and show that both methods provide substantial speedup in each case on different GPUs.},
  acmid     = {2458533},
  address   = {New York, NY, USA},
  comment   = {Comparison between the use of barriers and atomics on GPUs. For atomics, the use of "algebraic properties" is discussed.},
  keywords  = {GPGPU, atomic-free, graph algorithms, irregular algorithms},
  numpages  = {12},
}

@InProceedings{Nasre2013a,
  author    = {Nasre, Rupesh and Burtscher, Martin and Pingali, Keshav},
  title     = {Data-Driven Versus Topology-driven Irregular Computations on {GPUs}},
  booktitle = {{P}roceedings of the 27th {IEEE} {I}nternational {S}ymposium on {P}arallel and {D}istributed {P}rocessing},
  date      = {2013},
  series    = {IPDPS '13},
  publisher = {{IEEE} Computer Society},
  location  = {Boston, MA, US},
  isbn      = {978-0-7695-4971-2},
  pages     = {463--474},
  doi       = {10.1109/IPDPS.2013.28},
 abstract = {Irregular algorithms are algorithms with complex main data structures such as directed and undirected graphs, trees, etc. A useful abstraction for many irregular algorithms is its operator formulation in which the algorithm is viewed as the iterated application of an operator to certain nodes, called active nodes, in the graph. Each operator application, called an activity, usually touches only a small part of the overall graph, so nonoverlapping activities can be performed in parallel. In topology-driven implementations, all nodes are assumed to be active so the operator is applied everywhere in the graph even if there is no work to do at some nodes. In contrast, in data-driven implementations the operator is applied only to nodes at which there might be work to do. Multicore implementations of irregular algorithms are usually data-driven because current multicores only support small numbers of threads and work-efficiency is important. Conversely, many irregular GPU implementations use a topology-driven approach because work inefficiency can be counterbalanced by the large number of GPU threads. In this paper, we study data-driven and topology-driven implementations of six important graph algorithms on GPUs. Our goal is to understand the tradeoffs between these implementations and how to optimize them. We find that data-driven versions are generally faster and scale better despite the cost of maintaining a worklist. However, topology-driven versions can be superior when certain algorithmic properties are exploited to optimize the implementation. These results led us to devise hybrid approaches that combine the two techniques and outperform both of them.},
  acmid     = {2511363},
  address   = {Washington, DC, USA},
  comment   = {Using Pingali's work on "The Tao of Parallelism in Algorithms", shows that there can be topolgy-driven and data-driven implementations.},
  keywords  = {irregular algorithms, data-driven, topology-driven, algorithmic properties, GPGPU},
  numpages  = {12},
}

@TechReport{Naumov2011,
  Title                    = {Parallel Solution of Sparse Triangular Linear Systems in the Preconditioned Iterative Methods on the {GPU}},
  Author                   = {Maxim Naumov},
  Institution              = {NVIDIA Corporation},
  Month                    = jun,
  Number                   = {2011--001},
  Type                     = {Technical report},

 abstract = {A novel algorithm for solving in parallel a sparse triangular linear system on a graphical processing unit is proposed. It implements the solution of the triangular system in two phases. First, the analysis phase builds a dependency graph based on the matrix sparsity pattern and groups the independent rows into levels. Second, the solve phase obtains the full solution by iterating sequentially across the constructed levels. The solution elements corresponding to each single level are obtained at once in parallel. The numerical experiments are also presented and it is shown that the incomplete-LU and Cholesky preconditioned iterative methods, using the parallel sparse triangular solve algorithm, can achieve on average more than 2$\times$ speedup on graphical processing units (GPUs) over their CPU implementation.},
  Date                     = {2011},
  Organization             = {NVIDIA},
  Owner                    = {andrea},
  Timestamp                = {2014.07.27},
  Url                      = {http://research.nvidia.com/sites/default/files/publications/nvr-2011-001.pdf}
}

@InProceedings{Nelson2014,
  Title                    = {Grappa: A Latency-Tolerant Runtime for Large-Scale Irregular Applications},
  Author                   = {Jacob Nelson and Brandon Holt and Brandon Myers and Preston Briggs and Luis Ceze and Simon Kahan and Mark Oskin},
  Booktitle                = {{P}roceedings of the {I}nternational {W}orkshop on {R}ack-{S}cale {C}omputing},
  Month                    = apr,
  Series                   = {WRSC '14},

 abstract = {Grappa is a runtime system for commodity clusters of multicore computers that presents a massively parallel, single address space abstraction to applications. Grappa's purpose is to enable scalable performance of irregular parallel applications, such as branch and bound optimization, SPICE circuit simulation, and graph processing. Poor data locality, imbalanced parallel work and complex communication patterns make scaling these applications difficult. \\Grappa serves both as a C++ user library and as a foundation for higher level languages. Grappa tolerates delays to remote memory by multiplexing thousands of lightweight workers to each processor core, balances load via fine-grained distributed work-stealing, increases communication throughput by aggregating smaller data requests into large ones, and provides efficient synchronization and remote operations. We present a detailed description of the Grappa system and performance comparisons on several irregular benchmarks to hand-optimized MPI code and to the Cray XMT, a custom system used to target the real-time graph-analytics market. We find Grappa to be 9$\times$ faster than MPI on a random access microbenchmark, between 3.5$\times$ and 5.4$\times$ slower than MPI on applications, and between 2.6$\times$ faster and 4.4$\times$ slower than the XMT.},
  Date                     = {2014},
  Location                 = {Amsterdam, NL},
  Owner                    = {andrea},
  Timestamp                = {2017.05.08},
  Url                      = {ftp://trout.cs.washington.edu/tr/2014/02/UW-CSE-14-02-01.PDF}
}

@Article{Neves2017,
  author       = {Neves, Diogo Telmo},
  title        = {{EPIC}: A framework to exploit parallelism in irregular codes},
  journaltitle = {Concurrency and Computation - Practice \& Experience},
  date         = {2017},
  language     = {{English}},
  volume       = {29},
  number       = {2},
  month        = jan,
  issn         = {{1532-0626}},
  doi          = {10.1002/cpe.3842},
  abstract     = {To harness the performance potential of current multicore processors, a multitude of algorithms, frameworks and libraries have been developed. Nevertheless, it is still extremely difficult to take advantage of the full potential of multicore processors. Moreover, when using third-party tools and/or in the presence of asymmetric sets of tasks, this problem would only aggravate. The EPIC framework was developed to ease the exploitation of task parallelism in irregular applications that use third-party tools and/or generate asymmetric sets of tasks. It is based on a software design and implements two algorithms that, together, allow, in a seamlessly way, the efficient exploitation of coarse-grained parallelism, fine-grained parallelism, and the combination of both of these types. Thus, it becomes possible to make a better and transparent usage of the performance potential of current multicore processors on shared-memory systems. In this paper, we present two refinements to the EPIC framework: one that refines the software design of the EPIC framework and another that refines the scheduling algorithm of the EPIC framework. Together, these refinements allow to cope with a special class of sets of tasks: sets of tasks where asymmetry is insignificant or can be neglected. Thus, these refinements broaden the applicability of the EPIC framework to a large class of irregular applications where task parallelism can be exploited. To assess the feasibility and the benefit of using this new version of the EPIC framework to exploit task parallelism, we used four real-world irregular applications three from phylogenetics and another from astrophysics and several input data sets with different characteristics. Our studies show groundbreaking results in terms of the achieved speedups and that scalability is not impaired, even when using third-party tools and/or in the presence of (a)symmetric sets of tasks.},
  location     = {{111 RIVER ST, HOBOKEN 07031-5774, NJ USA}},
  owner        = {andrea},
  publisher    = {{WILEY-BLACKWELL}},
  timestamp    = {2017.05.08},
  type         = {{Article}},
}

@InProceedings{Nguyen2013,
  Title                    = {A Lightweight Infrastructure for Graph Analytics},
  Author                   = {Nguyen, Donald and Lenharth, Andrew and Pingali, Keshav},
  Booktitle                = {{P}roceedings of the 24th {ACM} {S}ymposium on {O}perating {S}ystems {P}rinciples},

  Address                  = {New York, NY, USA},
  Pages                    = {456--471},
  Publisher                = {ACM},
  Series                   = {SOSP '13},

 abstract = {Several domain-specific languages (DSLs) for parallel graph analytics have been proposed recently. In this paper, we argue that existing DSLs can be implemented on top of a general-purpose infrastructure that (i) supports very fine-grain tasks, (ii) implements autonomous, speculative execution of these tasks, and (iii) allows application-specific control of task scheduling policies. To support this claim, we describe such an implementation called the Galois system. \\We demonstrate the capabilities of this infrastructure in three ways. First, we implement more sophisticated algorithms for some of the graph analytics problems tackled by previous DSLs and show that end-to-end performance can be improved by orders of magnitude even on power-law graphs, thanks to the better algorithms facilitated by a more general programming model. Second, we show that, even when an algorithm can be expressed in existing DSLs, the implementation of that algorithm in the more general system can be orders of magnitude faster when the input graphs are road networks and similar graphs with high diameter, thanks to more sophisticated scheduling. Third, we implement the APIs of three existing graph DSLs on top of the common infrastructure in a few hundred lines of code and show that even for power-law graphs, the performance of the resulting implementations often exceeds that of the original DSL systems, thanks to the lightweight infrastructure.},
  Acmid                    = {2522739},
  Date                     = {2013},
  Doi                      = {10.1145/2517349.2522739},
  ISBN                     = {978-1-4503-2388-8},
  Location                 = {Farminton, PA, USA},
  Numpages                 = {16}
}

@Book{Nocedal2006,
  author      = {Nocedal, J. and Wright, S.J.},
  title       = {Numerical Optimization},
  date        = {2006},
  edition     = {2nd},
  publisher   = {Springer},
  location    = {New York},
  ad_theotech = {General},
  owner       = {ap8213},
  remark      = {Section 8.2 gives a short introduction to automatic differentiation},
  timestamp   = {2014.10.09},
}

@Article{Notay2000,
  author       = {Yvan Notay},
  title        = {Flexible Conjugate Gradients},
  journaltitle = {{SIAM} Journal on Scientific Computing},
  date         = {2000},
  volume       = {22},
  number       = {4},
  pages        = {1444--1460},
  doi          = {10.1137/S1064827599362314},
  abstract     = {We analyze the conjugate gradient (CG) method with preconditioning slightly variable from one iteration to the next. To maintain the optimal convergence properties, we consider a variant proposed by Axelsson that performs an explicit orthogonalization of the search directions vectors. For this method, which we refer to as flexible CG, we develop a theoretical analysis that shows that the convergence rate is essentially independent of the variations in the preconditioner as long as the latter are kept sufficiently small. We further discuss the real convergence rate on the basis of some heuristic arguments supported by numerical experiments. Depending on the eigenvalue distribution corresponding to the fixed reference preconditioner, several situations have to be distinguished. In some cases, the convergence is as fast with truncated versions of the algorithm or even with the standard CG method, whereas quite large variations are allowed without too much penalty. In other cases, the flexible variant effectively outperforms the standard method, while the need for truncation limits the size of the variations that can be reasonably allowed.},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@Manual{Osier1993,
  Title                    = {{GNU} gprof},
  Author                   = {Osier, J.},
  Month                    = jan,
  Organization             = {Free Software Foundation, Inc.},

  Date                     = {1993},
  Owner                    = {ap8213},
  Timestamp                = {2014.03.04},
  Url                      = {https://ftp.gnu.org/old-gnu/Manuals/gprof-2.9.1/html_chapter/gprof_1.html}
}

@Book{Papadimitriou1982,
  author    = {Papadimitriou, Christos H. and Steiglitz, Kenneth},
  title     = {Combinatorial Optimization: Algorithms and Complexity},
  date      = {1982},
  publisher = {Prentice-Hall, Inc.},
  location  = {Upper Saddle River, NJ, USA},
  isbn      = {0-13-152462-3},
  owner     = {ap8213},
  timestamp = {2015.10.06},
}

@Article{Pedram2014,
  author       = {Ardavan Pedram and Andreas Gerstlauer and Robert A. van de Geijn},
  title        = {Algorithm, Architecture, and Floating-Point Unit Codesign of a Matrix Factorization Accelerator},
  journaltitle = {{IEEE} Transactions on Computers},
  date         = {2014},
  volume       = {63},
  number       = {8},
  issn         = {0018-9340},
  doi          = {10.1109/TC.2014.2315627},
  abstract     = {This paper examines the mapping of algorithms encountered when solving dense linear systems and linear least-squares problems to a custom Linear Algebra Processor. Specifically, the focus is on Cholesky, LU (with partial pivoting), and QR factorizations and their blocked algorithms. As part of the study, we expose the benefits of redesigning floating point units and their surrounding data-paths to support these complicated operations. We show how adding moderate complexity to the architecture greatly alleviates complexities in the algorithm. We study design tradeoffs and the effectiveness of architectural modifications to demonstrate that we can improve power and performance efficiency to a level that can otherwise only be expected of full-custom ASIC designs. A feasibility study of inner kernels is extended to blocked level and shows that, at block level, the Linear Algebra Core (LAC) can achieve high efficiencies with up to 45 GFLOPS/W for both Cholesky and LU factorization, and over 35 GFLOPS/W for QR factorization. While maintaining such efficiencies, our extensions to the MAC units can achieve up to 10, 12, and 20 percent speedup for the blocked algorithms of Cholesky, LU, and QR factorization, respectively.},
  location     = {Los Alamitos, CA, USA},
  owner        = {andrea},
  publisher    = {IEEE Computer Society},
  timestamp    = {2017.05.08},
}

@Online{Picciau2016a,
  author = {Andrea Picciau},
  date   = {2016},
  title  = {Smart building optimisation problems},
  url    = {https://github.com/andpic/smart-building-optimisation},
  note   = {Git repository, Accessed 10 May 2017},
}

@Article{Pingali2011,
  author       = {Pingali, Keshav and Nguyen, Donald and Kulkarni, Milind and Burtscher, Martin and Hassaan, M. Amber and Kaleem, Rashid and Lee, Tsung-Hsien and Lenharth, Andrew and Manevich, Roman and Méndez-Lojo, Mario and Prountzos, Dimitrios and Sui, Xin},
  title        = {The Tao of Parallelism in Algorithms},
  journaltitle = {{ACM} {SIGPLAN} Notices},
  date         = {2011},
  volume       = {46},
  number       = {6},
  month        = jun,
  pages        = {12--25},
  issn         = {0362-1340},
  doi          = {10.1145/1993316.1993501},
 abstract = {For more than thirty years, the parallel programming community has used the dependence graph as the main abstraction for reasoning about and exploiting parallelism in "regular" algorithms that use dense arrays, such as finite-differences and FFTs. In this paper, we argue that the dependence graph is not a suitable abstraction for algorithms in new application areas like machine learning and network analysis in which the key data structures are "irregular" data structures like graphs, trees, and sets. \\To address the need for better abstractions, we introduce a data-centric formulation of algorithms called the operator formulation in which an algorithm is expressed in terms of its action on data structures. This formulation is the basis for a structural analysis of algorithms that we call tao-analysis. Tao-analysis can be viewed as an abstraction of algorithms that distills out algorithmic properties important for parallelization. It reveals that a generalized form of data-parallelism called amorphous data-parallelism is ubiquitous in algorithms, and that, depending on the tao-structure of the algorithm, this parallelism may be exploited by compile-time, inspector-executor or optimistic parallelization, thereby unifying these seemingly unrelated parallelization techniques. Regular algorithms emerge as a special case of irregular algorithms, and many application-specific optimization techniques can be generalized to a broader context. \\These results suggest that the operator formulation and tao-analysis of algorithms can be the foundation of a systematic approach to parallel programming.},
  acmid        = {1993501},
  issue_date   = {June 2011},
  keywords     = {amorphous data-parallelism, galois system, irregular programs, operator formulation, tao-analysis},
  location     = {New York, NY, USA},
  numpages     = {14},
  owner        = {andrea},
  publisher    = {ACM},
  timestamp    = {2017.05.02},
}

@Article{Ploskas2013,
  author       = {Nikolaos Ploskas and Nikolaos Samaras},
  title        = {A Computational Comparison of Basis Updating Schemes for the Simplex Algorithm on a {CPU}-{GPU} System},
  journaltitle = {American Journal of Operations Research},
  date         = {2013},
  volume       = {3},
  number       = {6},
  month        = nov,
  pages        = {497--505},
  doi          = {10.4236/ajor.2013.36048},
  abstract     = {The computation of the basis inverse is the most time-consuming step in simplex type algorithms. This inverse does not have to be computed from scratch at any iteration, but updating schemes can be applied to accelerate this calculation. In this paper, we perform a computational comparison in which the basis inverse is computed with five different updating schemes. Then, we propose a parallel implementation of two updating schemes on a CPU-GPU System using MATLAB and CUDA environment. Finally, a computational study on randomly generated full dense linear programs is presented to establish the practical value of GPU-based implementation.},
  owner        = {andrea},
  timestamp    = {2014.12.13},
}

@Manual{Poulson2015,
  Title                    = {Elemental Manual},
  Author                   = {Jack Poulson},

  Date                     = {2015},
  Owner                    = {andrea},
  Timestamp                = {2017.05.10},
  Url                      = {http://libelemental.org/documentation/elem-0.85.pdf},
  Version                  = {0.84}
}

@InProceedings{Prountzos2015,
  Title                    = {Synthesizing Parallel Graph Programs via Automated Planning},
  Author                   = {Prountzos, Dimitrios and Manevich, Roman and Pingali, Keshav},
  Booktitle                = {{P}roceedings of the 36th {ACM SIGPLAN} {C}onference on {P}rogramming {L}anguage {D}esign and {I}mplementation},

  Address                  = {New York, NY, USA},
  Pages                    = {533--544},
  Publisher                = {ACM},
  Series                   = {PLDI '15},

 abstract = {We describe a system that uses automated planning to synthesize correct and efficient parallel graph programs from high-level algorithmic specifications. Automated planning allows us to use constraints to declaratively encode program transformations such as scheduling, implementation selection, and insertion of synchronization. Each plan emitted by the planner satisfies all constraints simultaneously, and corresponds to a composition of these transformations. In this way, we obtain an integrated compilation approach for a very challenging problem domain. We have used this system to synthesize parallel programs for four graph problems: triangle counting, maximal independent set computation, preflow-push maxflow, and connected components. Experiments on a variety of inputs show that the synthesized implementations perform competitively with hand-written, highly-tuned code.},
  Acmid                    = {2737953},
  Date                     = {2015},
  Doi                      = {10.1145/2737924.2737953},
  ISBN                     = {978-1-4503-3468-6},
  Keywords                 = {Amorphous Data-parallelism, Compiler Optimization, Concurrency, Irregular Programs, Parallelism, Synthesis},
  Location                 = {Portland, OR, USA},
  Numpages                 = {12}
}

@InProceedings{Reguly2012,
  Title                    = {Efficient sparse matrix-vector multiplication on cache-based {GPUs}},
  Author                   = {I. Reguly and M. Giles},
  Booktitle                = {{P}roceedings of {I}nnovative {P}arallel {C}omputing},
  Month                    = may,
  Pages                    = {1--12},
  Series                   = {InPar '12},

 abstract = {Sparse matrix-vector multiplication is an integral part of many scientific algorithms. Several studies have shown that it is a bandwidth-limited operation on current hardware. On cache-based architectures the main factors that influence performance are spatial locality in accessing the matrix, and temporal locality in re-using the elements of the vector. This paper discusses efficient implementations of sparse matrix-vector multiplication on NVIDIA's Fermi architecture, the first to introduce conventional L1 caches to GPUs. We focus on the compressed sparse row (CSR) format for developing general purpose code. We present a parametrised algorithm, show the effects of parameter tuning on performance and introduce a method for determining the nearoptimal set of parameters that incurs virtually no overhead. On a set of sparse matrices from the University of Florida Sparse Matrix Collection we show an average speed-up of 2.1 times over NVIDIA's CUSPARSE 4.0 library in single precision and 1.4 times in double precision. Many algorithms require repeated evaluation of sparse matrix-vector products with the same matrix, so we introduce a dynamic run-time auto-tuning system which improves performance by 10-15\% in seven iterations. The CSR format is compared to alternative ELLPACK and HYB formats and the cost of conversion is assessed using CUSPARSE. Sparse matrix-vector multiplication performance is also analysed when solving a finite element problem with the conjugate gradient method. We show how problemspecific knowledge can be used to improve performance by up to a factor of two.},
  Date                     = {2012},
  Doi                      = {10.1109/InPar.2012.6339602},
  Keywords                 = {cache storage;conjugate gradient methods;finite element analysis;graphics processing units;mathematics computing;matrix multiplication;sparse matrices;vectors;CSR format;CUSPARSE;ELLPACK formats;HYB formats;L1 caches;NVIDIA CUSPARSE 4.0 library;NVIDIA Fermi architecture;University of Florida sparse matrix collection;bandwidth-limited operation;cache-based GPU;cache-based architectures;compressed sparse row format;conjugate gradient method;dynamic run-time autotuning system;finite element problem;general purpose code;sparse matrix-vector multiplication;spatial locality;temporal locality;Algorithm design and analysis;Graphics processing unit;Heuristic algorithms;Instruction sets;Memory management;Sparse matrices;Vectors;autotuning;cache performance;conjugate gradient method;finite element method;sparse matrix-vector multiplication},
  Location                 = {San Jose, CA, USA}
}

@InProceedings{Ren2012,
  author    = {Ling Ren and Xiaoming Chen and Yu Wang and Chenxi Zhang and Huazhong Yang},
  title     = {Sparse {LU} Factorization for Parallel Circuit Simulation on {GPU}},
  booktitle = {{P}roceedings of the 49th {ACM}/{EDAC}/{IEEE} {D}esign {A}utomation {C}onference},
  date      = {2012},
  series    = {DAC '12},
  location  = {San Francisco, CA, US},
  month     = jun,
  isbn      = {978-1-4503-1199-1},
  pages     = {1125--1130},
  url       = {http://ieeexplore.ieee.org/document/6241646/},
  abstract  = {Sparse solver has become the bottleneck of SPICE simulators. There has been few work on GPU-based sparse solver because of the high data-dependency. The strong data-dependency determines that parallel sparse LU factorization runs efficiently on shared-memory computing devices. But the number of CPU cores sharing the same memory is often limited. The state of the art Graphic Processing Units (GPU) naturally have numerous cores sharing the device memory, and provide a possible solution to the problem. In this paper, we propose a GPU-based sparse LU solver for circuit simulation. We optimize the work partitioning, the number of active thread groups, and the memory access pattern, based on GPU architecture. On matrices whose factorization involves many floating-point operations, our GPU-based sparse LU factorization achieves 7.90$\times$ speedup over 1-core CPU and 1.49$\times$ speedup over 8-core CPU. We also analyze the scalability of parallel sparse LU factorization and investigate the specifications on CPUs and GPUs that most influence the performance.},
  issn      = {0738-100X},
  keywords  = {SPICE;circuit simulation;graphics processing units;shared memory systems;CPU cores;GPU;SPICE simulators;data-dependency;graphic processing units;parallel circuit simulation;parallel sparse LU factorization;shared-memory computing devices;sparse solver;Bandwidth;Graphics processing unit;Instruction sets;Parallel processing;Sorting;Sparse matrices;Vectors;Circuit Simulation;GPU;Parallel Sparse LU Factorization},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Book{Rodriguez2008,
  Title                    = {Algoritmi numerici},
  Author                   = {Giuseppe Rodriguez},
  Publisher                = {Pitagora Editrice},

  Date                     = {2008},
  ISBN                     = {88-371-1714-0},
  Owner                    = {andrea},
  Pages                    = {117},
  Timestamp                = {2016.10.13}
}

@Online{Rupp2014,
  Title                    = {{CPU}, {GPU} and {MIC} Hardware Characteristics over Time},
  Author                   = {Karl Rupp},
  Date                     = {2014},
  Month                    = mar,
  Url                      = {https://www.karlrupp.net/2013/06/cpu-gpu-and-mic-hardware-characteristics-over-time/},

  Note                     = {Accessed 21 July 2016},

  Owner                    = {andrea},
  Timestamp                = {2016.11.07}
}

@Article{Rupp2016,
  Title                    = {{ViennaCL} - Linear Algebra Library for Multi- and Many-Core Architectures},
  Author                   = {Karl Rupp and Philippe Tillet and Florian Rudolf and Josef Weinbub and Andreas Morhammer and Tibor Grasser and Ansgar Jüngel and Siegfried Selberherr},
  Number                   = {5},
  Pages                    = {S412--S439},
  Volume                   = {38},

 abstract = {CUDA, OpenCL, and OpenMP are popular programming models for the multicore architectures of CPUs and many-core architectures of GPUs or Xeon Phis. At the same time, computational scientists face the question of which programming model to use to obtain their scientific results. We present the linear algebra library ViennaCL, which is built on top of all three programming models, thus enabling computational scientists to interface to a single library, yet obtain high performance for all three hardware types. Since the respective compute back end can be selected at runtime, one can seamlessly switch between different hardware types without the need for error-prone and time-consuming recompilation steps. We present new benchmark results for sparse linear algebra operations in ViennaCL, complementing results for the dense linear algebra operations in ViennaCL reported in earlier work. Comparisons with vendor libraries show that ViennaCL provides better overall performance for sparse matrix-vector and sparse matrix-matrix products. Additional benchmark results for pipelined iterative solvers with kernel fusion and preconditioners identify the respective sweet spots for CPUs, Xeon Phis, and GPUs.},
  Date                     = {2016},
  Doi                      = {10.1137/15M1026419},
  Journaltitle             = {{SIAM} Journal on Scientific Computing}
}

@InProceedings{Ryoo2008,
  Title                    = {Program Optimization Space Pruning for a Multithreaded {GPU}},
  Author                   = {Ryoo, Shane and Rodrigues, Christopher I. and Stone, Sam S. and Baghsorkhi, Sara S. and Ueng, Sain-Zee and Stratton, John A. and Hwu, Wen-mei W.},
  Booktitle                = {{P}roceedings of the 6th {A}nnual {IEEE/ACM} {I}nternational {S}ymposium on {C}ode {G}eneration and {O}ptimization},

  Address                  = {New York, NY, USA},
  Pages                    = {195--204},
  Publisher                = {ACM},
  Series                   = {CGO '08},

 abstract = {Program optimization for highly-parallel systems has historically been considered an art, with experts doing much of the performance tuning by hand. With the introduction of inexpensive, single-chip, massively parallel platforms, more developers will be creating highly-parallel applications for these platforms, who lack the substantial experience and knowledge needed to maximize their performance. This creates a need for more structured optimization methods with means to estimate their performance effects. Furthermore these methods need to be understandable by most programmers. This paper shows the complexity involved in optimizing applications for one such system and one relatively simple methodology for reducing the workload involved in the optimization process. \\This work is based on one such highly-parallel system, the GeForce 8800 GTX using CUDA. Its flexible allocation of resources to threads allows it to extract performance from a range of applications with varying resource requirements, but places new demands on developers who seek to maximize an application's performance. We show how optimizations interact with the architecture in complex ways, initially prompting an inspection of the entire configuration space to find the optimal configuration. Even for a seemingly simple application such as matrix multiplication, the optimal configuration can be unexpected. We then present metrics derived from static code that capture the first-order factors of performance. We demonstrate how these metrics can be used to prune many optimization configurations, down to those that lie on a Pareto-optimal curve. This reduces the optimization space by as much as 98\% and still finds the optimal configuration for each of the studied applications.},
  Acmid                    = {1356084},
  Date                     = {2008},
  Doi                      = {10.1145/1356058.1356084},
  ISBN                     = {978-1-59593-978-4},
  Keywords                 = {gpgpu, optimization, parallel computing},
  Location                 = {Boston, MA, USA},
  Numpages                 = {10}
}

@Book{Saad2003,
  Title                    = {Iterative Methods for Sparse Linear Systems},
  Author                   = {Yousef Saad},
  Publisher                = {Society for Industrial and Applied Mathematics},
  Edition                  = {2},

  Date                     = {2003},
  Doi                      = {10.1137/1.9780898718003},
  Owner                    = {ap8213},
  Timestamp                = {2015.09.23}
}

@InProceedings{Sadrieh2011,
  author    = {Arash Sadrieh and Parisa A. Bahri},
  title     = {Optimal Control of the Process Systems Using Graphic Processing Units},
  booktitle = {{P}roceedings of the 18th {IFAC} {W}orld {C}ongress},
  date      = {2011},
  series    = {IFAC '11},
  location  = {Milan, IT},
  doi       = {10.3182/20110828-6-IT-1002.01804},
  abstract  = {In this paper the Graphic Processing Unit (GPU) is applied in order to improve the computational performance of process systems optimal control calculations. To apply GPU massive parallel architecture, a simplified version of interior point optimisation algorithm was selected and modified to fulfil special hardware requirements of GPU architecture. In this algorithm, a damped nonlinear Newton with preconditioned iterative linear solver was used to solve Dual-Primal equations. The comparison of results between this implementation and standard CPU-based implementation shows considerable improvement in computational performance.},
  owner     = {ap8213},
  timestamp = {2014.10.09},
}

@InProceedings{Sager2008,
  author    = {Sebastian Sager and Christian Kirches and Hans Georg Bock},
  title     = {Fast solution of periodic optimal control problems in automobile test-driving with gear shifts},
  booktitle = {{P}roceedings of the 47th {IEEE} {C}onference on {D}ecision and {C}ontrol},
  date      = {2008},
  series    = {CDC '08},
  location  = {Cancun, MEX},
  month     = dec,
  pages     = {1563--1568},
  doi       = {10.1109/CDC.2008.4739014},
  abstract  = {Optimal control problems involving time-dependent decisions from a finite set have gained much interest lately, as they occur in practical applications with a high potential for optimization. A typical application is automobile driving with gear shifts. Recent work [7], [8], [9] lead to a tremendous speedup in computational times to obtain optimal solutions, allowing for more complex scenarios. In this paper we extend a benchmark mixed-integer optimal control problem to a more complicated case in which a periodic solution on a closed track is considered. Our generic solution approach is based on a convexification and relaxation of the integer control constraint. It may also be used for other objectives, such as energy minimization. Using the direct multiple shooting method we solve the new benchmark problem and present numerical results.},
  issn      = {0191-2216},
  keywords  = {automobiles;automotive components;gears;optimal control;testing;vehicle dynamics;automobile driving;automobile test-driving;direct multiple shooting method;energy minimization;finite set;gear shifts;integer control constraint;mixed-integer optimal control problem;optimization;periodic optimal control problems;time-dependent decisions;Automobiles;Chemical engineering;Computational efficiency;Differential equations;Gears;Optimal control;Optimization methods;Scientific computing;Testing;Valves},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@InProceedings{Salihoglu2014,
  Title                    = {{HelP}: High-level Primitives For Large-Scale Graph Processing},
  Author                   = {Salihoglu, Semih and Widom, Jennifer},
  Booktitle                = {{P}roceedings of {W}orkshop on {GRA}ph {D}ata {M}anagement {E}xperiences and {S}ystems},

  Address                  = {New York, NY, USA},
  Pages                    = {3:1--3:6},
  Publisher                = {ACM},
  Series                   = {GRADES '14},

 abstract = {Large-scale graph processing systems typically expose a small set of functions, such as the compute() function of Pregel, or the gather(), apply(), and scatter() functions of PowerGraph. For some computations, these APIs are too low-level, yielding long and complex programs, but with shared coding patterns. Similar issues with the MapReduce framework have led to widely-used languages such as Pig Latin and Hive, which introduce higher-level primitives. We take an analogous approach for graph processing: we propose HelP, a set of high-level primitives that capture commonly appearing operations in large-scale graph computations. Using our primitives we have implemented a large suite of algorithms, some of which we previously implemented with the APIs of existing systems. Our experience has been that implementing algorithms using our primitives is more intuitive and much faster than using the APIs of existing distributed systems. All of our primitives and algorithms are fully implemented as a library on top of the open-source GraphX system.},
  Acmid                    = {2621938},
  Articleno                = {3},
  Date                     = {2014},
  Doi                      = {10.1145/2621934.2621938},
  ISBN                     = {978-1-4503-2982-8},
  Location                 = {Snowbird, UT, USA},
  Numpages                 = {6}
}

@Book{Scarpino2011,
  author    = {Scarpino, M.},
  title     = {Open{CL} in action},
  date      = {2011},
  publisher = {Manning Publications Co.},
  owner     = {andrea},
  timestamp = {2014.03.05},
}

@Article{Scholtes2005,
  author       = {Scholtes, Carsten},
  title        = {A Method to Derive the Cache Performance of Irregular Applications on Machines with Direct Mapped Caches},
  journaltitle = {International Journal of Computational Science and Engineering},
  date         = {2005},
  volume       = {1},
  number       = {2-4},
  month        = may,
  pages        = {157--174},
  issn         = {1742-7185},
  doi          = {10.1504/IJCSE.2005.009700},
 abstract = {A probabilistic method is presented to derive the cache performance of irregular applications on machines with direct mapped caches from inspection of the source code. The method has been applied to analyse both a program to multiply a sparse matrix with a dense matrix and a program for the Cholesky-factorisation of a sparse matrix. The resulting predictions are compared with measurements of the respective programs.},
  acmid        = {1360421},
  issue_date   = {May 2005},
  keywords     = {cache memories, cache performance, direct mapped caches, irregular applications, irregularity, parallel computing, prediction methods},
  location     = {Inderscience Publishers, Geneva, SWITZERLAND},
  numpages     = {18},
  publisher    = {Inderscience Publishers},
}

@InProceedings{Shahzad2010,
  author    = {Amir Shahzad and Eric C. Kerrigan and George A. Constantinides},
  title     = {A Warm-start Interior-point Method for Predictive Control},
  booktitle = {{P}roceedings of the 6th {UKACC} {I}nternational {C}onference on {C}ontrol},
  date      = {2010},
  series    = {UKACC '10},
  location  = {Coventry, UK},
  doi       = {10.1137/S1052623400369235},
  abstract  = {We study the situation in which, having solved a linear program with an interior-point method, we are presented with a new problem instance whose data is slightly perturbed from the original. We describe strategies for recovering a "warm-start" point for the perturbed problem instance from the iterates of the original problem instance. We obtain worst-case estimates of the number of iterations required to converge to a solution of the perturbed instance from the warm-start points, showing that these estimates depend on the size of the perturbation and on the conditioning and other properties of the problem instances.},
  owner     = {andrea},
  timestamp = {2014.12.15},
}

@TechReport{Shewchuk1994,
  Title                    = {An Introduction to the Conjugate Gradient Method Without the Agonizing Pain},
  Author                   = {Jonathan Richard Shewchuk},
  Institution              = {Carnegie Mellon University},

 abstract = {The Conjugate Gradient Method is the most prominent iterative method for solving sparse systems of linear equations. Unfortunately, many textbook treatments of the topic are written so that even their own authors would be mystified, if they bothered to read their own writing. For this reason, an understanding of the method has been reserved for the elite brilliant few who have painstakingly decoded the mumblings of their forebears. Nevertheless, the Conjugate Gradient Method is a composite of simple, elegant ideas that almost anyone can understand. Of course, a reader as intelligent as yourself will learn them almost effortlessly. The idea of quadratic forms is introduced and used to derive the methods of Steepest Descent, Conjugate Directions, and Conjugate Gradients. Eigenvectors are explained and used to examine the convergence of the Jacobi Method, Steepest Descent, and Conjugate Gradients. Other topics include preconditioning and the nonlinear Conjugate Gradient Method. I have taken pains to make this article easy to read. Sixty-two illustrations are provided. Dense prose is avoided. Concepts are explained in several different ways. Most equations are coupled with an intuitive interpretation.},
  Date                     = {1994},
  Location                 = {Pittsburgh, PA, USA},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07},
  Url                      = {http://www.cs.cmu.edu/~./quake-papers/painless-conjugate-gradient.pdf}
}

@InProceedings{Shimai2009,
  author    = {Yusuke Shimai and Junichi Tani and Hiroki Noguchi and Hiroshi Kawaguchi and Masahiko Yoshimoto},
  title     = {{FPGA} Implementation of Mixed Integer Quadratic Programming Solver for Mobile Robot Control},
  booktitle = {{P}roceedings of the 2009 {I}nternational {C}onference on {F}ield-{P}rogrammable {T}echnology},
  date      = {2009},
  series    = {FPT '09},
  location  = {Sidney, AUS},
  month     = dec,
  pages     = {447--450},
  doi       = {10.1109/FPT.2009.5377635},
  abstract  = {We propose a high-speed mixed integer quadratic programming (MIQP) solver on an FPGA. The MIQP solver can be applied to various optimizing applications including real-time robot control. In order to rapidly solve the MIQP problem, we implement reusing a first solution (first point), pipeline architecture, and multi-core architecture on the single FPGA. By making use of them, we confirmed that 79.5\% of the cycle times are reduced, compared with straightforward sequential processing. The operating frequency is 67 MHz, although a core 2 duo PC requires 3.16 GHz in processing the same size problem. The power consumption of the MIQP solver is 4.2 W.},
  keywords  = {control engineering computing;field programmable gate arrays;integer programming;mobile robots;pipeline processing;quadratic programming;FPGA implementation;MIQP solver;high-speed mixed integer quadratic programming solver;mobile robot control;multicore architecture;pipeline architecture;power consumption;real-time robot control;straightforward sequential processing;Artificial intelligence;Control systems;Field programmable gate arrays;Linear matrix inequalities;Mobile robots;NP-hard problem;Quadratic programming;Robot control;Robot programming;Symmetric matrices},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Article{Shin1995,
  author       = {Shin, K.G. and Cui, X.},
  title        = {Computing time delay and its effects on real-time control systems},
  journaltitle = {{IEEE} Transactions on Control Systems Technology},
  date         = {1995},
  volume       = {3},
  number       = {2},
  pages        = {218--224},
  issn         = {1063-6536},
  doi          = {10.1109/87.388130},
  abstract     = {The reliability of a real-time digital control computer depends not only on the reliability of the hardware and software used, but also on the time delay in computing the control output, because of the negative effects of computing time delay on control system performance. For a given fixed sampling interval, the effects of computing time delay are classified into the delay and loss problems. The delay problem occurs when the computing time delay is nonzero but smaller than the sampling interval, while the loss problem occurs when the computing time delay is greater than, or equal to, the sampling interval, i.e., loss of the control output. These two problems are analyzed as a means of evaluating real-time control systems. First, a generic analysis of the effects of computing time delay is presented along with necessary conditions for system stability. Then, we present both qualitative and quantitative analyses of the computing time delay effects on a robot control system, deriving upper bounds of the computing time delay with respect to system stability and system performance.},
  keywords     = {computerised control;control system analysis;control systems;delays;performance evaluation;stability;computing time delay;digital control computer;loss problem;real-time control systems;robot control;sampling interval;system performance;system stability;upper bounds;Control systems;Delay effects;Digital control;Hardware;Performance analysis;Real time systems;Sampling methods;Software performance;Stability analysis;System performance},
  owner        = {ap8213},
  timestamp    = {2014.10.09},
}

@InProceedings{Shun2013,
  Title                    = {Ligra: A Lightweight Graph Processing Framework for Shared Memory},
  Author                   = {Shun, Julian and Blelloch, Guy E.},
  Booktitle                = {{P}roceedings of the 18th {ACM SIGPLAN} {S}ymposium on {P}rinciples and {P}ractice of {P}arallel {P}rogramming},

  Address                  = {New York, NY, USA},
  Pages                    = {135--146},
  Publisher                = {ACM},
  Series                   = {PPoPP '13},

 abstract = {There has been significant recent interest in parallel frameworks for processing graphs due to their applicability in studying social networks, the Web graph, networks in biology, and unstructured meshes in scientific simulation. Due to the desire to process large graphs, these systems have emphasized the ability to run on distributed memory machines. Today, however, a single multicore server can support more than a terabyte of memory, which can fit graphs with tens or even hundreds of billions of edges. Furthermore, for graph algorithms, shared-memory multicores are generally significantly more efficient on a per core, per dollar, and per joule basis than distributed memory systems, and shared-memory algorithms tend to be simpler than their distributed counterparts. \\In this paper, we present a lightweight graph processing framework that is specific for shared-memory parallel/multicore machines, which makes graph traversal algorithms easy to write. The framework has two very simple routines, one for mapping over edges and one for mapping over vertices. Our routines can be applied to any subset of the vertices, which makes the framework useful for many graph traversal algorithms that operate on subsets of the vertices. Based on recent ideas used in a very fast algorithm for breadth-first search (BFS), our routines automatically adapt to the density of vertex sets. We implement several algorithms in this framework, including BFS, graph radii estimation, graph connectivity, betweenness centrality, PageRank and single-source shortest paths. Our algorithms expressed using this framework are very simple and concise, and perform almost as well as highly optimized code. Furthermore, they get good speedups on a 40-core machine and are significantly more efficient than previously reported results using graph frameworks on machines with many more cores.},
  Acmid                    = {2442530},
  Date                     = {2013},
  Doi                      = {10.1145/2442516.2442530},
  ISBN                     = {978-1-4503-1922-5},
  Keywords                 = {graph algorithms, parallel programming, shared memory},
  Location                 = {Shenzhen, CN},
  Numpages                 = {12}
}

@Article{Smith2011,
  Title                    = {Sparse triangular solves for {ILU} revisited: data layout crucial to better performance},
  Author                   = {Barry Smith and Hong Zhang},

  Month                    = nov,
  Number                   = {4},
  Pages                    = {386--391},
  Volume                   = {25},

 abstract = {A key to good processor utilization for sparse matrix computations is storing the data in the format that is most conducive to fast access by the memory system. In particular, for sparse matrix triangular solves the traditional compressed sparse matrix format is poor, and minor adjustments to the data structure can increase the processor utilization dramatically. Such adjustments involve storing the L and U factors separately and storing the U rows backwards so that they are accessed in a simple streaming fashion during the triangular solves. Changes to the PETSc libraries to use this modified storage format resulted in over twice the floating-point rate for some matrices. This improvement can be accounted for by a decrease in the cache misses and TLB (transaction lookaside buffer) misses in the modified code.},
  Date                     = {2011},
  Doi                      = {10.1177/1094342010389857},
  Journaltitle             = {International Journal of High Performance Computing Applications},
  Owner                    = {andrea},
  Timestamp                = {2015.09.28}
}

@PhdThesis{Smith2013,
  author      = {Smith, E.},
  title       = {Parallel solution of linear programs},
  institution = {University of Edinburgh},
  date        = {2013},
  url         = {http://hdl.handle.net/1842/8833},
  abstract    = {The factors limiting the performance of computer software periodically undergo sudden shifts, resulting from technological progress, and these shifts can have profound implications for the design of high performance codes. At the present time, the speed with which hardware can execute a single stream of instructions has reached a plateau. It is now the number of instruction streams that may be executed concurrently which underpins estimates of compute power, and with this change, a critical limitation on the performance of software has come to be the degree to which it can be parallelised. The research in this thesis is concerned with the means by which codes for linear programming may be adapted to this new hardware. For the most part, it is codes implementing the simplex method which will be discussed, though these have typically lower performance for single solves than those implementing interior point methods. However, the ability of the simplex method to rapidly re-solve a problem makes it at present indispensable as a subroutine for mixed integer programming. The long history of the simplex method as a practical technique, with applications in many industries and government, has led to such codes reaching a great level of sophistication. It would be unexpected in a research project such as this one to match the performance of top commercial codes with many years of development behind them. The simplex codes described in this thesis are, however, able to solve real problems of small to moderate size, rather than being confined to random or otherwise artificially generated instances. The remainder of this thesis is structured as follows. The rest of this chapter gives a brief overview of the essential elements of modern parallel hardware and of the linear programming problem. Both the simplex method and interior point methods are discussed, along with some of the key algorithmic enhancements required for such systems to solve real-world problems. Some background on the parallelisation of both types of code is given. The next chapter describes two standard simplex codes designed to exploit the current generation of hardware. i6 is a parallel standard simplex solver capable of being applied to a range of real problems, and showing exceptional performance for dense, square programs. i8 is also a parallel, standard simplex solver, but now implemented for graphics processing units (GPUs).},
  owner       = {andrea},
  timestamp   = {2014.03.05},
}

@InCollection{Smith2012,
  author    = {E. Smith and J. Gondzio and J.A.J. Hall},
  title     = {{GPU} acceleration of the matrix-free interior point method},
  booktitle = {{P}arallel {P}rocessing and {A}pplied {M}athematics},
  date      = {2012},
  editor    = {Wyrzykowski, R. and Dongarra, J. and Karczewski, K. and Waśniewski, J.},
  volume    = {7203},
  series    = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  isbn      = {978-3-642-31463-6},
  pages     = {681--689},
  doi       = {10.1007/978-3-642-31464-3_69},
  abstract  = {The matrix-free technique is an iterative approach to interior point methods (IPM), so named because both the solution procedure and the computation of an appropriate preconditioner require only the results of the operations Ax and ATy, where A is the matrix of constraint coefficients. This paper demonstrates its overwhelmingly superior performance on two classes of linear programming (LP) problems relative to both the simplex method and to IPM with equations solved directly. It is shown that the reliance of this technique on sparse matrix-vector operations enables further, significant performance gains from the use of a GPU, and from multi-core processors.},
  keywords  = {interior point methods; linear programming; matrix-free methods; parallel sparse linear algebra},
  owner     = {ap8213},
  timestamp = {2014.03.21},
}

@Book{Smith1993,
  Title                    = {The Design and Analysis of Parallel Algorithms},
  Author                   = {Justin R. Smith},
  Publisher                = {Oxford University Press},

 abstract = {This text for students and professionals in computer science provides a valuable overview of current knowledge concerning parallel algorithms. These computer operations have recently acquired increased importance due to their ability to enhance the power of computers by permitting multiple processors to work on different parts of a problem independently and simultaneously. This approach has led to solutions of difficult problems in a number of vital fields, including artificial intelligence, image processing, and differential equations. As the first up-to-date summary of the topic, this book will be sought after by researchers, computer science professionals, and advanced students involved in parallel computing and parallel algorithms.},
  Date                     = {1993},
  ISBN                     = {0195078810},
  Owner                    = {andrea},
  Timestamp                = {2017.05.10}
}

@InProceedings{Soman2010,
  Title                    = {A fast {GPU} algorithm for graph connectivity},
  Author                   = {J. Soman and K. Kishore and P. J. Narayanan},
  Booktitle                = {{P}roceedings of the 2010 {IEEE} {I}nternational {S}ymposium on {P}arallel {D}istributed {P}rocessing, {W}orkshops and {P}hd {F}orum},
  Month                    = apr,
  Pages                    = {1--8},
  Series                   = {IPDPSW '10},

 abstract = {Graphics processing units provide a large computational power at a very low price which position them as an ubiquitous accelerator. General purpose programming on the graphics processing units (GPGPU) is best suited for regular data parallel algorithms. They are not directly amenable for algorithms which have irregular data access patterns such as list ranking, and finding the connected components of a graph, and the like. In this work, we present a GPU-optimized implementation for finding the connected components of a given graph. Our implementation tries to minimize the impact of irregularity, both at the data level and functional level. Our implementation achieves a speed up of 9 to 12 times over the best sequential CPU implementation. For instance, our implementation finds connected components of a graph of 10 million nodes and 60 million edges in about 500 milliseconds on a GPU, given a random edge list. We also draw interesting observations on why PRAM algorithms, such as the Shiloach-Vishkin algorithm may not be a good fit for the GPU and how they should be modified.},
  Date                     = {2010},
  Doi                      = {10.1109/IPDPSW.2010.5470817},
  Keywords                 = {coprocessors;parallel processing;GPU-optimized implementation;Shiloach-Vishkin algorithm;craphics processing units;fast GPU algorithm;general purpose programming;graph connectivity;large computational power;regular data parallel algorithms;ubiquitous accelerator;Arithmetic;Central Processing Unit;Graphics;Inference algorithms;Parallel algorithms;Parallel processing;Parallel programming;Partitioning algorithms;Pervasive computing;Phase change random access memory;Connected Components;GPGPU;GPU;Irregular algorithms},
  Location                 = {Atlanta, GA, US}
}

@InProceedings{Spampinato2009,
  author    = {Daniele D. Spampinato and Anne C. Elster},
  title     = {Linear optimization on modern {GPU}s},
  booktitle = {{P}roceedings of the {IEEE} {I}nternational {S}ymposium on {P}arallel and {D}istributed {P}rocessing},
  date      = {2009},
  series    = {IPDPS '09},
  location  = {Rome, IT},
  month     = may,
  pages     = {1--8},
  doi       = {10.1109/IPDPS.2009.5161106},
  abstract  = {Optimization algorithms are becoming increasingly more important in many areas, such as finance and engineering. Typically, real problems involve several hundreds of variables, and are subject to as many constraints. Several methods have been developed trying to reduce the theoretical time complexity. Nevertheless, when problems exceed reasonable sizes they end up being very computationally intensive. Heterogeneous systems composed by coupling commodity CPUs and GPUs are becoming relatively cheap, highly performing systems. Recent developments of GPGPU technologies give even more powerful control over them. In this paper, we show how we use a revised simplex algorithm for solving linear programming problems originally described by Dantzig for both our CPU and GPU implementations. Previously, this approach has showed not to scale beyond around 200 variables. However, by taking advantage of modern libraries such as ATLAS for matrix-matrix multiplication, and the NVIDIA CUDA programming library on recent GPUs, we show that we can scale to problem sizes up to at least 2000 variables in our experiments for both architectures. On the GPU, we also achieve an appreciable precision on large problems with thousands of variables and constraints while achieving between 2$\times$ and 2.5$\times$ speed-ups over the serial ATLAS-based CPU version. With further tuning of both the algorithm and its implementations, even better results should be achievable for both the CPU and GPU versions.},
  file      = {:home/andrea/Dropbox/PhD/Papers/Spampinato - Linear Optimization on Modern GPU.pdf:PDF},
  issn      = {1530-2075},
  keywords  = {coprocessors;linear programming;matrix multiplication;parallel architectures;ATLAS-based CPU version;GPGPU technologies;NVIDIA CUDA programming library;graphics processing unit;linear optimization;linear programming problems;matrix-matrix multiplication;modern GPUs;theoretical time complexity;Computer graphics;Design automation;Finance;Hardware;High performance computing;Information science;Libraries;Linear programming;Optimization methods;Power engineering computing},
  owner     = {ap8213},
  timestamp = {2014.10.09},
}

@Article{Spielman2004,
  author       = {Daniel A. Spielman and Shang-Hua Teng},
  title        = {Smoothed Analysis of Algorithms: Why the Simplex Algorithm Usually Takes Polynomial Time},
  journaltitle = {Journal of the {ACM}},
  date         = {2004},
  volume       = {51},
  number       = {3},
  month        = may,
  pages        = {385--463},
  issn         = {0004-5411},
  doi          = {10.1145/990308.990310},
  abstract     = {We introduce the smoothed analysis of algorithms, which continuously interpolates between the worst-case and average-case analyses of algorithms. In smoothed analysis, we measure the maximum over inputs of the expected performance of an algorithm under small random perturbations of that input. We measure this performance in terms of both the input size and the magnitude of the perturbations. We show that the simplex algorithm has smoothed complexity polynomial in the input size and the standard deviation of Gaussian perturbations.},
  acmid        = {990310},
  issue_date   = {May 2004},
  keywords     = {Simplex method, complexity, perturbation, smoothed analysis},
  location     = {New York, NY, USA},
  numpages     = {79},
  owner        = {andrea},
  publisher    = {ACM},
  timestamp    = {2017.05.08},
}

@Book{Stoer2002,
  author    = {Stoer, J. and Bulirsch, R.},
  title     = {Introduction to numerical analysis},
  date      = {2002},
  series    = {Texts in applied mathematics},
  publisher = {Springer},
  location  = {New York},
  isbn      = {0-387-95452-X},
  owner     = {ap8213},
  timestamp = {2014.10.09},
}

@Article{Stone2010,
  author       = {Stone, J. E. and Gohara, D. and Shi, G.},
  title        = {{OpenCL}: A Parallel Programming Standard for Heterogeneous Computing Systems},
  journaltitle = {Computing in Science \& Engineering},
  date         = {2010},
  volume       = {12},
  number       = {3},
  month        = may,
  pages        = {66--73},
  issn         = {0740-7475},
  doi          = {10.1109/MCSE.2010.69},
 abstract = {The OpenCL standard offers a common API for program execution on systems composed of different types of computational devices such as multicore CPUs, GPUs, or other accelerators.},
  acmid        = {1803953},
  issue_date   = {May 2010},
  location     = {Los Alamitos, CA, USA},
  numpages     = {8},
  owner        = {ap8213},
  publisher    = {IEEE Computer Society Press},
  timestamp    = {2014.10.09},
}

@InBook{Strout2001,
  Title                    = {Rescheduling for Locality in Sparse Matrix Computations},
  Author                   = {Strout, Michelle Mills and Carter, Larry and Ferrante, Jeanne},
  Editor                   = {Alexandrov, Vassil N. and Dongarra, Jack J. and Juliano, Benjoe A. and Renner, R. S. and Tan, C. J. Kenneth},
  Pages                    = {137--146},
  Publisher                = {Springer Berlin Heidelberg},

  Address                  = {Berlin, Heidelberg},
  Series                   = {ICCS '01},

 abstract = {In modern computer architecture the use of memory hierarchies causes a program's data locality to directly affect performance. Data locality occurs when a piece of data is still in a cache upon reuse. For dense matrix computations, loop transformations can be used to improve data locality. However, sparse matrix computations have non-affine loop bounds and indirect memory references which prohibit the use of compile time loop transformations. This paper describes an algorithm to tile at runtime called serial sparse tiling. We test a runtime tiled version of sparse Gauss-Seidel on 4 different architectures where it exhibits speedups of up to 2.7. The paper also gives a static model for determining tile size and outlines how overhead affects the overall speedup.},
  Booktitle                = {{P}roceedings of the 2001 {I}nternational {C}onference on {C}omputational {S}cience},
  Date                     = {2001},
  Doi                      = {10.1007/3-540-45545-0_23},
  ISBN                     = {978-3-540-45545-5},
  Location                 = {San Francisco, CA, USA},
  Owner                    = {andrea},
  Part                     = {I},
  Timestamp                = {2017.05.08}
}

@InProceedings{Suchoski2012,
  Title                    = {Adapting Sparse Triangular Solution to {GPUs}},
  Author                   = {Brad Suchoski and Caleb Severn and Manu Shantharam and Padma Raghavan},
  Booktitle                = {{P}roceeding of the 41st {I}nternational {C}onference on {P}arallel {P}rocessing {W}orkshops},
  Month                    = sep,
  Pages                    = {140--148},
  Series                   = {ICPPW '12},

 abstract = {High performance computing systems are increasingly incorporating hybrid CPU/GPU nodes to accelerate the rate at which floating point calculations can be performed for scientific applications. Currently, a key challenge is adapting scientific applications to such systems when the underlying computations are sparse, such as sparse linear solvers for the simulation of partial differential equation models using semi-implicit methods. Now, a key bottleneck is sparse triangular solution for solvers such as preconditioned conjugate gradients (PCG). We show that sparse triangular solution can be effectively mapped to GPUs by extracting very large degrees of fine-grained parallelism using graph coloring. We develop simple performance models to predict these effects at intersection of the data and hardware attributes and we evaluate our scheme on a Nvidia Tesla M2090 GPU relative to the level set scheme developed at NVIDIA. Our results indicate that our approach significantly enhances the available fine-grained parallelism to speed-up PCG iteration time compared to the NVIDIA scheme, by a factor with a geometric mean of 5.41 on a single GPU, with speedups as high as 63 in some cases.},
  Date                     = {2012},
  Doi                      = {10.1109/ICPPW.2012.23},
  ISSN                     = {1530-2016},
  Keywords                 = {floating point arithmetic;graphics processing units;multiprocessing systems;natural sciences computing;NVIDIA Tesla M2090 GPU;fine-grained parallelism;floating point calculations;graph coloring;high performance computing systems;partial differential equation models;preconditioned conjugate gradients;scientific applications;semiimplicit methods;sparse linear solvers;sparse triangular solution;Color;Concurrent computing;Graphics processing unit;Image color analysis;Level set;Parallel processing;Sparse matrices},
  Location                 = {Los Alamitos, CA, USA},
  Owner                    = {andrea},
  Timestamp                = {2015.09.28}
}

@Article{Suhl1993,
  Title                    = {A fast {LU} update for linear programming},
  Author                   = {Leena M. Suhl and Uwe H. Suhl},
  Number                   = {1},
  Pages                    = {33--47},
  Volume                   = {43},

 abstract = {This paper discusses sparse matrix kernels of simplex-based linear programming software. State-of-the-art implementations of the simplex method maintain an LU factorization of the basis matrix which is updated at each iteration. The LU factorization is used to solve two sparse sets of linear equations at each iteration. We present new implementation techniques for a modified Forrest-Tomlin LU update which reduce the time complexity of the update and the solution of the associated sparse linear systems. We present numerical results on Netlib and other real-life LP models.},
  Date                     = {1993},
  Doi                      = {10.1007/BF02025534},
  File                     = {:home/ap8213/Dropbox/Documents/Papers/Suhl, Suhl - A fast LU update for linear programming.pdf:PDF},
  ISSN                     = {0254-5330},
  Journaltitle             = {Annals of Operations Research},
  Owner                    = {ap8213},
  Publisher                = {Baltzer Science Publishers, Baarn/Kluwer Academic Publishers},
  Timestamp                = {2014.10.09}
}

@Online{Sutton2016,
  author     = {Michael Sutton and Tal Ben{-}Nun and Amnon Barak and Sreepathi Pai and Keshav Pingali},
  title      = {Adaptive Work-Efficient Connected Components on the {GPU}},
  date       = {2016},
  abstract   = {This report presents an adaptive work-efficient approach for implementing the Connected Components algorithm on GPUs. The results show a considerable increase in performance (up to 6.8$\times$) over current state-of-the-art solutions.},
  eprint     = {arXiv:1612.01178},
  eprinttype = {arXiv},
  timestamp  = {Mon, 02 Jan 2017 11:09:15 +0100},
}

@InProceedings{Tang2013,
  Title                    = {Accelerating Sparse Matrix-vector Multiplication on {GPUs} Using Bit-representation-optimized Schemes},
  Author                   = {Tang, Wai Teng and Tan, Wen Jun and Ray, Rajarshi and Wong, Yi Wen and Chen, Weiguang and Kuo, Shyh-hao and Goh, Rick Siow Mong and Turner, Stephen John and Wong, Weng-Fai},
  Booktitle                = {{P}roceedings of the {I}nternational {C}onference on {H}igh {P}erformance {C}omputing, {N}etworking, {S}torage and {A}nalysis},

  Address                  = {New York, NY, USA},
  Pages                    = {26:1--26:12},
  Publisher                = {ACM},
  Series                   = {SC '13},

 abstract = {The sparse matrix-vector (SpMV) multiplication routine is an important building block used in many iterative algorithms for solving scientific and engineering problems. One of the main challenges of SpMV is its memory-boundedness. Although compression has been proposed previously to improve SpMV performance on CPUs, its use has not been demonstrated on the GPU because of the serial nature of many compression and decompression schemes. In this paper, we introduce a family of bit-representation-optimized (BRO) compression schemes for representing sparse matrices on GPUs. The proposed schemes, BRO-ELL, BRO-COO, and BRO-HYB, perform compression on index data and help to speed up SpMV on GPUs through reduction of memory traffic. Furthermore, we formulate a BRO-aware matrix reordering scheme as a data clustering problem and use it to increase compression ratios. With the proposed schemes, experiments show that average speedups of 1.5$\times$ compared to ELLPACK and HYB can be achieved for SpMV on GPUs.},
  Acmid                    = {2503234},
  Articleno                = {26},
  Date                     = {2013},
  Doi                      = {10.1145/2503210.2503234},
  ISBN                     = {978-1-4503-2378-9},
  Keywords                 = {GPU, compression, data compression, matrix-vector multiplication, memory bandwidth, parallelism, sparse matrix format},
  Location                 = {Denver, CO, USA},
  Numpages                 = {12}
}

@Article{Tarjan1972,
  Title                    = {Depth-first search and linear graph algorithms},
  Author                   = {Robert Tarjan},

  Month                    = jun,
  Number                   = {2},
  Pages                    = {146--160},
  Volume                   = {1},

  Date                     = {1972},
  Journaltitle             = {{SIAM} Journal on Computing},
  Owner                    = {andrea},
  Timestamp                = {2015.04.24}
}

@InProceedings{Temam1992,
  Title                    = {Characterizing the Behaviour of Sparse Algorithms on Caches},
  Author                   = {O. Temam and W. Jalby},
  Booktitle                = {{P}roceedings of the {I}nternational {C}onference on {H}igh {P}erformance {C}omputing, {N}etworking, {S}torage and {A}nalysis},
  Pages                    = {578--587},
  Series                   = {SC '92},

 abstract = {A methodology is presented for modeling the irregular references of sparse codes using probabilistic methods. The behavior on cache of one of the most frequent primitives, SpMxV sparse matrix vector multiply, is analyzed. A model of its references is built, and performance bottlenecks of SpMxV are analyzed using the model and simulations. The main parameters are identified and their role is explained and quantified. This analysis is then used to discuss optimizations of SpMxV. A blocking technique which takes into account the specifics of sparse codes is proposed.},
  Date                     = {1992},
  Location                 = {Minneapolis, MN, USA},
  Owner                    = {andrea},
  Timestamp                = {2015.09.27}
}

@InProceedings{Thoman2011,
  author    = {Thoman, Peter and Kofler, Klaus and Studt, Heiko and Thomson, John and Fahringer, Thomas},
  title     = {Automatic {OpenCL} Device Characterization: Guiding Optimized Kernel Design},
  booktitle = {{P}roceedings of the 17th {I}nternational {C}onference on {P}arallel {P}rocessing},
  date      = {2011},
  series    = {Euro-Par '11},
  publisher = {Springer-Verlag},
  location  = {Bordeaux, FR},
  isbn      = {978-3-642-23396-8},
  pages     = {438--452},
  doi       = {10.1007/978-3-642-23397-5_43},
  abstract  = {The OpenCL standard allows targeting a large variety of CPU, GPU and accelerator architectures using a single unified programming interface and language. While the standard guarantees portability of functionality for complying applications and platforms, performance portability on such a diverse set of hardware is limited. Devices may vary significantly in memory architecture as well as type, number and complexity of computational units. To characterize and compare the OpenCL performance of existing and future devices we propose a suite of microbenchmarks, uCLbench. \\We present measurements for eight hardware architectures four GPUs, three CPUs and one accelerator and illustrate how the results accurately reflect unique characteristics of the respective platform. In addition to measuring quantities traditionally benchmarked on CPUs like arithmetic throughput or the bandwidth and latency of various address spaces, the suite also includes code designed to determine parameters unique to OpenCL like the dynamic branching penalties prevalent on GPUs. We demonstrate how our results can be used to guide algorithm design and optimization for any given platform on an example kernel that represents the key computation of a linear multigrid solver. Guided manual optimization of this kernel results in an average improvement of 61\% across the eight platforms tested.},
  acmid     = {2033459},
  address   = {Berlin, Heidelberg},
  numpages  = {15},
}

@Article{Totoni2014,
  Title                    = {Structure-adaptive parallel solution of sparse triangular linear systems},
  Author                   = {Ehsan Totoni and Michael T. Health and Laxmikant V. Kale},

  Month                    = Oct,
  Number                   = {9},
  Pages                    = {454--470},
  Volume                   = {40},

 abstract = {Solving sparse triangular systems of linear equations is a performance bottleneck in many methods for solving more general sparse systems. Both for direct methods and for many iterative preconditioners, it is used to solve the system or improve an approximate solution, often across many iterations. Solving triangular systems is notoriously resistant to parallelism, however, and existing parallel linear algebra packages appear to be ineffective in exploiting significant parallelism for this problem. \\We develop a novel parallel algorithm based on various heuristics that adapt to the structure of the matrix and extract parallelism that is unexploited by conventional methods. By analyzing and reordering operations, our algorithm can often extract parallelism even for cases where most of the nonzero matrix entries are near the diagonal. Our main parallelism strategies are: (1) identify independent rows, (2) send data earlier to achieve greater overlap, and (3) process dense off-diagonal regions in parallel. We describe the implementation of our algorithm in Charm++ and MPI and present promising experimental results on up to 512 cores of BlueGene/P, using numerous sparse matrices from real applications.},
  Date                     = {2014},
  Doi                      = {10.1016/j.parco.2014.06.006},
  Journaltitle             = {Parallel Computing},
  Owner                    = {ap8213},
  Timestamp                = {2015.08.15}
}

@InProceedings{Ubal2012,
  Title                    = {Multi2Sim: A simulation framework for {CPU}-{GPU} computing},
  Author                   = {R. Ubal and B. Jang and P. Mistry and D. Schaa and D. Kaeli},
  Booktitle                = {21st {I}nternational {C}onference on {P}arallel {A}rchitectures and {C}ompilation {T}echniques},
  Month                    = sep,
  Pages                    = {335--344},
  Series                   = {PACT '12},

 abstract = {Accurate simulation is essential for the proper design and evaluation of any computing platform. Upon the current move toward the CPU-GPU heterogeneous computing era, researchers need a simulation framework that can model both kinds of computing devices and their interaction. In this paper, we present Multi2Sim, an open-source, modular, and fully configurable toolset that enables ISA-level simulation of an x86 CPU and an AMD Evergreen GPU. Focusing on a model of the AMD Radeon 5870 GPU, we address program emulation correctness, as well as architectural simulation accuracy, using AMD's OpenCL benchmark suite. Simulation capabilities are demonstrated with a preliminary architectural exploration study, and workload characterization examples. The project source code, benchmark packages, and a detailed user's guide are publicly available at www.multi2sim.org.},
  Date                     = {2012},
  Keywords                 = {graphics processing units;microprocessor chips;simulation;AMD Evergreen GPU;AMD OpenCL benchmark suite;AMD Radeon 5870 GPU;CPU-GPU computing;ISA-level simulation;Multi2Sim;architectural exploration study;open-source modular fully configurable toolset;simulation framework;workload characterization examples;Benchmark testing;Computational modeling;Computer architecture;Graphics processing units;Hardware;Kernel;VLIW;AMD;Evergreen ISA;GPU;Multi2Sim}
}

@InProceedings{Unkule2012,
  Title                    = {Automatic Restructuring of {GPU} Kernels for Exploiting Inter-thread Data Locality},
  Author                   = {Unkule, Swapneela and Shaltz, Christopher and Qasem, Apan},
  Booktitle                = {{P}roceedings of the 21st {I}nternational {C}onference on {C}ompiler {C}onstruction},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {21--40},
  Publisher                = {Springer-Verlag},
  Series                   = {CC '12},

 abstract = {Hundreds of cores per chip and support for fine-grain multithreading have made GPUs a central player in today's HPC world. For many applications, however, achieving a high fraction of peak on current GPUs, still requires significant programmer effort. A key consideration for optimizing GPU code is determining a suitable amount of work to be performed by each thread. Thread granularity not only has a direct impact on occupancy but can also influence data locality at the register and shared-memory levels. This paper describes a software framework to analyze dependencies in parallel GPU threads and perform source-level restructuring to obtain GPU kernels with varying thread granularity. The framework supports specification of coarsening factors through source-code annotation and also implements a heuristic based on estimated register pressure that automatically recommends coarsening factors for improved memory performance. We present preliminary experimental results on a select set of CUDA kernels. The results show that the proposed strategy is generally able to select profitable coarsening factors. More importantly, the results demonstrate a clear need for automatic control of thread granularity at the software level for achieving higher performance.},
  Acmid                    = {2259233},
  Date                     = {2012},
  Doi                      = {10.1007/978-3-642-28652-0_2},
  ISBN                     = {978-3-642-28651-3},
  Location                 = {Tallinn, EE},
  Numpages                 = {20}
}

@Article{Vielma2015,
  author       = {Juan Pablo Vielma},
  title        = {Mixed Integer Linear Programming Formulation Techniques},
  journaltitle = {{SIAM} Review},
  date         = {2015},
  volume       = {57},
  number       = {1},
  month        = feb,
  pages        = {3--57},
  doi          = {10.1137/130915303},
  abstract     = {A wide range of problems can be modeled as Mixed Integer Linear Programming (MIP) problems using standard formulation techniques. However, in some cases the resulting MIP can be either too weak or too large to be effectively solved by state of the art solvers. In this survey we review advanced MIP formulation techniques that result in stronger and/or smaller formulations for a wide class of problems.},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@Article{Vilches2015,
  author       = {Antonio Vilches and Rafael Asenjo and Angeles navarro and Francisco Corbera and Rub́en Gran and María Garzarán},
  title        = {Adaptive Partitioning for irregular Applications on Heterogeneous {CPU-GPU} Chips},
  journaltitle = {Procedia Computer Science},
  date         = {2015},
  volume       = {51},
  pages        = {140--149},
  doi          = {10.1016/j.procs.2015.05.213},
  abstract     = {Commodity processors are comprised of several CPU cores and one integrated GPU. To fully exploit this type of architectures, one needs to automatically determine how to partition the workload between both devices. This is specially challenging for irregular workloads, where each iteration's work is data dependent and shows control and memory divergence. In this paper, we present a novel adaptive partitioning strategy specially designed for irregular applications running on heterogeneous CPU-GPU chips. The main novelty of this work is that the size of the workload assigned to the GPU and CPU adapts dynamically to maximize the GPU and CPU utilization while balancing the workload among the devices. Our experimental results on an Intel Haswell architecture using a set of irregular benchmarks show that our approach outperforms exhaustive static and adaptive state-of-the-art approaches in terms of performance and energy consumption.},
  owner        = {andrea},
  timestamp    = {2016.05.27},
}

@InProceedings{Vuduc2010,
  Title                    = {On the Limits of {GPU} Acceleration},
  Author                   = {Vuduc, Richard and Chandramowlishwaran, Aparna and Choi, Jee and Guney, Murat and Shringarpure, Aashay},
  Booktitle                = {{P}roceedings of the 2nd {USENIX} {C}onference on {H}ot {T}opics in {P}arallelism},

  Address                  = {Berkeley, CA, USA},
  Pages                    = {13--13},
  Publisher                = {USENIX Association},
  Series                   = {HotPar'10},

 abstract = {This paper throws a small "wet blanket" on the hot topic of GPGPU acceleration, based on experience analyzing and tuning both multithreaded CPU and GPU implementations of three computations in scientific computing. These computations--(a) iterative sparse linear solvers; (b) sparse Cholesky factorization; and (c) the fast multipole method--exhibit complex behavior and vary in computational intensity and memory reference irregularity. In each case, algorithmic analysis and prior work might lead us to conclude that an idealized GPU can deliver better performance, but we find that for at least equal-effort CPU tuning and consideration of realistic workloads and calling-contexts, we can with two modern quad-core CPU sockets roughly match one or two GPUs in performance. \\Our conclusions are not intended to dampen interest in GPU acceleration; on the contrary, they should do the opposite: they partially illuminate the boundary between CPU and GPU performance, and ask architects to consider application contexts in the design of future coupled on-die CPU/GPU processors.},
  Acmid                    = {1863099},
  Date                     = {2010},
  Location                 = {Berkeley, CA, USA},
  Numpages                 = {1},
  Owner                    = {ap8213},
  Timestamp                = {2015.10.06},
  Url                      = {http://dl.acm.org/citation.cfm?id=1863086.1863099}
}

@InProceedings{Vuduc2002,
  Title                    = {Automatic Performance Tuning and Analysis of Sparse Triangular Solve},
  Author                   = {Richard Vuduc and Shoaib Kamil and Jen Hsu and Rajesh Nishtala and James W. Demmel and Katherine A. Yelick},
  Booktitle                = {{P}roceeding of the {W}orkshop on {P}erformance {O}ptimization of {H}igh-level {L}anguages and {L}ibraries ({POHLL}) at the {ACM} {I}nternational {C}onference on {S}upercomputing},

  Address                  = {New York, USA},
  Month                    = jun,
  Series                   = {ICS '02},

  Bdsk-url-2               = {http://www.ece.lsu.edu/jxr/pohll-02/papers/vuduc.pdf},
  Cvsidenote               = {Winner, Best Presentation; Winner, Best Student Paper},
  Date                     = {2002},
  Date-added               = {2009-08-27 10:11:50 -0400},
  Date-modified            = {2010-03-16 08:52:47 -0400},
  Location                 = {Venice, IT},
  Owner                    = {andrea},
  Timestamp                = {2016.09.07},
  Topic                    = {sparse linear algebra; performance modeling; autotuning},
  Url                      = {http://bebop.cs.berkeley.edu/pubs/vuduc2002-sts-bounds.pdf}
}

@Article{Waechter2006,
  author       = {Waechter, A. and Biegler, L.T.},
  title        = {On the Implementation of an Interior-point Filter Line-search Algorithm for Large-scale Nonlinear Programming},
  journaltitle = {Mathematical Programming},
  date         = {2006},
  volume       = {106},
  number       = {1},
  month        = may,
  pages        = {25--57},
  issn         = {0025-5610},
  doi          = {10.1007/s10107-004-0559-y},
  abstract     = {We present a primal-dual interior-point algorithm with a filter line-search method for nonlinear programming. Local and global convergence properties of this method were analyzed in previous work. Here we provide a comprehensive description of the algorithm, including the feasibility restoration phase for the filter method, second-order corrections, and inertia correction of the KKT matrix. Heuristics are also considered that allow faster performance. This method has been implemented in the IPOPT code, which we demonstrate in a detailed numerical study based on 954 problems from the CUTEr test set. An evaluation is made of several line-search options, and a comparison is provided with two state-of-the-art interior-point codes for nonlinear programming.},
  acmid        = {1107695},
  issue_date   = {May 2006},
  keywords     = {65K05, 90C30, 90C51},
  location     = {Secaucus, NJ, USA},
  numpages     = {33},
  owner        = {ap8213},
  publisher    = {Springer-Verlag New York, Inc.},
  timestamp    = {2014.10.09},
}

@InProceedings{Wang2016,
  Title                    = {Gunrock: A High-performance Graph Processing Library on the {GPU}},
  Author                   = {Wang, Yangzihao and Davidson, Andrew and Pan, Yuechao and Wu, Yuduo and Riffel, Andy and Owens, John D.},
  Booktitle                = {{P}roceedings of the 21st {ACM SIGPLAN} {S}ymposium on {P}rinciples and {P}ractice of {P}arallel {P}rogramming},

  Address                  = {New York, NY, USA},
  Pages                    = {11:1--11:12},
  Publisher                = {ACM},
  Series                   = {PPoPP '16},

 abstract = {For large-scale graph analytics on the GPU, the irregularity of data access/control flow and the complexity of programming GPUs have been two significant challenges for developing a programmable high-performance graph library. "Gunrock," our high-level bulk-synchronous graph-processing system targeting the GPU, takes a new approach to abstracting GPU graph analytics: rather than designing an abstraction around computation, Gunrock instead implements a novel data-centric abstraction centered on operations on a vertex or edge frontier. Gunrock achieves a balance between performance and expressiveness by coupling high-performance GPU computing primitives and optimization strategies with a high-level programming model that allows programmers to quickly develop new graph primitives with small code size and minimal GPU programming knowledge. We evaluate Gunrock on five graph primitives (BFS, BC, SSSP, CC, and PageRank) and show that Gunrock has on average at least an order of magnitude speedup over Boost and PowerGraph, comparable performance to the fastest GPU hardwired primitives, and better performance than any other GPU high-level graph library.},
  Acmid                    = {2851145},
  Articleno                = {11},
  Date                     = {2016},
  Doi                      = {10.1145/2851141.2851145},
  ISBN                     = {978-1-4503-4092-2},
  Location                 = {Barcelona, ES},
  Numpages                 = {12}
}

@TechReport{Whitehead2011,
  author      = {Whitehead, Nathan and Fit-Florea, Alex},
  title       = {Precision \& performance: Floating point and {IEEE} 754 compliance for NVIDIA {GPU}s},
  institution = {NVIDIA Corporation},
  date        = {2011},
  number      = {1},
  url         = {http://docs.nvidia.com/cuda/floating-point/#axzz4gbha7lKQ},
  owner       = {andrea},
  timestamp   = {2017.05.08},
  volume      = {21},
}

@Article{Wilson2010,
  author       = {Wilson, G. and Banzhaf, W.},
  title        = {Deployment of parallel linear genetic programming using {GPU}s on {PC} and video game console platforms},
  journaltitle = {Genetic Programming and Evolvable Machines},
  date         = {2010},
  language     = {English},
  volume       = {11},
  number       = {2},
  pages        = {147--184},
  issn         = {1389--2576},
  doi          = {10.1007/s10710-010-9102-5},
  abstract     = {We present a general method for deploying parallel linear genetic programming (LGP) to the PC and Xbox 360 video game console by using a publicly available common framework for the devices called XNA (for XNA's Not Acronymed). By constructing the LGP within this framework, we effectively produce an LGP game for PC and XBox 360 that displays results as they evolve. We use the GPU of each device to parallelize fitness evaluation and the mutation operator of the LGP algorithm, thus providing a general LGP implementation suitable for parallel computation on heterogeneous devices. While parallel GP implementations on PCs are now common, both the implementation of GP on a video game console using GPU and the construction of a GP around a framework for heterogeneous devices are novel contributions. The objective of this work is to describe how to implement the parallel execution of LGP in order to use the underlying hardware (especially GPU) on the different platforms while still maintaining loyalty to the general methodology of the LGP algorithm built for the common framework. We discuss the implementation of texture-based data structures and the sequential and parallel algorithms built for their use on both CPU and GPU. Following the description of the general algorithm, the particular tailoring of the implementations for each hardware platform is described. Sequential (CPU) and parallel (GPU-based) algorithm performance is compared on both PC and video game platforms using the metrics of GP operations per second, actual time elapsed, speedup of parallel over sequential implementation, and percentage of execution time used by the GPU versus CPU.},
  keywords     = {Genetic programming; Parallel processing; SIMD; Graphics processing unit (GPU); GPGPU; Xbox 360; Heterogeneous devices},
  owner        = {ap8213},
  publisher    = {Springer US},
  timestamp    = {2014.10.09},
}

@InProceedings{Wolf2011,
  author    = {Wolf, Michael M. and Heroux, Michael A. and Boman, Erik G.},
  title     = {Factors Impacting Performance of Multithreaded Sparse Triangular Solve},
  booktitle = {{P}roceedings of the 9th {I}nternational {C}onference on {H}igh {P}erformance {C}omputing for {C}omputational {S}cience},
  date      = {2011},
  series    = {VECPAR '10},
  publisher = {Springer-Verlag},
  location  = {Berkeley, CA, USA},
  isbn      = {978-3-642-19327-9},
  pages     = {32--44},
  url       = {http://dl.acm.org/citation.cfm?id=1964246},
  abstract  = {As computational science applications grow more parallel with multi-core supercomputers having hundreds of thousands of computational cores, it will become increasingly difficult for solvers to scale. Our approach is to use hybrid MPI/threaded numerical algorithms to solve these systems in order to reduce the number of MPI tasks and increase the parallel efficiency of the algorithm. However, we need efficient threaded numerical kernels to run on the multi-core nodes in order to achieve good parallel efficiency. In this paper, we focus on improving the performance of a multithreaded triangular solver, an important kernel for preconditioning. We analyze three factors that affect the parallel performance of this threaded kernel and obtain good scalability on the multi-core nodes for a range of matrix sizes.},
  acmid     = {1964246},
  address   = {Berlin, Heidelberg},
  numpages  = {13},
}

@PhdThesis{Wolter2006,
  author      = {Kati Wolter},
  title       = {Implementation of Cutting Plane Separators for Mixed Integer Programs},
  institution = {Technische Universität Berlin},
  date        = {2006},
  owner       = {andrea},
  timestamp   = {2015.09.28},
}

@InProceedings{Wu2009,
  author    = {Chih-Hung Wu and Seda Ogrenci Memik and Sanjay Merothra},
  title     = {{FPGA} implementation of the interior-point algorithm with applications to collision detection},
  booktitle = {{P}roceedings of the 17th {IEEE} {S}ymposium on {F}ield {P}rogrammable {C}ustom {C}omputing {M}achines},
  date      = {2009},
  series    = {FCCM '09},
  location  = {Napa Valley, CA, USA},
  month     = apr,
  pages     = {295--298},
  doi       = {10.1109/FCCM.2009.38},
  abstract  = {The interior-point algorithm is a powerful method for solving a Linear Program (LP). A variety of optimization problems can be formulated as LPs. Often times the limiting factor of deploying an algorithm to solve LPs in a high performance system is the run-time efficiency. In this paper, we present the FPGA implementation of an affine interior-point algorithm that is designed to solve LPs. Specifically, we present the application of this algorithm to solving the LP for the real-time collision detection. The most important feature that distinguishes this particular algorithm from other collision detection methods is its superior ability to perform detection between pairs of objects undergoing fast rotational and translational motions.},
  keywords  = {field programmable gate arrays;linear programming;FPGA;collision detection;interior-point algorithm;linear program;optimization problems;Acceleration;Application software;Field programmable gate arrays;Hardware;Linear programming;Mathematical programming;Object detection;Parallel processing;Solids;Sparse matrices;inter-frame collision;interior point;linear programming},
  owner     = {andrea},
  timestamp = {2017.05.08},
}

@Article{Wu2013,
  Title                    = {A preconditioned conjugate gradient algorithm for {GeneRank} with application to microarray data mining},
  Author                   = {Wu, Gang and Xu, Wei and Zhang, Ying and Wei, Yimin},
  Number                   = {1},
  Pages                    = {27--56},
  Volume                   = {26},

 abstract = {The problem of identifying key genes is of fundamental importance in biology and medicine. The GeneRank model explores connectivity data to produce a prioritization of the genes in a microarray experiment that is less susceptible to variation caused by experimental noise than the one based on expression levels alone. The GeneRank algorithm amounts to solving an unsymmetric linear system. However, when the matrix in question is very large, the GeneRank algorithm is inefficient and even can be infeasible. On the other hand, the adjacency matrix is symmetric in the GeneRank model, while the original GeneRank algorithm fails to exploit the symmetric structure of the problem in question. In this paper, we discover that the GeneRank problem can be rewritten as a symmetric positive definite linear system, and propose a preconditioned conjugate gradient algorithm to solve it. Numerical experiments support our theoretical results, and show superiority of the novel algorithm.},
  Date                     = {2013},
  Doi                      = {10.1007/s10618-011-0245-7},
  ISSN                     = {1573-756X},
  Journaltitle             = {Data Mining and Knowledge Discovery},
  Owner                    = {andrea},
  Timestamp                = {2016.06.14}
}

@PhdThesis{Wunderling1996,
  author      = {Roland Wunderling},
  title       = {Paralleler und objektorientierter {S}implex-{A}lgorithmus},
  institution = {Technische Universität Berlin},
  date        = {1996},
  language    = {German},
}

@InProceedings{Yoo2013,
  author    = {Yoo, Richard M. and Hughes, Christopher J. and Kim, Changkyu and Chen, Yen-Kuang and Kozyrakis, Christos},
  title     = {Locality-aware Task Management for Unstructured Parallelism: A Quantitative Limit Study},
  booktitle = {{P}roceedings of the 25th {A}nnual {ACM} {S}ymposium on {P}arallelism in {A}lgorithms and {A}rchitectures},
  date      = {2013},
  series    = {SPAA '13},
  publisher = {ACM},
  location  = {Montréal, QB, Canada},
  isbn      = {978-1-4503-1572-2},
  pages     = {315--325},
  doi       = {10.1145/2486159.2486175},
 abstract = {As we increase the number of cores on a processor die, the on-chip cache hierarchies that support these cores are getting larger, deeper, and more complex. As a result, non-uniform memory access effects are now prevalent even on a single chip. To reduce execution time and energy consumption, data access locality should be exploited. This is especially important for task-based programming systems, where a scheduler decides when and where on the chip the code segments, i.e., tasks, should execute. Capturing locality for structured task parallelism has been done effectively, but the more difficult case, unstructured parallelism, remains largely unsolved - little quantitative analysis exists to demonstrate the potential of locality-aware scheduling, and to guide future scheduler implementations in the most fruitful direction. \\ This paper quantifies the potential of locality-aware scheduling for unstructured parallelism on three different many-core processors. Our simulation results of 32-core systems show that locality-aware scheduling can bring up to 2.39$\times$ speedup over a randomized schedule, and 2.05$\times$ speedup over a state-of-the-art baseline scheduling scheme. At the same time, a locality-aware schedule reduces average energy consumption by 55\% and 47\%, relative to the random and the baseline schedule, respectively. In addition, our 1024-core simulation results project that these benefits will only increase: Compared to 32-core executions, we see up to 1.83$\times$ additional locality benefits. To capture such potentials in a practical setting, we also perform a detailed scheduler design space exploration to quantify the impact of different scheduling decisions. We also highlight the importance of locality-aware stealing, and demonstrate that a stealing scheme can exploit significant locality while performing load balancing. Over randomized stealing, our proposed scheme shows up to 2.0$\times$ speedup for stolen tasks.},
  acmid     = {2486175},
  address   = {New York, NY, USA},
  keywords  = {energy, locality, performance, task scheduling, task stealing},
  numpages  = {11},
}

@InProceedings{Zhang2006,
  Title                    = {A Hierarchical Model of Data Locality},
  Author                   = {Zhang, Chengliang and Ding, Chen and Ogihara, Mitsunori and Zhong, Yutao and Wu, Youfeng},
  Booktitle                = {{C}onference {R}ecord of the 33rd {ACM SIGPLAN-SIGACT} {S}ymposium on {P}rinciples of {P}rogramming {L}anguages},

  Address                  = {New York, NY, USA},
  Pages                    = {16--29},
  Publisher                = {ACM},
  Series                   = {POPL '06},

 abstract = {In POPL 2002, Petrank and Rawitz showed a universal result---finding optimal data placement is not only NP-hard but also impossible to approximate within a constant factor if P $\neq$ NP. Here we study a recently published concept called reference affinity, which characterizes a group of data that are always accessed together in computation. On the theoretical side, we give the complexity for finding reference affinity in program traces, using a novel reduction that converts the notion of distance into satisfiability. We also prove that reference affinity automatically captures the hierarchical locality in divide-and-conquer computations including matrix solvers and N-body simulation. The proof establishes formal links between computation patterns in time and locality relations in space.On the practical side, we show that efficient heuristics exist. In particular, we present a sampling method and show that it is more effective than the previously published technique, especially for data that are often but not always accessed together. We show the effect on generated and real traces. These theoretical and empirical results demonstrate that effective data placement is still attainable in general-purpose programs because common (albeit not all) locality patterns can be precisely modeled and efficiently analyzed.},
  Acmid                    = {1111040},
  Date                     = {2006},
  Doi                      = {10.1145/1111037.1111040},
  ISBN                     = {1-59593-027-2},
  Keywords                 = {N-body simulation, NP-complete, hierarchical data placement, program locality, reference affinity, volume distance},
  Location                 = {Charleston, SC, USA},
  Numpages                 = {14}
}

@InProceedings{Zhang2009,
  author    = {Y. Zhang and Y. H. Shalabi and R. Jain and K. K. Nagar and J. D. Bakos},
  title     = {{FPGA} vs. {GPU} for sparse matrix vector multiply},
  booktitle = {Proceedings of the 2009 International Conference on Field-Programmable Technology},
  date      = {2009},
  series    = {FPT '09},
  location  = {Sydney, NSW, AUS},
  month     = dec,
  pages     = {255--262},
  doi       = {10.1109/FPT.2009.5377620},
  abstract  = {Sparse matrix-vector multiplication (SpMV) is a common operation in numerical linear algebra and is the computational kernel of many scientific applications. It is one of the original and perhaps most studied targets for FPGA acceleration. Despite this, GPUs, which have only recently gained both general-purpose programmability and native support for double precision floating-point arithmetic, are viewed by some as a more effective platform for SpMV and similar linear algebra computations. In this paper, we present an analysis comparing an existing GPU SpMV implementation to our own, novel FPGA implementation. In this analysis, we describe the challenges faced by any SpMV implementation, the unique approaches to these challenges taken by both FPGA and GPU implementations, and their relative performance for SpMV.},
  keywords  = {coprocessors;field programmable gate arrays;sparse matrices;FPGA acceleration;FPGA implementation;GPU implementation;SpMV implementation;computational kernel;field programmable gate arrays;graphics processing unit;linear algebra computation;numerical linear algebra;precision floating-point arithmetic;programmability;sparse matrix vector multiplication;Acceleration;Biological system modeling;Biology computing;Computer architecture;Field programmable gate arrays;Kernel;Linear algebra;Scientific computing;Sparse matrices;Vectors},
}

@Article{Zhao2015,
  Title                    = {Optimal home energy management system with mixed types of loads},
  Author                   = {C. Zhao and S. Dong and F. Li and Y. Song},

  Month                    = dec,
  Number                   = {4},
  Pages                    = {29--37},
  Volume                   = {1},

 abstract = {This paper presents a novel home area energy management system (HEMS) for smart homes with different load profiles installed with photovoltaic generation, energy storage, and DC demand. The developed HEMS is shown to optimize the utilization of local renewables while minimizing energy waste between AC and DC conversions and between storage charging and discharging. Previous studies on HEMS have not considered the impact of load types. In this study, the performance of the proposed HEMS is demonstrated on different smart homes with and without electric heating. A comparative study is carried out to investigate battery behavior, characteristics of AC and DC conversion, and benefits that customers receive. A sensitivity analysis is also conducted to discuss the effects from varied energy storage capacities, AC/DC conversion efficiencies, and PV output. The results show that cost reduction in energy bills can be greatly impacted by load profiles, and customers with electric heating load coupled with sufficiently large energy storage would receive the most reduction in their energy bills.},
  Date                     = {2015},
  Doi                      = {10.17775/CSEEJPES.2015.00045},
  Journaltitle             = {{CSEE} Journal of Power and Energy Systems},
  Series                   = {PP}
}

@Article{Zhong2014,
  author       = {Zhong, Jianlong and He, Bingsheng},
  title        = {Medusa: Simplified Graph Processing on GPUs},
  journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
  date         = {2014},
  volume       = {25},
  number       = {6},
  month        = jun,
  pages        = {1543--1552},
  issn         = {1045-9219},
  doi          = {10.1109/TPDS.2013.111},
 abstract = {Graphs are common data structures for many applications, and efficient graph processing is a must for application performance. Recently, the graphics processing unit (GPU) has been adopted to accelerate various graph processing algorithms such as BFS and shortest paths. However, it is difficult to write correct and efficient GPU programs and even more difficult for graph processing due to the irregularities of graph structures. To simplify graph processing on GPUs, we propose a programming framework called Medusa which enables developers to leverage the capabilities of GPUs by writing sequential C/C++ code. Medusa offers a small set of user-defined APIs and embraces a runtime system to automatically execute those APIs in parallel on the GPU. We develop a series of graph-centric optimizations based on the architecture features of GPUs for efficiency. Additionally, Medusa is extended to execute on multiple GPUs within a machine. Our experiments show that 1) Medusa greatly simplifies implementation of GPGPU programs for graph processing, with many fewer lines of source code written by developers and 2) the optimization techniques significantly improve the performance of the runtime system, making its performance comparable with or better than manually tuned GPU graph operations.},
  acmid        = {2707627},
  issue_date   = {June 2014},
  location     = {Piscataway, NJ, USA},
  numpages     = {10},
  publisher    = {IEEE Press},
}

@Proceedings{Feo2011,
  Title                    = {Proceedings of the First Workshop on Irregular Applications: Architectures and Algorithms},

  Address                  = {New York, NY, USA},
  Editor                   = {John Feo and Oreste Villa and Antonino Tumeo and Simone Secchi},
  Publisher                = {ACM},
  Series                   = {IAAA '11},

 abstract = {Irregular applications are characterized by irregular data structures, control and communication patterns. Novel irregular high performance applications which deal with large data sets and require have recently appeared. Unfortunately, current high performance systems and software infrastructures executes irregular algorithms poorly. Only coordinated efforts by end user, area specialists and computer scientists that consider both the architecture and the software stack may be able to provide solutions to the challenges of modern irregular applications.},
  Acmid                    = {2089144},
  Booktitle                = {{P}roceedings of the {F}irst {W}orkshop on {I}rregular {A}pplications: {A}rchitectures and {A}lgorithms},
  Date                     = {2011},
  Doi                      = {10.1145/2089142.2089144},
  ISBN                     = {978-1-4503-1121-2},
  Keywords                 = {algorithms, architectures, irregular applications},
  Location                 = {Seattle, WA, USA},
  Numpages                 = {2},
  Owner                    = {andrea},
  Pages                    = {1--2},
  Timestamp                = {2016.09.07}
}

@Manual{Altera2013,
  Title                    = {Implementing {FPGA} Design with the {OpenCL} Standard},
  Month                    = nov,

  Date                     = {2013},
  Institution              = {Altera Corporation},
  Owner                    = {andrea},
  Timestamp                = {2015.01.30},
  Type                     = {Whitepaper},
  Url                      = {http://www.altera.co.uk/literature/wp/wp-01173-opencl.pdf}
}

@TechReport{Amd2012,
  Title                    = {{AMD} Graphics Cores Next ({GCN}) Architecture},
  Institution              = {{AMD} Corporation},
  Note                     = {Accessed on 21 June 2017},
  Type                     = {Online},

  Date                     = {2012},
  Url                      = {https://www.amd.com/Documents/GCN_Architecture_whitepaper.pdf}
}

@Misc{Amd2014,
  Title                    = {{AMD} {F}irePro {W}5000},
  HowPublished             = {Online},

  Date                     = {2014},
  Organization             = {AMD Corporation},
  Owner                    = {andrea},
  Timestamp                = {2016.03.17},
  Url                      = {http://www.amd.com/documents/2795_W5000_DataSheet_R3.pdf}
}

@Online{Clsparse2016,
  Title                    = {{clSPARSE} Documentation},
  Date                     = {2016},
  Url                      = {http://clmathlibraries.github.io/clSPARSE/},

  Note                     = {Accessed on 10 May 2017},

  Owner                    = {andrea},
  Timestamp                = {2017.05.10},
  Version                  = {0.10.0.0}
}

@TechReport{CommitteeClimateChange2013,
  title       = {Meeting Carbon Budgets: 2013 Progress Report to Parliament},
  institution = {The Committee on Climate Change},
  date        = {2013},
  chapter     = {3},
  url         = {http://www.theccc.org.uk/wp-content/uploads/2013/06/CCC-Prog-Rep_Chap3_singles_web_1.pdf},
  owner       = {ap8213},
  page        = {110},
  timestamp   = {2014.10.09},
}

@Manual{CPLEX2011,
  title        = {{CPLEX} User's manual},
  date         = {2011},
  edition      = {12.4},
  note         = {Accessed 30 March 2014},
  organization = {IBM corporation},
  url          = {http://pic.dhe.ibm.com/infocenter/cosinfoc/v12r4/topic/ilog.odms.studio.help/pdf/usrcplex.pdf},
  owner        = {andrea},
  timestamp    = {2014.03.30},
}

@Manual{Cublas2015,
  Title                    = {{CUBLAS} Library User Guide},
  Edition                  = {7.5},
  Month                    = oct,
  Organization             = {NVIDIA},

  Date                     = {2015},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07},
  Url                      = {http://docs.nvidia.com/cuda/pdf/CUBLAS_Library.pdf}
}

@Manual{CUDA2013,
  title        = {{CUDA} Toolkit Documentation},
  date         = {2013},
  language     = {English},
  edition      = {5.5},
  note         = {Accessed 1 March 2014},
  organization = {{Nvidia corporation}},
  url          = {http://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html},
  month        = oct,
  owner        = {andrea},
  timestamp    = {2014.03.05},
}

@TechReport{Cuda65P,
  Title                    = {{CUDA} 6.5 performance report},
  Institution              = {NVIDIA Corporation},
  Month                    = sep,
  Note                     = {Accessed 20 July 2016},

  Date                     = {2014},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07},
  Url                      = {http://developer.download.nvidia.com/compute/cuda/6_5/rel/docs/CUDA_6.5_Performance_Report.pdf}
}

@TechReport{Cuda70P,
  Title                    = {{CUDA} 7.0 performance report},
  Institution              = {NVIDIA Corporation},
  Month                    = may,
  Note                     = {Accessed 20 July 2016},

  Date                     = {2015},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07},
  Url                      = {http://developer.download.nvidia.com/compute/cuda/compute-docs/cuda-performance-report.pdf}
}

@TechReport{CudaK20B,
  Title                    = {{NVIDIA} Tesla {K20}-{K20X} {GPU} Accelerators -- Benchmarks},
  Institution              = {NVIDIA Corporation},
  Note                     = {Accessed 20 July 2016},

  Date                     = {2012},
  Owner                    = {andrea},
  Timestamp                = {2016.11.07},
  Url                      = {http://www.nvidia.com/docs/IO/122874/K20-and-K20X-application-performance-technical-brief.pdf}
}

@Manual{Cusparse2015,
  Title                    = {{CUSPARSE} library},
  Edition                  = {7.0},
  Month                    = mar,
  Note                     = {Accessed 1 September 2015.},
  Organization             = {NVIDIA corporation},

  Date                     = {2015},
  Owner                    = {ap8213},
  Timestamp                = {2015.09.28},
  Url                      = {https://developer.nvidia.com/cuda-toolkit-70}
}

@Manual{GLPK2010,
  title        = {{GNU} Linear Programming Kit Reference Manual},
  date         = {2010},
  organization = {Free Software Foundation},
  url          = {http://kam.mff.cuni.cz/~elias/glpk.pdf},
  owner        = {andrea},
  timestamp    = {2014.12.14},
}

@Misc{ImperialHpc,
  title = {Imperial College High Performance Computing Service},
  year  = {2017},
  url   = {http://www.imperial.ac.uk/admin-services/ict/self-service/research-support/hpc/},
}

@TechReport{Intel2015,
  Title                    = {The Compute Architecture of Intel Processor Graphics {Gen9}},
  Institution              = {Intel Corporation},

  Date                     = {2015},
  Owner                    = {andrea},
  Timestamp                = {2017.04.27},
  Url                      = {https://software.intel.com/sites/default/files/managed/c5/9a/The-Compute-Architecture-of-Intel-Processor-Graphics-Gen9-v1d0.pdf}
}

@Misc{IntelI3,
  title        = {Intel Core i3-2130 Processor},
  date         = {2011},
  howpublished = {Online},
  note         = {Accessed 13 October 2016},
  organization = {Intel Corporation},
  url          = {http://ark.intel.com/products/53428/Intel-Core-i3-2130-Processor-3M-Cache-3_40-GHz},
  owner        = {andrea},
  timestamp    = {2016.03.17},
}

@Misc{IntelXeonE5,
  Title                    = {{Intel} {Xeon} Processor {E5-2640 v3}},
  HowPublished             = {Online},
  Note                     = {Accessed 13 October 2016},

  Date                     = {2014},
  Organization             = {Intel Corporation},
  Owner                    = {andrea},
  Timestamp                = {2016.03.17},
  Url                      = {http://ark.intel.com/products/83359/Intel-Xeon-Processor-E5-2640-v3-20M-Cache-2_60-GHz}
}

@Misc{Nvidia2013,
  Title                    = {{NVIDIA} professional graphics solution},
  HowPublished             = {Online},
  Month                    = jul,

  Date                     = {2013},
  Organization             = {NVIDIA Corporation},
  Owner                    = {andrea},
  Timestamp                = {2016.03.17},
  Url                      = {http://www.nvidia.co.uk/content/PDF/line_card/6660-nv-prographicssolutions-linecard-july13-final-lr.pdf}
}

@TechReport{NvidiaFermi2009,
  Title                    = {{NVIDIA}'s Next Generation {CUDA} Compute Architecture: Fermi},
  Institution              = {NVIDIA Corporation},

  Date                     = {2009},
  Url                      = {http://www.nvidia.it/content/PDF/fermi_white_papers/NVIDIA_Fermi_Compute_Architecture_Whitepaper.pdf}
}

@Misc{NvidiaGt430,
  Title                    = {{NVIDIA} {GeForce} {GT} 430},
  HowPublished             = {Online},
  Note                     = {Accessed 13 October 2016},

  Date                     = {2010},
  Organization             = {NVIDIA corporation},
  Owner                    = {andrea},
  Timestamp                = {2016.03.17},
  Url                      = {http://www.nvidia.com/object/product-geforce-gt-430-oem-us.html}
}

@Misc{NvidiaK80,
  Title                    = {{NVIDIA} Tesla {GPU} Accelerators},
  HowPublished             = {Online},
  Note                     = {Accessed 13 October 2016},

  Date                     = {2014},
  Organization             = {NVIDIA corporation},
  Owner                    = {andrea},
  Timestamp                = {2016.03.17},
  Url                      = {http://international.download.nvidia.com/pdf/kepler/TeslaK80-datasheet.pdf}
}

@Manual{OpenMP2008,
  title        = {{OpenMP} application program interface},
  date         = {2008},
  edition      = {3},
  organization = {{OpenMP Architecture Review Board}},
  url          = {http://www.openmp.org/mp-documents/spec30.pdf},
  month        = may,
  owner        = {andrea},
  timestamp    = {2014.03.28},
}

@Misc{Oracle2014,
  Title                    = {x86 Assembly Language Reference Manual},
  HowPublished             = {Online},
  Note                     = {Accessed 4 June 2017},

  Date                     = {2014},
  Organization             = {Oracle},
  Url                      = {http://docs.oracle.com/cd/E36784_01/html/E36859/docinfo.html#scrolltoc}
}

@Manual{Paralution2016,
  title     = {Paralution - User Manual},
  date      = {2016},
  version   = {1.1.0},
  url       = {http://www.paralution.com/downloads/paralution-um.pdf},
  owner     = {andrea},
  timestamp = {2017.05.10},
}

@Online{Phist2016,
  Title                    = {{PHIST} - a Pipelined Hybrid Parallel Iterative Solver Toolkit},
  Date                     = {2016},
  Url                      = {https://bitbucket.org/essex/phist/wiki/Getting_Started/Overview},

  Note                     = {Git repository, Accessed 10 May 2017},

  Owner                    = {andrea},
  Timestamp                = {2017.05.10}
}

@Manual{SDAccel2014,
  Title                    = {The {Xilinx} {SDAccel} Development Environment},

  Date                     = {2014},
  Institution              = {Xilinx Inc.},
  Owner                    = {andrea},
  Timestamp                = {2015.01.30},
  Url                      = {http://www.xilinx.com/publications/prod_mktg/sdnet/sdaccel-backgrounder.pdf}
}

@Online{Spral2014,
  Title                    = {The Sparse Parallel Robust Algorithms Library ({SPRAL})},
  Date                     = {2014},
  Url                      = {http://www.numerical.rl.ac.uk/spral/},
  Organization             = {Numerical Analysis Group, Rutherford Appleton Laboratory}
}

@Manual{Virtex7,
  title       = {7 Series {FPGA} Overview},
  date        = {2014},
  type        = {Product Specification},
  number      = {1.16.1},
  url         = {https://www.xilinx.com/support/documentation/data_sheets/ds180_7Series_Overview.pdf},
  institution = {Xilinx Inc.},
  month       = dec,
  owner       = {andrea},
  timestamp   = {2015.01.29},
}

@Manual{Kincaid1989,
  author = {D. R. Kincaid and T. C. Oppe and D. M. Young},
  title  = {{ITPACKV} {2D} User's Guide},
  date   = {1989},
  url    = {http://www.netlib.no/netlib/itpack/index.html},
  month  = may,
}

@InProceedings{Liu2015,
  author    = {Liu, Weifeng and Vinter, Brian},
  title     = {{CSR5}: An Efficient Storage Format for Cross-Platform Sparse Matrix-Vector Multiplication},
  booktitle = {Proceedings of the 29th {ACM} International Conference on Supercomputing},
  date      = {2015},
  series    = {ICS '15},
  publisher = {ACM},
  location  = {Newport Beach, CA, USA},
  isbn      = {978-1-4503-3559-1},
  pages     = {339--350},
  doi       = {10.1145/2751205.2751209},
 abstract = {Sparse matrix-vector multiplication (SpMV) is a fundamental building block for numerous applications. In this paper, we propose CSR5 (Compressed Sparse Row 5), a new storage format, which offers high-throughput SpMV on various platforms including CPUs, GPUs and Xeon Phi. First, the CSR5 format is insensitive to the sparsity structure of the input matrix. Thus the single format can support an SpMV algorithm that is efficient both for regular matrices and for irregular matrices. Furthermore, we show that the overhead of the format conversion from the CSR to the CSR5 can be as low as the cost of a few SpMV operations.\\We compare the CSR5-based SpMV algorithm with 11 state-of-the-art formats and algorithms on four mainstream processors using 14 regular and 10 irregular matrices as a benchmark suite. For the 14 regular matrices in the suite, we achieve comparable or better performance over the previous work. For the 10 irregular matrices, the CSR5 obtains average performance improvement of 17.6\%, 28.5\%, 173.0\% and 293.3\% (up to 213.3\%, 153.6\%, 405.1\% and 943.3\%) over the best existing work on dual-socket Intel CPUs, an nVidia GPU, an AMD GPU and an Intel Xeon Phi, respectively. For real-world applications such as a solver with only tens of iterations, the CSR5 format can be more practical because of its low-overhead for format conversion.},
  acmid     = {2751209},
  address   = {New York, NY, USA},
  keywords  = {cpu, csr, csr5, gpu, sparse matrices, spmv, storage formats, xeon phi},
  numpages  = {12},
}

@Article{Fong2011,
  author       = {David Chin-Lung Fong and Michael Saunders},
  title        = {{LSMR}: An Iterative Algorithm for Sparse Least-Squares Problems},
  journaltitle = {{SIAM} Journal on Scientific Computing},
  date         = {2011},
  volume       = {33},
  number       = {5},
  pages        = {2950--2971},
  doi          = {10.1137/10079687X},
  url          = { 
        https://doi.org/10.1137/10079687X
    
},
 abstract = {An iterative method LSMR is presented for solving linear systems $Ax=b$ and least-squares problems $\min \|Ax-b\|_2$, with A being sparse or a fast linear operator. LSMR is based on the Golub–Kahan bidiagonalization process. It is analytically equivalent to the MINRES method applied to the normal equation $A^T\! Ax = A^T\! b$, so that the quantities $\|A^T\! r_k\|$ are monotonically decreasing (where $r_k = b - Ax_k$ is the residual for the current iterate $x_k$). We observe in practice that $\|r_k\|$ also decreases monotonically, so that compared to LSQR (for which only $\|r_k\|$ is monotonic) it is safer to terminate LSMR early. We also report some experiments with reorthogonalization.},
}

@Article{Agullo2009,
  author       = {Emmanuel Agullo and Jim Demmel and Jack Dongarra and Bilel Hadri and Jakub Kurzak and Julien Langou and Hatem Ltaief and Piotr Luszczek and Stanimire Tomov},
  title        = {Numerical linear algebra on emerging architectures: The {PLASMA} and {MAGMA} projects},
  journaltitle = {Journal of Physics: Conference Series},
  date         = {2009},
  volume       = {180},
  number       = {1},
  pages        = {012037},
  url          = {http://stacks.iop.org/1742-6596/180/i=1/a=012037},
 abstract = {The emergence and continuing use of multi-core architectures and graphics processing units require changes in the existing software and sometimes even a redesign of the established algorithms in order to take advantage of now prevailing parallelism. Parallel Linear Algebra for Scalable Multi-core Architectures (PLASMA) and Matrix Algebra on GPU and Multics Architectures (MAGMA) are two projects that aims to achieve high performance and portability across a wide range of multi-core architectures and hybrid systems respectively. We present in this document a comparative study of PLASMA's performance against established linear algebra packages and some preliminary results of MAGMA on hybrid multi-core and GPU systems.},
}

@InProceedings{Shinano2012,
  author    = {Yuji Shinano and Tobias Achterberg and Timo Berthold and Stefan Heinz and Thorsten Koch},
  title     = {{ParaSCIP}: a parallel extension of {SCIP}},
  booktitle = {Competence in High Performance Computing},
  date      = {2012},
  editor    = {Christian Bischof and Heinz-Gerd Hegering and Wolfgang Nagel and Gabriel Wittum},
  pages     = {135--148},
  doi       = {10.1007/978-3-642-24025-6_12},
 abstract = {Mixed integer programming (MIP) has become one of the most important techniques in Operations Research and Discrete Optimization. SCIP (Solving Constraint Integer Programs) is currently one of the fastest non-commercial MIP solvers. It is based on the branch-and-bound procedure in which the problem is recursively split into smaller subproblems, thereby creating a so-called branching tree. We present ParaSCIP, an extension of SCIP, which realizes a parallelization on a distributed memory computing environment. ParaSCIP uses SCIP solvers as independently running processes to solve subproblems (nodes of the branching tree) locally. This makes the parallelization development independent of the SCIP development. Thus, ParaSCIP directly profits from any algorithmic progress in future versions of SCIP. Using a first implementation of ParaSCIP, we were able to solve two previously unsolved instances from MIPLIB2003, a standard test set library for MIP solvers. For these computations, we used up to 2048 cores of the HLRN~II supercomputer.},
}

@TechReport{Shinano2013,
  author      = {Yuji Shinano and Stefan Heinz and Stefan Vigerske and Michael Winkler},
  title       = {{FiberSCIP}: A shared memory parallelization of {SCIP}},
  institution = {ZIB},
  date        = {2013},
  number      = {13--55},
  location    = {Takustr.7, 14195 Berlin},
 abstract = {Recently, parallel computing environments have become significantly popular. In order to obtain the benefit of using parallel computing environments, we have to deploy our programs for these effectively. This paper focuses on a parallelization of SCIP (Solving Constraint Integer Programs), which is a MIP solver and constraint integer programming framework available in source code. There is a parallel extension of SCIP named ParaSCIP, which parallelizes SCIP on massively parallel distributed memory computing environments. This paper describes FiberSCIP, which is yet another parallel extension of SCIP to utilize multi-threaded parallel computation on shared memory computing environments, and has the following contributions: First, the basic concept of having two parallel extensions and the relationship between them and the parallelization framework provided by UG (Ubiquity Generator) is presented, including an implementation of deterministic parallelization. Second, the difficulties to achieve a good performance that utilizes all resources on an actual computing environment and the difficulties of performance evaluation of the parallel solvers are discussed. Third, a way to evaluate the performance of new algorithms and parameter settings of the parallel extensions is presented. Finally, current performance of FiberSCIP for solving mixed-integer linear programs (MIPs) and mixed-integer non-linear programs (MINLPs) in parallel is demonstrated.},
  urn         = {urn:nbn:de:0297-zib-42595},
}

@InProceedings{Bell2009,
  author    = {Bell, Nathan and Garland, Michael},
  title     = {Implementing Sparse Matrix-vector Multiplication on Throughput-oriented Processors},
  booktitle = {Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis},
  date      = {2009},
  series    = {SC '09},
  publisher = {ACM},
  location  = {Portland, Oregon},
  isbn      = {978-1-60558-744-8},
  pages     = {1--11},
  doi       = {10.1145/1654059.1654078},
 abstract = {Sparse matrix-vector multiplication (SpMV) is of singular importance in sparse linear algebra. In contrast to the uniform regularity of dense linear algebra, sparse operations encounter a broad spectrum of matrices ranging from the regular to the highly irregular. Harnessing the tremendous potential of throughput-oriented processors for sparse operations requires that we expose substantial fine-grained parallelism and impose sufficient regularity on execution paths and memory access patterns. We explore SpMV methods that are well-suited to throughput-oriented architectures like the GPU and which exploit several common sparsity classes. The techniques we propose are efficient, successfully utilizing large percentages of peak bandwidth. Furthermore, they deliver excellent total throughput, averaging 16 GFLOP/s and 10 GFLOP/s in double precision for structured grid and unstructured mesh matrices, respectively, on a GeForce GTX 285. This is roughly 2.8 times the throughput previously achieved on Cell BE and more than 10 times that of a quad-core Intel Clovertown system.},
  acmid     = {1654078},
  address   = {New York, NY, USA},
  articleno = {18},
  numpages  = {11},
}

@Article{Rafique2015,
  author       = {A. Rafique and G. A. Constantinides and N. Kapre},
  title        = {Communication Optimization of Iterative Sparse Matrix-Vector Multiply on {GPUs} and {FPGAs}},
  journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
  date         = {2015},
  volume       = {26},
  number       = {1},
  month        = jan,
  pages        = {24--34},
  issn         = {1045-9219},
  doi          = {10.1109/TPDS.2014.6},
 abstract = {Trading communication with redundant computation can increase the silicon efficiency of FPGAs and GPUs in accelerating communication-bound sparse iterative solvers. While k iterations of the iterative solver can be unrolled to provide O(k) reduction in communication cost, the extent of this unrolling depends on the underlying architecture, its memory model, and the growth in redundant computation. This paper presents a systematic procedure to select this algorithmic parameter k, which provides communication-computation tradeoff on hardware accelerators like FPGA and GPU. We provide predictive models to understand this tradeoff and show how careful selection of k can lead to performance improvement that otherwise demands significant increase in memory bandwidth. On an Nvidia C2050 GPU, we demonstrate a 1.9$\times$-42.6$\times$ speedup over standard iterative solvers for a range of benchmarks and that this speedup is limited by the growth in redundant computation. In contrast, for FPGAs, we present an architecture-aware algorithm that limits off-chip communication but allows communication between the processing cores. This reduces redundant computation and allows large k and hence higher speedups. Our approach for FPGA provides a 0.3$\times$-4.4$\times$ speedup over same-generation GPU devices where k is picked carefully for both architectures for a range of benchmark.},
  keywords     = {field programmable gate arrays;graphics processing units;iterative methods;mathematics computing;matrix multiplication;FPGA;Nvidia C2050 GPU;algorithmic parameter;architecture-aware algorithm;communication cost reduction;communication optimization;communication-bound sparse iterative solvers;communication-computation tradeoff;field programmable gate array;graphics processing unit;hardware accelerators;iterative sparse matrix-vector multiplication;off-chip communication;processing core communication;Field programmable gate arrays;Graphics processing units;Instruction sets;Kernel;Registers;Sparse matrices;Vectors;Iterative numerical methods;field programmable gate arrays (FPGAs);graphics processing units (GPUs);matrix powers kernel;spare matrix-vector multiply},
}

@Article{Li2013,
  author       = {Li, Ruipeng and Saad, Yousef},
  title        = {{GPU}-accelerated Preconditioned Iterative Linear Solvers},
  journaltitle = {Journal of Supercomputing},
  date         = {2013},
  volume       = {63},
  number       = {2},
  month        = feb,
  pages        = {443--466},
  issn         = {0920-8542},
  doi          = {10.1007/s11227-012-0825-3},
 abstract = {This work is an overview of our preliminary experience in developing a high-performance iterative linear solver accelerated by GPU coprocessors. Our goal is to illustrate the advantages and difficulties encountered when deploying GPU technology to perform sparse linear algebra computations. Techniques for speeding up sparse matrix-vector product (SpMV) kernels and finding suitable preconditioning methods are discussed. Our experiments with an NVIDIA TESLA M2070 show that for unstructured matrices SpMV kernels can be up to 8 times faster on the GPU than the Intel MKL on the host Intel Xeon X5675 Processor. Overall performance of the GPU-accelerated Incomplete Cholesky (IC) factorization preconditioned CG method can outperform its CPU counterpart by a smaller factor, up to 3, and GPU-accelerated The incomplete LU (ILU) factorization preconditioned GMRES method can achieve a speed-up nearing 4. However, with better suited preconditioning techniques for GPUs, this performance can be further improved.},
  acmid        = {2434703},
  issue_date   = {February 2013},
  keywords     = {GPU computing, Preconditioned iterative methods, Sparse matrix computations},
  location     = {Hingham, MA, USA},
  numpages     = {24},
  publisher    = {Kluwer Academic Publishers},
}

@InProceedings{Bolz2003,
  author    = {Bolz, Jeff and Farmer, Ian and Grinspun, Eitan and Schröder, Peter},
  title     = {Sparse Matrix Solvers on the {GPU}: Conjugate Gradients and Multigrid},
  booktitle = {ACM SIGGRAPH 2003 Papers},
  date      = {2003},
  series    = {SIGGRAPH '03},
  publisher = {ACM},
  location  = {San Diego, California},
  isbn      = {1-58113-709-5},
  pages     = {917--924},
  doi       = {10.1145/1201775.882364},
 abstract = {Many computer graphics applications require high-intensity numerical simulation. We show that such computations can be performed efficiently on the GPU, which we regard as a full function streaming processor with high floating-point performance. We implemented two basic, broadly useful, computational kernels: a sparse matrix conjugate gradient solver and a regular-grid multigrid solver. Real time applications ranging from mesh smoothing and parameterization to fluid solvers and solid mechanics can greatly benefit from these, evidence our example applications of geometric flow and fluid simulation running on NVIDIA's GeForce FX.},
  acmid     = {882364},
  address   = {New York, NY, USA},
  keywords  = {GPU computing, Navier-Stokes, conjugate gradient, fluid simulation, mesh smoothing, multigrid, numerical simulation},
  numpages  = {8},
}

@Article{Buatois2009,
  author       = {Luc Buatois and Guillaume Caumon and Bruno Lévy},
  title        = {Concurrent number cruncher: a {GPU} implementation of a general sparse linear solver},
  journaltitle = {International Journal of Parallel, Emergent and Distributed Systems},
  date         = {2009},
  volume       = {24},
  number       = {3},
  pages        = {205--223},
  doi          = {10.1080/17445760802337010},
 abstract = {A wide class of numerical methods needs to solve a linear system, where the matrix pattern of non-zero coefficients can be arbitrary. These problems can greatly benefit from highly multithreaded computational power and large memory bandwidth available on graphics processor units (GPUs), especially since dedicated general purpose APIs such as close-to-metal (CTM) (AMD–ATI) and compute unified device architecture (CUDA) (NVIDIA) have appeared. CUDA even provides a BLAS implementation, but only for dense matrices (CuBLAS). Other existing linear solvers for the GPU are also limited by their internal matrix representation. This paper describes how to combine recent GPU programming techniques and new GPU dedicated APIs with high performance computing strategies (namely block compressed row storage (BCRS), register blocking and vectorization), to implement a sparse general-purpose linear solver. Our implementation of the Jacobi-preconditioned conjugate gradient algorithm outperforms by up to a factor of 6.0$\times$ leading-edge CPU counterparts, making it attractive for applications which are content with single precision.},
}

@Manual{Gurobi2017,
  title        = {Gurobi Optimizer Reference Manual},
  date         = {2017},
  version      = {7.0},
  organization = {Gurobi Optimization},
  url          = {http://www.gurobi.com/documentation/7.0/refman.pdf},
  institution  = {Xilinx Inc.},
  month        = dec,
  owner        = {andrea},
  timestamp    = {2015.01.29},
}

@Article{Saad2010,
  author       = {Y. Saad and M. Yeung and J. Erhel and F. Guyomarc'h},
  title        = {A Deflated Version of the Conjugate Gradient Algorithm},
  journaltitle = {{SIAM} Journal on Scientific Computing},
  date         = {2000},
  volume       = {21},
  number       = {5},
  pages        = {1909--1926},
  doi          = {10.1137/S1064829598339761},
  url          = { 
        https://doi.org/10.1137/S1064829598339761
    
},
 abstract = {We present a deflated version of the conjugate gradient algorithm for solving linear systems. The new algorithm can be useful in cases when a small number of eigenvalues of the iteration matrix are very close to the origin. It can also be useful when solving linear systems with multiple right-hand sides, since the eigenvalue information gathered from solving one linear system can be recycled for solving the next systems and then updated.},
}

@InProceedings{Wong2010,
  author    = {H. Wong and M. M. Papadopoulou and M. Sadooghi-Alvandi and A. Moshovos},
  title     = {Demystifying {GPU} microarchitecture through microbenchmarking},
  booktitle = {Proceedings of the IEEE International Symposium on Performance Analysis of Systems Software},
  date      = {2010},
  series    = {ISPASS '10},
  month     = {3},
  pages     = {235--246},
  doi       = {10.1109/ISPASS.2010.5452013},
  abstract  = {Graphics processors (GPU) offer the promise of more than an order of magnitude speedup over conventional processors for certain non-graphics computations. Because the GPU is often presented as a C-like abstraction (e.g., Nvidia's CUDA), little is known about the characteristics of the GPU's architecture beyond what the manufacturer has documented. This work develops a microbechmark suite and measures the CUDA-visible architectural characteristics of the Nvidia GT200 (GTX280) GPU. Various undisclosed characteristics of the processing elements and the memory hierarchies are measured. This analysis exposes undocumented features that impact program performance and correctness. These measurements can be useful for improving performance optimization, analysis, and modeling on this architecture and offer additional insight on the decisions made in developing this GPU.},
  keywords  = {computer graphics;coprocessors;GPU microarchitecture;Nvidia GT200 GPU;graphics processors;microbenchmarking;Clocks;Computer architecture;Delay;Hardware;Kernel;Microarchitecture;Performance analysis;Registers;Samarium;Yarn},
}

@Manual{Nvprof2015,
  title        = {Profiler User's Guide},
  date         = {2015},
  edition      = {7.0},
  note         = {Accessed 12 July 2017.},
  organization = {NVIDIA corporation},
  url          = {http://docs.nvidia.com/cuda/profiler-users-guide/index.html#axzz4mitW5BwQ},
  month        = mar,
  owner        = {ap8213},
  timestamp    = {2015.09.28},
}

@Manual{CudaProgramming2015,
  title        = {{CUDA} {C} Programming Guide},
  date         = {2015},
  edition      = {7.5},
  organization = {NVIDIA},
  url          = {http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#axzz4mitW5BwQ},
  month        = oct,
  owner        = {andrea},
  timestamp    = {2016.11.07},
}

@Manual{OpenCl2010,
  editor       = {Aaftab Munshi},
  title        = {The {OpenCL} Specification},
  date         = {2010},
  version      = {1.1},
  organization = {Khronos {OpenCL} Working Group},
  url          = {https://www.khronos.org/registry/OpenCL/specs/opencl-1.1.pdf},
}

@Article{Byrd2000,
  author       = {Byrd, Richard H. and Gilbert, Jean Charles and Nocedal, Jorge},
  title        = {A trust region method based on interior point techniques for nonlinear programming},
  journaltitle = {Mathematical Programming},
  date         = {2000-11-01},
  volume       = {89},
  number       = {1},
  pages        = {149--185},
  issn         = {1436-4646},
  doi          = {10.1007/PL00011391},
 abstract = {An algorithm for minimizing a nonlinear function subject to nonlinear inequality constraints is described. It applies sequential quadratic programming techniques to a sequence of barrier problems, and uses trust regions to ensure the robustness of the iteration and to allow the direct use of second order derivatives. This framework permits primal and primal-dual steps, but the paper focuses on the primal version of the new algorithm. An analysis of the convergence properties of this method is presented.},
  day          = {01},
}

@Misc{IntelI7,
  title        = {Intel Core i7-3770 Processor},
  date         = {2012},
  howpublished = {Online},
  note         = {Accessed 13 October 2016},
  organization = {Intel Corporation},
  url          = {http://ark.intel.com/products/65719/Intel-Core-i7-3770-Processor-8M-Cache-up-to-3_90-GHz},
  owner        = {andrea},
  timestamp    = {2016.03.17},
}

@InProceedings{Picciau2016,
  author    = {A. Picciau and G. E. Inggs and J. Wickerson and E. C. Kerrigan and G. A. Constantinides},
  title     = {Balancing Locality and Concurrency: Solving Sparse Triangular Systems on {GPUs}},
  booktitle = {Proceedings of the 23rd {IEEE} International Conference on High Performance Computing},
  date      = {2016-12},
  series    = {HiPC '16},
  location  = {Hyderabad, IN},
  pages     = {183--192},
  doi       = {10.1109/HiPC.2016.030},
 abstract = {Many numerical optimisation problems rely on fast algorithms for solving sparse triangular systems of linear equations (STLs). To accelerate the solution of such equations, two types of approaches have been used: on GPUs, concurrency has been prioritised to the disadvantage of data locality, while on multi-core CPUs, data locality has been prioritised to the disadvantage of concurrency. In this paper, we discuss the interaction between data locality and concurrency in the solution of STLs on GPUs, and we present a new algorithm that balances both. We demonstrate empirically that, subject to there being enough concurrency available in the input matrix, our algorithm outperforms Nvidia's concurrency-prioritising CUSPARSE algorithm for GPUs. Experimental results show a maximum speedup of 5.8-fold. Our solution algorithm, which we have implemented in OpenCL, requires a pre-processing phase that partitions the graph associated with the input matrix into sub-graphs, whose data can be stored in low-latency local memories. This preliminary analysis phase is expensive, but because it depends only on the input matrix, its cost can be amortised when solving for many different right-hand sides.},
  keywords  = {concurrency control;data handling;graph theory;graphics processing units;matrix algebra;parallel algorithms;storage management;GPU;Nvidia concurrency-prioritising CUSPARSE algorithm;OpenCL;data locality;graph partitioning;input matrix;low-latency local memories;multicore CPU;numerical optimisation problem;sparse triangular system of linear equations;Algorithm design and analysis;Concurrent computing;Context;Data structures;Graphics processing units;Partitioning algorithms;Sparse matrices;CUSPARSE;GPU;OpenCL;concurrency;data locality;linear algebra;sparse;systems of equations},
}

@Article{Davis2018,
  author       = {Davis, Timothy A. and Hager, William W. and Kolodziej, Scott P. and Yearalan, S. Nuri},
  title        = {Algorithm {XXX}: {Mongoose}, A Graph Coarsening and Partitioning Library},
  journaltitle = {ACM Transactions on Mathematical Software},
  year         = {2018},
  date         = {2018-04},
  volume       = {0},
  number       = {0},
  abstract     = {Partitioning  graphs  is  a  common  and  useful  operation  in  many  areas,  from  parallel  computing  to  VLSI design to sparse matrix algorithms. In this paper, we introduce Mongoose, a multilevel hybrid graph partitioning algorithm and library. Building on previous work in multilevel partitioning frameworks and combinatoric approaches, we introduce novel stall-reducing and stall-free coarsening strategies, as well as an efficient hybrid algorithm leveraging 1) traditional combinatoric methods and 2) continuous quadratic programming  formulations. We  demonstrate how  this  new hybrid  algorithm outperforms  either strategy in isolation, and we also compare Mongoose to METIS and demonstrate its effectiveness on large and social networking (power law) graphs.},
}

@InProceedings{Hong2018,
  author    = {Hong, Changwan and Sukumaran-Rajam, Aravind and Bandyopadhyay, Bortik and Kim, Jinsung and Kurt, S\"{u}reyya Emre and Nisa, Israt and Sabhlok, Shivani and \c{C}ataly\"{u}rek, \"{U}mit V. and Parthasarathy, Srinivasan and Sadayappan, P.},
  title     = {Efficient Sparse-matrix Multi-vector Product on {GPU}s},
  booktitle = {Proceedings of the 27th International Symposium on High-Performance Parallel and Distributed Computing},
  date      = {2018},
  series    = {HPDC '18},
  publisher = {ACM},
  location  = {Tempe, Arizona},
  isbn      = {978-1-4503-5785-2},
  pages     = {66--79},
  doi       = {10.1145/3208040.3208062},
  url       = {http://doi.acm.org/10.1145/3208040.3208062},
  abstract  = {Sparse Matrix-Vector (SpMV) and Sparse Matrix-Multivector (SpMM) products are key kernels for computational science and data science. While GPUs offer significantly higher peak performance and memory bandwidth than multicore CPUs, achieving high performance on sparse computations on GPUs is very challenging. A tremendous amount of recent research has focused on various GPU implementations of the SpMV kernel. But the multi-vector SpMM kernel has received much less attention. In this paper, we present an in-depth analysis to contrast SpMV and SpMM, and develop a new sparse-matrix representation and computation approach suited to achieving high data-movement efficiency and effective GPU parallelization of SpMM. Experimental evaluation using the entire SuiteSparse matrix suite demonstrates significant performance improvement over existing SpMM implementations from vendor libraries.},
  keywords  = {GPU, sparse matrix multi-vector multiplication, sparse matrix-matrix multiplication, sparse matrix-vector multiplication},
  numpages  = {14},
}

@Article{Saad1993,
  author   = {Saad, Youcef},
  title    = {A Flexible Inner-Outer Preconditioned GMRES Algorithm},
  journal  = {SIAM Journal on Scientific Computing},
  year     = {1993},
  volume   = {14},
  number   = {2},
  pages    = {461-469},
  doi      = {10.1137/0914028},
  abstract = {A variant of the GMRES algorithm is presented that allows changes in the preconditioning at every step. There are many possible applications of the new algorithm, some of which are briefly discussed. In particular, a result of the flexibility of the new variant is that any iterative method can be used as a preconditioner. For example, the standard GMRES algorithm itself can be used as a preconditioner, as can CGNR (or CGNE), the conjugate gradient method applied to the normal equations. However, the more appealing utilization of the method is in conjunction with relaxation techniques, possibly multilevel techniques. The possibility of changing preconditioners may be exploited to develop efficient iterative methods and to enhance robustness. A few numerical experiments are reported to illustrate this fact.},
}

@Article{Ekstrom2018,
  author      = {Ekstr{\"o}m, Sven-Erik and Garoni, Carlo},
  title       = {A matrix-less and parallel interpolation–extrapolation algorithm for computing the eigenvalues of preconditioned banded symmetric Toeplitz matrices},
  journal     = {Numerical Algorithms},
  year        = {2018},
  doi         = {10.1007/s11075-018-0508-0},
  abstract    = {In  the  past  few  years,  Bogoya,  Bottcher,  Grudsky,  and  Maximenko obtained the precise asymptotic expansion for the eigenvalues of a Toeplitz matrix $T_n(f)$, under suitable assumptions on the generating function $f$, as the matrix size $n$ goes to infinity. On the basis of  several numerical experiments, it was conjectured by Serra-Capizzano that a completely analogous expansion also holds for the eigenvalues of the preconditioned Toeplitz matrix $T_n(u)^{-1}T_n(v)$, provided $f = v/u$ is monotone and further conditions on $u$ and $v$ are satisfied. Based on this expansion, we here propose and analyze an interpolation–extrapolation algorithm for computing the eigenvalues of $T_n(u)^{-1}T_n(v)$. The algorithm is suited for parallel implementation and it may be called “matrix-less” as it does not need to store the entries of the matrix. We illustrate the performance of the algorithm through numerical experiments and we also present its generalization to the case where $f = v/u$ is non-monotone.},
  institution = {Uppsala University, Division of Scientific Computing},
}

@InProceedings{Zhong2017,
  author    = {Zhong, Wenyong and Cao, Yanxin and Li, Jiawen and Sun, Jianhua and Chen, Hao},
  title     = {Specialization or generalization: A study on breadth-first graph traversal on {GPUs}},
  booktitle = {Proceedings of the International Conference on Progress in Informatics and Computing},
  year      = {2017},
  series    = {{PIC}},
  month     = {12},
  pages     = {294-301},
}

@Book{Diestel2005,
  author       = {Diestel, Reinhard},
  title        = {Graph Theory},
  date         = {2005},
  volume       = {173},
  edition      = {3},
  series       = {Graduate Texts in Mathematics},
  publisher    = {Springer--Verlag Heidelberg},
  isbn         = {3540261826},
  howpublished = {Hardcover},
  month        = aug,
  owner        = {andrea},
  timestamp    = {2016.07.23},
}

@Article{Frick2015,
  author       = {Damian Frick and Alexander Domahidi and Manfred Morari},
  title        = {Embedded optimization for mixed logical dynamical systems},
  journaltitle = {Computers and Chemical Engineering},
  date         = {2015},
  volume       = {72},
  number       = {0},
  month        = jan,
  pages        = {21--33},
  note         = {A Tribute to Ignacio E. Grossmann},
  issn         = {0098-1354},
  doi          = {http://dx.doi.org/10.1016/j.compchemeng.2014.06.005},
  abstract     = {Predictive control of hybrid systems is currently considered prohibitive using embedded computing platforms. To overcome this limitation for mixed logical dynamical systems of small to medium size, we propose to use (1) a standard branch-and-bound approach combined with a fast embedded interior point solver, (2) pre-processing heuristics, run once and offline, to significantly reduce the number of subproblems to be solved, and (3) relaxations of the original MPC problem that allow a trade off between computation time and closed-loop performance. A problem-specific ANSI C implementation of the proposed method can be automatically generated, and has a fixed memory footprint and a code size that is insignificantly larger than that of the subproblem solver. Two extensive numerical studies are presented, where problems with up to 60 binary variables are solved in less than 0.2 s with a performance deterioration of below 2\% when compared to an optimal MPC scheme.},
  keywords     = {Mixed logical dynamical systems},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@Article{Peyton1993,
  author       = {Barry W Peyton and Alex Pothen and Xiaoqing Yuan},
  title        = {Partitioning a chordal graph into transitive subgraphs for parallel sparse triangular solution },
  journaltitle = {Linear Algebra and its Applications},
  date         = {1993},
  volume       = {192},
  number       = {0},
  pages        = {329--353},
  issn         = {0024-3795},
  doi          = {10.1016/0024-3795(93)90248-M},
  url          = {http://www.sciencedirect.com/science/article/pii/002437959390248M},
  abstract     = {A recent approach for solving sparse triangular systems of equations on massively parallel computers employs a factorization of the triangular coefficient matrix to obtain a representation of its inverse in product form. The number of general communication steps required by this approach is proportional to the number of factors in the factorization. The triangular matrix can be symmetrically permuted to minimize the number of factors over suitable classes of permutations, and thereby the complexity of the parallel algorithm can be minimized. Algorithms for minimizing the number of factors over several classes of permutations have been considered in earlier work. Let $F = L + L^T$ denote the symmetric filled matrix corresponding to a Cholesky factor L, and let $G_F$ denote the adjacency graph of F. We consider the problem of minimizing the number of factors over all permutations which preserve the structure of $G_F$. The graph model of this problem is to partition the vertices $G_F$ into the fewest transitively closed subgraphs over all perfect elimination orderings while satisfying a certain precedence relationship. The solution to this chordal-graph partitioning problem can be described by a greedy scheme which eliminates a largest permissible subgraph at each step. Further, the subgraph eliminated at each step can be characterized in terms of lengths of chordless paths in the current elimination graph. This solution relies on several results concerning transitive perfect elimination orderings introduced in this paper. We describe a partitioning algorithm with $O(|V| + |E|)$ time and space complexity.},
}

@Article{Ploskas2014,
  author       = {Nikolaos Ploskas and Nikolaos Samaras},
  title        = {{GPU} accelerated pivoting rules for the simplex algorithm},
  journaltitle = {Journal of Systems and Software},
  date         = {2014},
  volume       = {96},
  pages        = {1--9},
  issn         = {0164-1212},
  doi          = {10.1016/j.jss.2014.04.047},
  url          = {http://www.sciencedirect.com/science/article/pii/S0164121214001174},
  abstract     = {Simplex type algorithms perform successive pivoting operations (or iterations) in order to reach the optimal solution. The choice of the pivot element at each iteration is one of the most critical step in simplex type algorithms. The flexibility of the entering and leaving variable selection allows to develop various pivoting rules. In this paper, we have proposed some of the most well-known pivoting rules for the revised simplex algorithm on a CPU-GPU computing environment. All pivoting rules have been implemented in MATLAB and CUDA. Computational results on randomly generated optimal dense linear programs and on a set of benchmark problems (Netlib-optimal, Kennington, Netlib-infeasible, Maros) are also presented. These results showed that the proposed GPU implementations of the pivoting rules outperform the corresponding CPU implementations.},
  keywords     = {Linear programming},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@Article{Ploskas2015,
  author       = {Nikolaos Ploskas and Nikolaos Samaras},
  title        = {Efficient {GPU}-based implementations of simplex type algorithms},
  journaltitle = {Applied Mathematics and Computation},
  date         = {2015},
  volume       = {250},
  pages        = {552--570},
  issn         = {0096-3003},
  doi          = {10.1016/j.amc.2014.10.096},
  abstract     = {Recent hardware advances have made it possible to solve large scale Linear Programming problems in a short amount of time. Graphical Processing Units (GPUs) have gained a lot of popularity and have been applied to linear programming algorithms. In this paper, we propose two efficient GPU-based implementations of the Revised Simplex Algorithm and a Primal-Dual Exterior Point Simplex Algorithm. Both parallel algorithms have been implemented in MATLAB using MATLAB's Parallel Computing Toolbox. Computational results on randomly generated optimal sparse and dense linear programming problems and on a set of benchmark problems (netlib, kennington, Maros) are also presented. The results show that the proposed GPU implementations outperform MATLAB's interior point method.},
  keywords     = {Linear Programming},
  owner        = {andrea},
  timestamp    = {2017.05.08},
}

@Article{Tomov2010,
  author       = {Stanimire Tomov and Jack Dongarra and Marc Baboulin},
  title        = {Towards dense linear algebra for hybrid {GPU} accelerated manycore systems},
  journaltitle = {Parallel Computing},
  date         = {2010},
  volume       = {36},
  number       = {5--6},
  month        = jun,
  pages        = {232--240},
  issn         = {0167-8191},
  doi          = {10.1016/j.parco.2009.12.005},
  abstract     = {We highlight the trends leading to the increased appeal of using hybrid multicore + GPU systems for high performance computing. We present a set of techniques that can be used to develop efficient dense linear algebra algorithms for these systems. We illustrate the main ideas with the development of a hybrid LU factorization algorithm where we split the computation over a multicore and a graphics processor, and use particular techniques to reduce the amount of pivoting and communication between the hybrid components. This results in an efficient algorithm with balanced use of a multicore processor and a graphics processor.},
  owner        = {andrea},
  posted-at    = {2010-12-17 09:48:58},
  timestamp    = {2016.11.07},
}

@Article{Abdelfattah2018,
  author   = {A. Abdelfattah and A. Haidar and S. Tomov and J. Dongarra},
  title    = {Analysis and Design Techniques towards High-Performance and Energy-Efficient Dense Linear Solvers on {GPU}s},
  journal  = {{IEEE} Transactions on Parallel and Distributed Systems},
  year     = {2018},
  pages    = {1--14},
  issn     = {1045--9219},
  doi      = {10.1109/TPDS.2018.2842785},
  abstract = {Graphics Processing Units (GPUs) are widely used in accelerating dense linear solvers. The matrix factorizations, which dominate the runtime for these solvers, are often designed using a hybrid scheme, where GPUs perform trailing matrix updates, while the CPUs perform the panel factorizations. Consequently, hybrid solutions require high-end CPUs and optimized CPU software in order to deliver high performance. Furthermore, they lack the energy efficiency inherent for GPUs due to the use of less energy-efficient CPUs, as well as CPU-GPU communications.},
  keywords = {Graphics processing units;Libraries;Task analysis;Layout;Kernel;Multicore processing;Dense Linear Solvers;GPU Computing;Energy Efficiency},
}

@InProceedings{Jaiganesh2018,
  author    = {Jaiganesh, Jayadharini and Burtscher, Martin},
  title     = {A High-performance Connected Components Implementation for GPUs},
  booktitle = {Proceedings of the 27th International Symposium on High-Performance Parallel and Distributed Computing},
  year      = {2018},
  series    = {HPDC '18},
  publisher = {ACM},
  location  = {Tempe, Arizona},
  isbn      = {978-1-4503-5785-2},
  pages     = {92--104},
  doi       = {10.1145/3208040.3208041},
  abstract  = {Computing connected components is an important graph algorithm that is used, for example, in medicine, image processing, and biochemistry. This paper presents a fast connected-components implementation for GPUs called ECL-CC. It builds upon the best features of prior algorithms and augments them with GPU-specific optimizations. For example, it incorporates a parallelism-friendly version of pointer jumping to speed up union-find operations and uses several compute kernels to exploit the multiple levels of hardware parallelism. The resulting CUDA code is asynchronous and lock free, employs load balancing, visits each edge exactly once, and only processes edges in one direction. It is 1.8 times faster on average than the fastest prior GPU implementation running on a Titan X and faster on most of the eighteen real-world and synthetic graphs we tested.},
  acmid     = {3208041},
  address   = {New York, NY, USA},
  keywords  = {GPU implementation, connected components, graph algorithm, parallelism, union-find},
  numpages  = {13},
}

@Online{Li2018,
  author     = {Li, Ruipeng and Xi, Yuanzhe and Erlandson, Lucas and Saad, Yousef},
  title      = {The Eigenvalues Slicing Library (EVSL): Algorithms, Implementation, and Software},
  year       = {2018},
  abstract   = {This paper describes a software package called EVSL (for EigenValues Slicing Library) for solving large sparse real symmetric standard and generalized eigenvalue problems. As its name indicates, the package exploits spectrum slicing, a strategy that consists of dividing the spectrum into a number of subintervals and extracting eigenpairs from each subinterval independently. In order to enable such a strategy, the methods implemented in EVSL rely on a quick calculation of the spectral density of a given matrix, or a matrix pair. What distinguishes EVSL from other currently available packages is that EVSL relies entirely on filtering techniques. Polynomial and rational filtering are both implemented and are coupled with Krylov subspace methods and the subspace iteration algorithm. On the implementation side, the package offers interfaces for various scenarios including matrix-free modes, whereby the user can supply his/her own functions to perform matrix-vector operations or to solve sparse linear systems. The paper describes the algorithms in EVSL, provides details on their implementations, and discusses performance issues for the various methods.},
  eprint     = {arXiv:1802.05215},
  eprinttype = {arXiv},
}

@Online{Coutinho2018,
  author     = {Coutinho, Demetrios and Xavier-de-Souza, Samuel and Aloise, Daniel},
  title      = {A Scalable Shared-Memory Parallel Simplex for Large-Scale Linear Programming},
  year       = {2018},
  abstract   = {We present a shared-memory parallel implementation of the Simplex tableau algorithm for dense large-scale Linear Programming (LP) problems. We present the general scheme and explain each parallelization step of the standard simplex algorithm, emphasizing important solutions for solving performance bottlenecks. We analyzed the speedup and the parallel efficiency for the proposed implementation relative to the standard Simplex algorithm using a shared-memory system with 64 processing cores. The experiments were performed for several different problems, with up to 8192 variables and constraints, in their primal and dual formulations. The results show that the performance is mostly much better when we use the formulation with more variables than inequality constraints. Also, they show that the parallelization strategies applied to avoid bottlenecks caused the implementation to scale well with the problem size and the core count up to a certain limit of problem size. Further analysis showed that this was an effect of resource limitation. Even though, our implementation was able to reach speedups in the order of 19$\times$.},
  eprint     = {arXiv:1804.04737},
  eprinttype = {arXiv},
}

@InProceedings{Simpson2018,
  author    = {Simpson, Toby and Dimosthenis, Pasadakis ad Kourounis, Drosos and Fujita, Kohei and Yamaguchi, Takuma and Tsuyoshi, Ichimura and Schenk, Olaf},
  title     = {Balanced Graph Partition Refinement using the Graph p-Laplacian},
  booktitle = {Proceedings of the {ACM} Platform for Advanced Scientific Computing Conference},
  year      = {2018},
  series    = {PASC '18},
  month     = jun,
  doi       = {10.1145/3218176.3218232},
  abstract  = {A continuous formulation of the optimal 2-way graph partitioning based on the p-norm minimization of the graph Laplacian Rayleigh quotient is presented, which provides a sharp approximation to the balanced graph partitioning problem, the optimality of which is known to be NP-hard. The minimization is initialized from a cut provided by a state-of-the-art multilevel recursive bisection algorithm, and then a continuation approach reduces the p-norm from a 2-norm towards a 1-norm, employing for each value of p a feasibility-preserving steepest-descent method that converges on the p-Laplacian eigenvector. A filter favors iterates advancing towards minimum edgecut and partition load imbalance. The complexity of the suggested approach is linear in graph edges. The simplicity of the steepest-descent algorithm renders the overall approach highly scalable and efficient in parallel distributed architectures. Parallel implementation of recursive bisection on multi-core CPUs and GPUs are presented for large-scale graphs with up to 1.9 billion tetrahedra. The suggested approach exhibits improvements of up to 52.8\% over METIS for graphs originating from triangular Delaunay meshes, 34.7\% over METIS and 21.9\% over KaHIP for power network graphs, 40.8\% over METIS and 20.6\% over KaHIP for sparse matrix graphs, and finally 93.2\% over METIS for graphs emerging from social networks.},
  timestamp = {2018.08.26},
}

@InProceedings{Dahiya2018,
  author    = {Dahiya, Yogesh and Konomis, Dimitris and Woodruff, David P.},
  title     = {An Empirical Evaluation of Sketching for Numerical Linear Algebra},
  booktitle = {Proceedings of the 24th {ACM} {SIGKDD} International Conference on Knowledge Discovery \&\#38; Data Mining},
  year      = {2018},
  series    = {KDD '18},
  publisher = {ACM},
  location  = {London, United Kingdom},
  isbn      = {978-1-4503-5552-0},
  pages     = {1292--1300},
  doi       = {10.1145/3219819.3220098},
  url       = {http://doi.acm.org/10.1145/3219819.3220098},
  abstract  = {Over the last ten years, tremendous speedups for problems in randomized numerical linear algebra such as low rank approximation and regression have been made possible via the technique of randomized data dimensionality reduction, also known as sketching. In theory, such algorithms have led to optimal input sparsity time algorithms for a wide array of problems. While several scattered implementations of such methods exist, the goal of this work is to provide a comprehensive comparison of such methods to alternative approaches. We investigate least squares regression, iteratively reweighted least squares, logistic regression, robust regression with Huber and Bisquare loss functions, leverage score computation, Frobenius norm low rank approximation, and entrywise $\ell_1$-low rank approximation. We give various implementation techniques to speed up several of these algorithms, and the resulting implementations demonstrate the tradeoffs of such techniques in practice.},
  acmid     = {3220098},
  address   = {New York, NY, USA},
  keywords  = {logistic regression, low rank approximation, regression, robust methods, sketching},
  numpages  = {9},
}

@Article{Anzt2018a,
  author    = {Hartwig Anzt and Thomas K. Huckle and Jürgen Bräckle and Jack Dongarra},
  title     = {Incomplete Sparse Approximate Inverses for Parallel Preconditioning},
  journal   = {Parallel Computing},
  year      = {2018},
  volume    = {71},
  pages     = {1--22},
  issn      = {0167-8191},
  doi       = {https://doi.org/10.1016/j.parco.2017.10.003},
  url       = {http://www.sciencedirect.com/science/article/pii/S016781911730176X},
  abstract  = {In this paper, we propose a new preconditioning method that can be seen as a generalization of block-Jacobi methods, or as a simplification of the sparse approximate inverse (SAI) preconditioners. The Incomplete Sparse Approximate Inverses (ISAI) is in particular efficient in the solution of sparse triangular linear systems of equations. Those arise, for example, in the context of incomplete factorization preconditioning. ISAI preconditioners can be generated via an algorithm providing fine-grained parallelism, which makes them attractive for hardware with a high concurrency level. In a study covering a large number of matrices, we identify the ISAI preconditioner as an attractive alternative to exact triangular solves in the context of incomplete factorization preconditioning.},
  keywords  = {Preconditioning, Incomplete Sparse Approximate Inverse, Incomplete LU factorization, Approximate sparse triangular solves, Parallel computing},
  timestamp = {2018.08.26},
}

@Online{Tavernier2018,
  author     = {Joris Tavernier and Jaak Simm and Karl Meerbergen and Yves Moreau},
  title      = {Multilevel preconditioning for Ridge Regression},
  year       = {2018},
  abstract   = {Solving linear systems is often the computational bottleneck in real-life problems. Iterative solvers are the only option due to the complexity of direct algorithms or because the system matrix is not explicitly known. Here, we develop a multilevel preconditioner for regularized least squares linear systems involving a feature or data matrix. Variants of this linear system may appear in machine learning applications, such as ridge regression, logistic regression, support vector machines and matrix factorization with side information. We use clustering algorithms to create coarser levels that preserve the principal components of the covariance or Gram matrix. These coarser levels approximate the dominant eigenvectors and are used to build a multilevel preconditioner accelerating the Conjugate Gradient method. We observed speed-ups for artificial and real-life data. For a specific data set, we achieved speed-up up to a factor 100.},
  eprint     = {arXiv:1806.05826},
  eprinttype = {arXiv},
}

@InProceedings{Wang2018,
  author    = {Wang, Xinliang and Liu, Weifeng and Xue, Wei and Wu, Li},
  title     = {swSpTRSV: A Fast Sparse Triangular Solve with Sparse Level Tile Layout on Sunway Architectures},
  booktitle = {Proceedings of the 23rd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
  year      = {2018},
  series    = {PPoPP '18},
  publisher = {ACM},
  location  = {Vienna, Austria},
  isbn      = {978-1-4503-4982-6},
  pages     = {338--353},
  doi       = {10.1145/3178487.3178513},
  url       = {http://doi.acm.org/10.1145/3178487.3178513},
  abstract  = {Sparse triangular solve (SpTRSV) is one of the most important kernels in many real-world applications. Currently, much research on parallel SpTRSV focuses on level-set construction for reducing the number of inter-level synchronizations. However, the out-of-control data reuse and high cost for global memory or shared cache access in inter-level synchronization have been largely neglected in existing work.\\In this paper, we propose a novel data layout called Sparse Level Tile to make all data reuse under control, and design a Producer-Consumer pairing method to make any inter-level synchronization only happen in very fast register communication. We implement our data layout and algorithms on an SW26010 many-core processor, which is the main building-block of the current world fastest supercomputer Sunway Taihulight. The experimental results of testing all 2057 square matrices from the Florida Matrix Collection show that our method achieves an average speedup of 6.9 and the best speedup of 38.5 over parallel level-set method. Our method also outperforms the latest methods on a KNC many-core processor in 1856 matrices and the latest methods on a K80 GPU in 1672 matrices, respectively.},
  acmid     = {3178513},
  address   = {New York, NY, USA},
  keywords  = {sparse level tile, sparse matrix, sparse triangular solve, sunway architecture},
  numpages  = {16},
}

@TechReport{Biswas2003,
  author      = {Biswas, Rupak and Oliker, Leonid and Shan, Hongzhang},
  title       = {Parallel computing strategies for irregular algorithms},
  institution = {LBNL},
  year        = {2003},
  number      = {53115},
  abstract    = {Parallel computing promises several orders of magnitude increase in our ability to solve realistic computationally intensive problems, but relies on their efficient mapping and execution on large-scale multiprocessor architectures. Unfortunately, many important applications are irregular and dynamic in nature, making their effective parallel implementation a daunting task. Moreover, with the proliferation of parallel architectures and programming paradigms, the typical scientist is faced with a plethora of questions that must be answered in order to obtain an acceptable parallel implementation of the solution algorithm. In this paper, we consider three representative irregular applications: unstructured remeshing, sparse matrix computations, and N-body problems, and parallelize them using various popular programming paradigms on a wide spectrum of computing platforms ranging from state-of-the-art supercomputers to PC clusters. We present the underlying problems, the solution algorithms, and the parallel implementation strategies. Smart load-balancing, partitioning, and ordering techniques are used to enhance parallel performance. Overall results demonstrate the complexity of efficiently parallelizing irregular algorithms.},
  timestamp   = {2018.08.26},
}

@Article{Liu2017,
  author   = {Liu, Weifeng and Li, Ang and Hogg, Jonathan D. and Duff, Iain S. and Vinter, Brian},
  title    = {Fast synchronization-free algorithms for parallel sparse triangular solves with multiple right-hand sides},
  journal  = {Concurrency and Computation: Practice and Experience},
  year     = {2017},
  volume   = {29},
  number   = {21},
  pages    = {e4244},
  note     = {e4244 cpe.4244},
  doi      = {10.1002/cpe.4244},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.4244},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4244},
  abstract = {Summary The sparse triangular solve kernels, SpTRSV and SpTRSM, are important building blocks for a number of numerical linear algebra routines. Parallelizing SpTRSV and SpTRSM on today's manycore platforms, such as GPUs, is not an easy task since computing a component of the solution may depend on previously computed components, enforcing a degree of sequential processing. As a consequence, most existing work introduces a preprocessing stage to partition the components into a group of level-sets or colour-sets so that components within a set are independent and can be processed simultaneously during the subsequent solution stage. However, this class of methods requires a long preprocessing time as well as significant runtime synchronization overheads between the sets. To address this, we propose in this paper novel approaches for SpTRSV and SpTRSM in which the ordering between components is naturally enforced within the solution stage. In this way, the cost for preprocessing can be greatly reduced, and the synchronizations between sets are completely eliminated. To further exploit the data-parallelism, we also develop an adaptive scheme for efficiently processing multiple right-hand sides in SpTRSM. A comparison with a state-of-the-art library supplied by the GPU vendor, using 20 sparse matrices on the latest GPU device, shows that the proposed approach obtains an average speedup of over two for SpTRSV and up to an order of magnitude speedup for SpTRSM. In addition, our method is up to two orders of magnitude faster for the preprocessing stage than existing SpTRSV and SpTRSM methods.},
  keywords = {GPU, manycore processor, sparse triangular solve, synchronization-free algorithm},
}

@Article{Chow2018,
  author   = {Chow, Edmond and Anzt, Hartwig and Scott, Jennifer and Dongarra, Jack},
  title    = {Using Jacobi iterations and blocking for solving sparse triangular systems in incomplete factorization preconditioning},
  journal  = {Journal of Parallel and Distributed Computing},
  year     = {2018},
  volume   = {119},
  pages    = {219 - 230},
  issn     = {0743-7315},
  doi      = {https://doi.org/10.1016/j.jpdc.2018.04.017},
  url      = {http://www.sciencedirect.com/science/article/pii/S0743731518303034},
  abstract = {When using incomplete factorization preconditioners with an iterative method to solve large sparse linear systems, each application of the preconditioner involves solving two sparse triangular systems. These triangular systems are challenging to solve efficiently on computers with high levels of concurrency. On such computers, it has recently been proposed to use Jacobi iterations, which are highly parallel, to approximately solve the triangular systems from incomplete factorizations. The effectiveness of this approach, however, is problem-dependent: the Jacobi iterations may not always converge quickly enough for all problems. Thus, as a necessary and important step to evaluate this approach, we experimentally test the approach on a large number of realistic symmetric positive definite problems. We also show that by using block Jacobi iterations, we can extend the range of problems for which such an approach can be effective. For block Jacobi iterations, it is essential for the blocking to be cognizant of the matrix structure.},
  keywords = {Sparse linear systems, Triangular solves, Iterative solvers, Preconditioning},
}

@InProceedings{Nagasaka2018,
  author     = {Yusuke Nagasaka and Satoshi Matsuoka and Ariful Azad and Aydın Buluç},
  title      = {High-performance sparse matrix-matrix products on Intel KNL and multicore architectures},
  booktitle  = {Proceedings of the 47th International Conference on Parallel Processing (Workshops)},
  year       = {2018},
  series     = {ICPPW '18},
  eprint     = {arXiv:1804.01698},
  eprinttype = {arXiv},
  abstract   = {Sparse matrix-matrix multiplication (SpGEMM) is a computational primitive that is widely used in areas ranging from traditional numerical applications to recent big data analysis and machine learning. Although many SpGEMM algorithms have been proposed, hardware specific optimizations for multi- and many-core processors are lacking and a detailed analysis of their performance under various use cases and matrices is not available. We firstly identify and mitigate multiple bottlenecks with memory management and thread scheduling on Intel Xeon Phi (Knights Landing or KNL). Specifically targeting multi- and many-core processors, we develop a hash-table-based algorithm and optimize a heap-based shared-memory SpGEMM algorithm. We examine their performance together with other publicly available codes. Different from the literature, our evaluation also includes use cases that are representative of real graph algorithms, such as multi-source breadth-first search or triangle counting. Our hash-table and heap-based algorithms are showing significant speedups from libraries in the majority of the cases while different algorithms dominate the other scenarios with different matrix size, sparsity, compression factor and operation type. We wrap up in-depth evaluation results and make a recipe to give the best SpGEMM algorithm for target scenario. A critical finding is that hash-table-based SpGEMM gets a significant performance boost if the nonzeros are not required to be sorted within each row of the output matrix.},
}

@InProceedings{Bromberger2018,
  author    = {Bromberger, Michael and Hoffmann, Markus and Rehrmann, Robin},
  title     = {Do Iterative Solvers Benefit from Approximate Computing? An Evaluation Study Considering Orthogonal Approximation Methods},
  booktitle = {Architecture of Computing Systems},
  year      = {2018},
  editor    = {Berekovic, Mladen and Buchty, Rainer and Hamann, Heiko and Koch, Dirk and Pionteck, Thilo},
  series    = {ARCS 2018},
  publisher = {Springer International Publishing},
  isbn      = {978-3-319-77610-1},
  pages     = {297--310},
  abstract  = {Employing algorithms of scientific computing often comes in hand with finding a trade-off between accuracy and performance. Novel parallel hardware and algorithms only slightly improve these issues due to the increasing size of the problems. While high accuracy is inevitable for most problems, there are parts in scientific computing that allow us to introduce approximation. Therefore, in this paper we give answers to the following questions: (1) Can we exploit different approximate computing strategies in scientific computing? (2) Is there a strategy to combine approaches? To answer these questions, we apply different approximation strategies to a widely used iterative solver for linear systems of equations. We show the advantages and the limits of each strategy and a way to configure a combination of strategies according to a given relative error. Combining orthogonal strategies as an overall concept gives us significant opportunities to increase the performance.},
  address   = {Cham},
}

@Online{Yang2018b,
  author     = {Yang, Carl and Buluç, Aydin and Owens, John D.},
  title      = {Design Principles for Sparse Matrix Multiplication on the GPU},
  year       = {2018},
  abstract   = {We implement two novel algorithms for sparse-matrix dense-matrix multiplication (SpMM) on the GPU. Our algorithms expect the sparse input in the popular compressed-sparse-row (CSR) format and thus do not require expensive format conversion. While previous SpMM work concentrates on thread-level parallelism, we additionally focus on latency hiding with instruction-level parallelism and load-balancing. We show, both theoretically and experimentally, that the proposed SpMM is a better fit for the GPU than previous approaches. We identify a key memory access pattern that allows efficient access into both input and output matrices that is crucial to getting excellent performance on SpMM. By combining these two ingredients – (i) merge-based load-balancing and (ii) row-major coalesced memory access – we demonstrate a 3.6x peak speedup and a 23.5\% geomean speedup over state-of-the-art SpMM implementations on real-world datasets.},
  eprint     = {arXiv:1803.08601},
  eprinttype = {arXiv},
}

@InBook{Jacquelin2018,
  author    = {Mathias Jacquelin and Esmond G. Ng and Barry W. Peyton},
  title     = {Fast and effective reordering of columns within supernodes using partition refinement},
  booktitle = {Proceedings of the Seventh SIAM Workshop on Combinatorial Scientific Computing},
  year      = {2018},
  pages     = {76--86},
  doi       = {10.1137/1.9781611975215.8},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611975215.8},
  abstract  = {In this paper, we consider the problem of computing a triangular factorization of a sparse symmetric matrix using Gaussian elimination. We assume that the sparse matrix has been permuted using a fill-reducing ordering algorithm. When the matrix is symmetric positive definite, the sparsity structure of the triangular factor can be determined once the fill-reducing ordering has been computed. Thus, an efficient numerical factorization scheme can be designed so that only the nonzero entries are stored and operated on. On modern architectures, the positions of the nonzero entries in the triangular factor play a big role in determining the efficiency. It is desirable to have dense blocks in the factor so that the computation can be cast in terms of level-3 BLAS as much as possible. On architectures with GPUs, for example, it is also desirable for these dense blocks to be as large as possible in order to reduce the times to transfer data between the main CPU and the GPUs. We address the problem of locally refining the ordering so that the number of dense blocks is reduced and the sizes of these dense blocks are increased in the triangular factor.},
}

@Online{Mohammadi2018,
  author        = {Mahdi Soltan Mohammadi and Kazem Cheshmi and Ganesh Gopalakrishnan and Mary W. Hall and Maryam Mehri Dehnavi and Anand Venkat and Tomofumi Yuki and Michelle Mills Strout},
  title         = {Sparse Matrix Code Dependence Analysis Simplification at Compile Time},
  year          = {2018},
  abstract      = {Analyzing array-based computations to determine data dependences is useful for many applications including automatic parallelization, race detection, computation and communication overlap, verification, and shape analysis. For sparse matrix codes, array data dependence analysis is made more difficult by the use of index arrays that make it possible to store only the nonzero entries of the matrix (e.g., in A[B[i]], B is an index array). Here, dependence analysis is often stymied by such indirect array accesses due to the values of the index array not being available at compile time. Consequently, many dependences cannot be proven unsatisfiable or determined until runtime. Nonetheless, index arrays in sparse matrix codes often have properties such as monotonicity of index array elements that can be exploited to reduce the amount of runtime analysis needed. In this paper, we contribute a formulation of array data dependence analysis that includes encoding index array properties as universally quantified constraints. This makes it possible to leverage existing SMT solvers to determine whether such dependences are unsatisfiable and significantly reduces the number of dependences that require runtime analysis in a set of eight sparse matrix kernels. Another contribution is an algorithm for simplifying the remaining satisfiable data dependences by discovering equalities and/or subset relationships. These simplifications are essential to make a runtime-inspection-based approach feasible.},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/abs-1807-10852},
  eprint        = {arXiv:1807.10852},
  eprinttype    = {arXiv:},
  timestamp     = {Mon, 13 Aug 2018 16:46:36 +0200},
}

@InProceedings{Dufrechou2018a,
  author    = {E. Dufrechou and P. Ezzatti},
  title     = {A New GPU Algorithm to Compute a Level Set-Based Analysis for the Parallel Solution of Sparse Triangular Systems},
  booktitle = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium},
  year      = {2018},
  series    = {IPDPS '18},
  month     = {5},
  pages     = {920--929},
  doi       = {10.1109/IPDPS.2018.00101},
  abstract  = {A myriad of problems in science and engineering, involve the solution of sparse triangular linear systems. They arise frequently as part of direct and iterative solvers for linear systems and eigenvalue problems, and hence can be considered as a key building block of sparse numerical linear algebra. This is why, since the early days, their parallel solution has been exhaustively studied, and efficient implementations of this kernel can be found for almost every hardware platform. In the GPU context, the most widespread implementation of this kernel is the one distributed in NVIDIA CUSPARSE library, which relies on a preprocessing stage to aggregate the unknowns of the triangular system into level sets. This determines an execution schedule for the solution of the system, where the level sets have to be processed sequentially while the unknowns that belong to one level set can be solved in parallel. One of the disadvantages of the CUSPARSE implementation is that this preprocessing stage is often extremely slow in comparison to the runtime of the solving phase. In this work, we present a parallel GPU algorithm that is able to compute the same level sets as CU S PARSE but takes significantly less runtime. Our experiments on a set of matrices from the SuiteSparse collection show acceleration factors of up to 44$\times$. Additionally, we provide a routine capable of solving a triangular linear system on the same pass used to calculate the level sets, yielding important performance benefits.},
  issn      = {1530-2075},
  keywords  = {eigenvalues and eigenfunctions;graphics processing units;iterative methods;linear systems;parallel algorithms;sparse matrices;parallel GPU algorithm;triangular linear system;parallel solution;sparse triangular linear systems;sparse numerical linear algebra;level set-based analysis;iterative solvers;direct solvers;eigenvalue problems;NVIDIA CUSPARSE library;SuiteSparse collection;Sparse matrices;Level set;Graphics processing units;Linear systems;Kernel;Runtime;Libraries;Sparse triangular linear systems;Level sets;cusparse;Graphics processors (GPUs)},
}

@Article{Tan2018,
  author     = {Tan, Guangming and Liu, Junhong and Li, Jiajia},
  title      = {Design and Implementation of Adaptive SpMV Library for Multicore and Many-Core Architecture},
  journal    = {ACM Trans. Math. Softw.},
  year       = {2018},
  volume     = {44},
  number     = {4},
  month      = aug,
  pages      = {46:1--46:25},
  issn       = {0098-3500},
  doi        = {10.1145/3218823},
  url        = {http://doi.acm.org/10.1145/3218823},
  abstract   = {Sparse matrix vector multiplication (SpMV) is an important computational kernel in traditional high-performance computing and emerging data-intensive applications. Previous SpMV libraries are optimized by either application-specific or architecture-specific approaches but present difficulties for use in real applications. In this work, we develop an auto-tuning system (SMATER) to bridge the gap between specific optimizations and general-purpose use. SMATER provides programmers a unified interface based on the compressed sparse row (CSR) sparse matrix format by implicitly choosing the best format and fastest implementation for any input sparse matrix during runtime. SMATER leverages a machine-learning model and retargetable back-end library to quickly predict the optimal combination. Performance parameters are extracted from 2,386 matrices in the SuiteSparse matrix collection. The experiments show that SMATER achieves good performance (up to 10 times that of the Intel Math Kernel Library (MKL) on Intel E5-2680 v3) while being portable on state-of-the-art x86 multicore processors, NVIDIA GPUs, and Intel Xeon Phi accelerators. Compared with the Intel MKL library, SMATER runs faster by more than 2.5 times on average. We further demonstrate its adaptivity in an algebraic multigrid solver from the Hypre library and report greater than 20\% performance improvement.},
  acmid      = {3218823},
  address    = {New York, NY, USA},
  articleno  = {46},
  issue_date = {August 2018},
  keywords   = {Sparse matrix vector multiplication, auto-tuning, machine learning, multicore},
  numpages   = {25},
  publisher  = {ACM},
}

@InProceedings{Wang2018a,
  author    = {Wang, Xinliang and Xu, Ping and Xue, Wei and Ao, Yulong and Yang, Chao and Fu, Haohuan and Gan, Lin and Yang, Guangwen and Zheng, Weimin},
  title     = {A Fast Sparse Triangular Solver for Structured-grid Problems on Sunway Many-core Processor SW26010},
  booktitle = {Proceedings of the 47th International Conference on Parallel Processing},
  year      = {2018},
  series    = {ICPP 2018},
  publisher = {ACM},
  location  = {Eugene, OR, USA},
  isbn      = {978-1-4503-6510-9},
  pages     = {53:1--53:11},
  doi       = {10.1145/3225058.3225071},
  url       = {http://doi.acm.org/10.1145/3225058.3225071},
  abstract  = {The sparse triangular solver (SpTRSV) is one of the most essential kernels in many scientific and engineering applications. Efficiently parallelizing the SpTRSV on modern many-core architectures is considerably difficult due to inherent dependency of computation and discontinuous memory accesses. Achieving high performance of SpTRSV is even more challenging for SW26010, the new-generation customized heterogeneous many-core processor equipped in the top-rank Sunway TaihuLight supercomputer. Owing to regular sparse pattern, structured-grid triangular problems show much different computing characteristics with general ones as well as new opportunities to algorithm design on many-core architectures, which ever lacks attention. In this work, we focus on how to design and implement fast SpTRSV for structured-grid problems on SW26010. A generalized algorithm framework of parallel SpTRSV is proposed for best utilization of the features and flexibilities of SW26010 many-core architecture according to the fine-grained Producer-Consumer model. Moreover, a novel parallel structured-grid SpTRSV is presented by using direct data transfers across registers of the computing elements of SW26010. Experiments on four typical structured-grid triangular problems with different problem sizes demonstrate that our SpTRSV can achieve an average momory bandwidth utilization of 79.7\% according to the stream benchmark, which leads to a speedup of 17.7 over serial version on SW26010. Furthermore, experiments with real world sparse linear problems show that our proposed SpTRSV can achieve superior preconditioning performance over the Intel Xeon E5-2670 v3 CPU and Intel Xeon Phi 7210 KNL over DDR4 memory.},
  acmid     = {3225071},
  address   = {New York, NY, USA},
  articleno = {53},
  keywords  = {Structured Grid, Sunway TaihuLight, Triangular Solver},
  numpages  = {11},
}

@Article{Abubaker2018,
  author   = {N. F. T. Abubaker and K. Akbudak and C. Aykanat},
  title    = {Spatiotemporal Graph and Hypergraph Partitioning Models for Sparse Matrix-Vector Multiplication on Many-Core Architectures},
  journal  = {{IEEE} Transactions on Parallel and Distributed Systems},
  year     = {2018},
  pages    = {1--1},
  issn     = {1045-9219},
  doi      = {10.1109/TPDS.2018.2864729},
  abstract = {There exist graph/hypergraph partitioning-based row/column reordering methods for encoding either spatial or temporal locality separately for sparse matrix-vector multiplication (SpMV) operations. Spatial and temporal hypergraph models in these methods are extended to encapsulate both spatial and temporal localities based on cut/uncut net categorization obtained from vertex partitioning. These extensions of spatial and temporal hypergraph models encode the spatial locality primarily and the temporal locality secondarily, and vice-versa, respectively. However, the literature lacks models that simultaneously encode both spatial and temporal localities utilizing only vertex partitioning for further improving the performance of SpMV on shared-memory architectures. In order to fill this gap, we propose a novel spatiotemporal hypergraph model that leads to a one-phase spatiotemporal reordering method which encodes both types of locality simultaneously. We also propose a framework for spatiotemporal methods which encodes both types of locality in two dependent phases and two separate phases. The validity of the proposed spatiotemporal models and methods are tested on a wide range of sparse matrices and the experiments are performed on both a 60-core Intel Xeon Phi processor and a Xeon processor. Results show the validity of the methods via almost doubling the Gflop/s performance through enhancing data locality in parallel SpMV operations.},
  keywords = {Spatiotemporal phenomena;Sparse matrices;Data models;Task analysis;Bipartite graph;Encoding;Taxonomy;Sparse matrix;sparse matrix-vector multiplication;data locality;spatial locality;temporal locality;hypergraph model;bipartite graph model;graph model;hypergraph partitioning;graph partitioning;Intel Many Integrated Core Architecture;Intel Xeon Phi},
}

@Article{Acer2018,
  author   = {Seher Acer and Oguz Selvitopi and Cevdet Aykanat},
  title    = {Optimizing nonzero-based sparse matrix partitioning models via reducing latency},
  journal  = {Journal of Parallel and Distributed Computing},
  year     = {2018},
  issn     = {0743-7315},
  doi      = {https://doi.org/10.1016/j.jpdc.2018.08.005},
  url      = {http://www.sciencedirect.com/science/article/pii/S0743731518305860},
  abstract = {For the parallelization of sparse matrix–vector multiplication (SpMV) on distributed memory systems, nonzero-based fine-grain and medium-grain partitioning models attain the lowest communication volume and computational imbalance among all partitioning models. This usually comes, however, at the expense of high message count, i.e., high latency overhead. This work addresses this shortcoming by proposing new fine-grain and medium-grain models that are able to minimize communication volume and message count in a single partitioning phase. The new models utilize message nets in order to encapsulate the minimization of total message count. We further fine-tune these models by proposing delayed addition and thresholding for message nets in order to establish a trade-off between the conflicting objectives of minimizing communication volume and message count. The experiments on an extensive dataset of nearly one thousand matrices show that the proposed models improve the total message count of the original nonzero-based models by up to 27\% on the average, which is reflected on the parallel runtime of SpMV as an average reduction of 15\% on 512 processors.},
  keywords = {Sparse matrix, Sparse matrix–vector multiplication, Row-column-parallel SpMV, Load balancing, Communication overhead, Hypergraph, Fine-grain partitioning, Medium-grain partitioning, Recursive bipartitioning},
}

@Online{Schlag2018,
  author   = {Sebastian Schlag and Christian Schulz and Daniel Seemaier and Darren Strash},
  title    = {Scalable Edge Partitioning},
  year     = {2018},
  abstract = {Edge-centric distributed computations have appeared as a recent technique to improve the shortcomings of think-like-a-vertex algorithms on large scale-free networks. In order to increase parallelism on this model, edge partitioning - partitioning edges into roughly equally sized blocks - has emerged as an alternative to traditional (node-based) graph partitioning. In this work, we give a distributed memory parallel algorithm to compute high-quality edge partitions in a scalable way. Our algorithm scales to networks with billions of edges, and runs efficiently on thousands of PEs. Our technique is based on a fast parallelization of split graph construction and a use of advanced node partitioning algorithms. Our extensive experiments show that our algorithm has high quality on large real-world networks and large hyperbolic random graphs, which have a power law degree distribution and are therefore specifically targeted by edge partitioning},
  eprint   = {arXiv:1808.06411},
}

@InProceedings{Davis2018a,
  author    = {Davis, Timothy A.},
  title     = {Graph algorithms via {SuiteSparse}:{GraphBLAS}:triangle counting and K-truss},
  booktitle = {Proceedings of the IEEE High Performance Extreme Computing Conference},
  year      = {2018},
  series    = {HPEC '18},
  abstract  = {SuiteSparse:GraphBLAS is a full implementation of the GraphBLAS standard, which defines a set of sparse matrix operations on an extended algebra of semirings using an almost unlimited variety of operators and types. When applied to sparse adjacency matrices, these algebraic operations are equivalent tocomputations on graphs. GraphBLAS provides a powerful and expressive framework for creating graph algorithms based on the elegant mathematics of sparse matrix operations on a semiring. To illustrate GraphBLAS, two graph algorithms are constructed in GraphBLAS and compared with efficient implementations without GraphBLAS: triangle counting and constructing the k-truss of a graph.},
  timestamp = {2018.08.27},
}

@InProceedings{Haidar2018,
  author    = {Azzam Haidar and Stanimire Tomov and Jack Dongarra and Nicholas J. Higham},
  title     = {Harnessing a {GPU}’s Tensor Cores for Fast {FP16} Arithmetic to Speed up Mixed-Precision Iterative Refinement Solvers},
  booktitle = {Proceedings of NVIDIA's GPU Technology Conference},
  year      = {2018},
  series    = {GTC '18},
  abstract  = {Recent in-hardware GPU acceleration of half precision arithmetic (FP16) -- motivated by various machine learning (ML) and artificial intelligence (AI) applications -- has reinvigorated a great interest in the mixed-precision iterative refinement technique. The technique is based on use of low precision arithmetic to accelerate the general HPC problem of solving Ax = b, where A is a large dense matrix, and the solution is needed in FP64 accuracy. While being a well known technique, its successful modification, software development, and adjustment to match architecture specifics, is challenging. For current manycore GPUs the challenges range from efficient parallelization to scaling, and using the FP16 arithmetic. Here, we address these challenges by showing how to algorithmically modify, develop high-performance implementations, and in general, how to use the FP16 arithmetic to significantly accelerate, as well as make more energy efficient, FP64-precision Ax = b solvers. One can reproduce our results as the developments will be made available through the MAGMA library. We quantify in 
practice the performance, and limitations of the approach stressing on the use of the Volta V100 Tensor Cores that provide additional FP16 performance boost},
  timestamp = {2018.08.27},
}

@Article{Hogg2013,
  author   = {Hogg, J.},
  title    = {A Fast Dense Triangular Solve in CUDA},
  journal  = {SIAM Journal on Scientific Computing},
  year     = {2013},
  volume   = {35},
  number   = {3},
  pages    = {C303-C322},
  doi      = {10.1137/12088358X},
  abstract = {The level 2 BLAS operation _trsv performs a dense triangular solve and is often used in the solve phase of a direct solver following a matrix factorization. With the advent of manycore architectures reducing the cost of compute-bound parts of the computation, memory-bound operations such as this kernel become increasingly important. This is particularly noticeable in sparse direct solvers used for optimization applications where multiple memory-bound solves follow each (traditionally expensive) compute-bound factorization. In this paper, a high performance implementation of the triangular solve is developed through an analysis of theoretical and practical bounds on its run time. This implementation outperforms the CUBLAS by a factor of 5--15.},
}

@Conference{Abdelfattah2018a,
  author       = {Ahmad Abdelfattah and Azzam Haidar and Stanimire Tomov and Jack Dongarra},
  title        = {Optimizing GPU Kernels for Irregular Batch Workloads: A Case Study for Cholesky Factorization},
  booktitle    = {IEEE High Performance Extreme Computing Conference},
  year         = {2018},
  series       = {HPEC'18},
  organization = {IEEE},
  publisher    = {IEEE},
  month        = {9},
  abstract     = {This paper introduces several frameworks for the design and implementation of high performance GPU kernels that target batch workloads with irregular sizes. Such workloads are ubiquitous in many scientific applications, including sparse direct solvers, astrophysics, and quantum chemistry. The paper addresses two main categories of frameworks, taking the Cholesky factorization as a case study. The first uses host-side kernel launches, and the second uses device-side launches. Within each category, different design options are introduced, with an emphasis on the advantages and the disadvantages of each approach. Our best performing design outperforms the state-of-the-art CPU implementation, scoring up to 4.7$\times$ speedup in double precision on a Pascal P100 GPU.},
  address      = {Waltham, MA},
}

@TechReport{Kaya2018,
  author      = {Oguz Kaya and Ramakrishnan Kannan and Grey Ballard},
  title       = {Partitioning and Communication Strategies for Sparse Non-negative Matrix Factorization},
  institution = {INRIA Bordeaux Sud-Ouest},
  year        = {2018},
  abstract    = {Non-negative matrix factorization (NMF), the problem of finding two non-negative low-rank factors whose product approximates an input matrix, is a useful tool for many data mining and scientific applications such as topic modeling in text mining and blind source separation in microscopy. In this paper, we focus on scaling algorithms for NMF to very large sparse datasets and massively parallel machines by employing effective algorithms, communication patterns, and partitioning schemes that leverage the sparsity of the input matrix. In the case of machine learning workflow, the computations after SpMM must deal with dense matrices, as Sparse-Dense matrix multiplication will result in a dense matrix. Hence, the partitioning strategy considering only SpMM will result in a huge imbalance in the overall workflow especially on computations after SpMM and in this specific case of NMF on non-negative least squares computations. Towards this, we consider two previous works developed for related problems, one that uses a fine-grained partitioning strategy using a point-to-point communication pattern and on that uses a checkerboard partitioning strategy using a collective-based communication pattern. We show that a combination of the previous approaches balances the demands of the various computations within NMF algorithms and achieves high efficiency and scalability. From the experiments, we could see that our proposed algorithm communicates atleast 4x less than the collective and achieves upto 100$\times$ speed up over the baseline FAUN on real world datasets. Our algorithm was experimented in two different super computing platforms and we could scale up to 32000 processors on Bluegene/Q.},
  timestamp   = {2018.08.27},
}

@InProceedings{Cheshmi2018,
  author    = {Kazem Cheshmi and Shoaib Kamil and Michelle Mills Strout and Maryam Mehri Dehnavi},
  title     = {ParSy: Inspection and Transformation of Sparse Matrix Computations for Parallelism},
  booktitle = {{P}roceedings of The International Conference for High Performance Computing, Networking, Storage, and Analysis},
  year      = {2018},
  series    = {SC '18},
  location  = {Dallas, TX, US},
  abstract  = {ParSy is a framework that generates parallel code for sparse matrix computations. It uses a novel inspection strategy along with code transformations to generate parallel code for shared memory processors that is optimized for locality and load balance. Code generated by existing automatic parallelism approaches for sparse algorithms can suffer from load imbalance and excessive synchronization, resulting in performance that does not scale well on multi-core systems. We propose a novel task coarsening strategy that creates well-balanced tasks that can execute in parallel. ParSy-generated code outperforms existing highly-optimized sparse matrix codes such as the Cholesky factorization on multi-core processors with speed-ups of 2.8$\times$ and 3.1$\times$ over the MKL Pardiso and PaStiX libraries respectively.},
}

@Article{Benatia2018,
  author     = {Benatia, Akrem and Ji, Weixing and Wang, Yizhuo and Shi, Feng},
  title      = {{BestSF}: A Sparse Meta-Format for Optimizing {SpMV} on {GPU}},
  journal    = {ACM Transactions on Architecture and Code Optimization ({TACO})},
  year       = {2018},
  volume     = {15},
  number     = {3},
  month      = sep,
  pages      = {29:1--29:27},
  issn       = {1544-3566},
  doi        = {10.1145/3226228},
  url        = {http://doi.acm.org/10.1145/3226228},
  abstract   = {The Sparse Matrix-Vector Multiplication (SpMV) kernel dominates the computing cost in numerous scientific applications. Many implementations based on different sparse formats were proposed to improve this kernel on the recent GPU architectures. However, it has been widely observed that there is no “best-for-all” sparse format for the SpMV kernel on GPU. Indeed, serious performance degradation of an order of magnitude can be observed without a careful selection of the sparse format to use. To address this problem, we propose in this article BestSF (Best Sparse Format), a new learning-based sparse meta-format that automatically selects the most appropriate sparse format for a given input matrix. To do so, BestSF relies on a cost-sensitive classification system trained using Weighted Support Vector Machines (WSVMs) to predict the best sparse format for each input sparse matrix. Our experimental results on two different NVIDIA GPU architectures using a large number of real-world sparse matrices show that BestSF achieved a noticeable overall performance improvement over using a single sparse format. While BestSF is trained to select the best sparse format in terms of performance (GFLOPS), our further experimental investigations revealed that using BestSF also led, in most of the test cases, to the best energy efficiency (MFLOPS/W). To prove its practical effectiveness, we also evaluate the performance and energy efficiency improvement achieved when using BestSF as a building block in a GPU-based Preconditioned Conjugate Gradient (PCG) iterative solver.},
  acmid      = {3226228},
  address    = {New York, NY, USA},
  articleno  = {29},
  issue_date = {August 2018},
  keywords   = {GPU computing, Sparse matrix-vector multiplication (SpMV), energy efficiency, iterative solvers, performance modeling},
  numpages   = {27},
  publisher  = {ACM},
}

@InProceedings{Nakamura2015,
  author    = {Nakamura, Takatoshi and Nodera, Takashi},
  title     = {The Flexible {ILU} Preconditioning for Solving Large Nonsymmetric Linear Systems of Equations},
  booktitle = {Proceedings of the International Workshop on Eigenvalue Problems: Algorithms, Software and Applications in Petascale Computing},
  year      = {2015},
  editor    = {Sakurai, Tetsuya and Zhang, Shao-Liang and Imamura, Toshiyuki and Yamamoto, Yusaku and Kuramashi, Yoshinobu and Hoshi, Takeo},
  series    = {EPASA 2015},
  publisher = {Springer International Publishing},
  isbn      = {978-3-319-62426-6},
  pages     = {51--61},
  abstract  = {The ILU factorization is one of the most popular preconditioners for the Krylov subspace method, alongside the GMRES. Properties of the preconditioner derived from the ILU factorization are relayed onto the dropping rules. Recently, Zhang et al. (Numer Linear Algebra Appl 19:555--569, 2011) proposed a Flexible incomplete Cholesky (IC) factorization for symmetric linear systems. This paper is a study of the extension of the IC factorization to the nonsymmetric case. The new algorithm is called the Crout version of the flexible ILU factorization, and attempts to reduce the number of nonzero elements in the preconditioner and computation time during the GMRES iterations. Numerical results show that our approach is effective and useful.},
}

@Article{Anzt2018,
  author   = {Anzt, Hartwig and Chow, Edmond and Dongarra, Jack},
  title    = {ParILUT -- A New Parallel Threshold ILU Factorization},
  journal  = {SIAM Journal on Scientific Computing},
  year     = {2018},
  volume   = {40},
  number   = {4},
  pages    = {C503-C519},
  doi      = {10.1137/16M1079506},
  abstract = {We propose a parallel algorithm for computing a threshold incomplete LU (ILU) factorization. The main idea is to interleave a parallel fixed-point iteration that approximates an incomplete factorization for a given sparsity pattern with a procedure that adjusts the pattern. We describe and test a strategy for identifying nonzeros to be added and nonzeros to be removed from the sparsity pattern. The resulting pattern may be different and more effective than that of existing threshold ILU algorithms. Also in contrast to other parallel threshold ILU algorithms, much of the new algorithm has fine-grained parallelism.},
}

@Article{Dziekonski2018,
  author    = {A. Dziekonski and M. Mrozowski},
  title     = {A {GPU} Solver for Sparse Generalized Eigenvalue Problems with Symmetric Complex-Valued Matrices Obtained Using Higher-Order FEM},
  journal   = {IEEE Access},
  year      = {2018},
  date      = {2018},
  doi       = {10.1109/access.2018.2871219},
  abstract  = {The paper discusses a fast implementation of the stabilized locally optimal block preconditioned conjugate gradient (sLOBPCG) method, using a hierarchical multilevel preconditioner to solve non-Hermitian sparse generalized eigenvalue problems with large symmetric complex-valued matrices obtained using the higher-order finite-element method (FEM), applied to the analysis of a microwave resonator. The resonant  frequencies  of  the  low-order  modes  are  the  eigenvalues  of  the  smallest  real  part  of  a  complex symmetric  (though  non-Hermitian)  matrix  pencil.  These  type  of  pencils  arise  in  the  FEM analysis  of resonant cavities loaded with a lossy material. To accelerate the computations, graphics processing units (GPU, NVIDIA Pascal P100) were used. Single and dual-GPU variants are considered and a GPU-memory-saving implementation is proposed. An efficient sliced ELLR-T sparse matrix storage format was used and operations were performed on blocks of vectors for best performance on a GPU. As a result, significant speedups (exceeding a factor of six in some computational scenarios) were achieved over the reference parallel implementation using a multicore central processing unit (CPU, Intel Xeon E5-2680 v3, twelve cores). These results indicate that the solution of generalized eigenproblems needs much more GPU memory than iterative techniques when solving a sparse system of equations, and also requires a second GPU to store some data structures in order to reduce the footprint, even for a moderately large systems.},
  timestamp = {2018.10.10},
}

@Article{Goddard2018,
  author    = {Goddard, Anthony and Wathen, Andy},
  title     = {A note on parallel preconditioning for all-at-once evolutionary {PDE}s},
  journal   = {Electronic Transactions on Numerical Analysis},
  year      = {2018},
  volume    = {XX},
  abstract  = {McDonald, Pestana and Wathen (SIAM J. Sci. Comput. 40 (2), pp. A2012–A1033, 2018) present a method for preconditioning of time-dependent PDEs via approximation by a nearby time-periodic problem, that is, they employ circulant-related matrices as preconditioners for the non-symmetric block Toeplitz matrices which arise from an all-at-once formulation. They suggest that such an approach might be efficiently implemented in parallel. In this short article, we present parallel numerical results for their preconditioner which exhibit strong scaling. We also extend their preconditioner via a Neumann series approach, which also allows for efficient parallel execution. Our simple implementation (in C++ and MPI) is available at the Git repository PARALAAOMPI.},
  timestamp = {2018.10.10},
}

@Article{Miyata2018,
  author   = {Miyata, Takafumi},
  title    = {On Correction-Based Iterative Methods for Eigenvalue Problems},
  journal  = {IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences},
  year     = {2018},
  volume   = {E101.A},
  number   = {10},
  pages    = {1668--1675},
  doi      = {10.1587/transfun.E101.A.1668},
  abstract = {The Jacobi-Davidson method and the Riccati method for eigenvalue problems are studied. In the methods, one has to solve a nonlinear equation called the correction equation per iteration, and the difference between the methods comes from how to solve the equation. In the Jacobi-Davidson/Riccati method the correction equation is solved with/without linearization. In the literature, avoiding the linearization is known as an improvement to get a better solution of the equation and bring the faster convergence. In fact, the Riccati method showed superior convergence behavior for some problems. Nevertheless the advantage of the Riccati method is still unclear, because the correction equation is solved not exactly but with low accuracy. In this paper, we analyzed the approximate solution of the correction equation and clarified the point that the Riccati method is specialized for computing particular solutions of eigenvalue problems. The result suggests that the two methods should be selectively used depending on target solutions. Our analysis was verified by numerical experiments.},
}

@Online{Fukaya2018,
  author     = {Takeshi Fukaya and Ramaseshan Kannan and Yuji Nakatsukasa and Yusaku Yamamoto and Yuka Yanagisawa},
  title      = {Shifted CholeskyQR for computing the QR factorization of ill-conditioned matrices},
  year       = {2018},
  abstract   = {The Cholesky QR algorithm is an efficient communication-minimizing algorithm for computing the QR factorization of a tall-skinny matrix. Unfortunately it has the inherent numerical instability and breakdown when the matrix is ill-conditioned. A recent work establishes that the instability can be cured by repeating the algorithm twice (called CholeskyQR2). However, the applicability of CholeskyQR2 is still limited by the requirement that the Cholesky factorization of the Gram matrix runs to completion, which means it does not always work for matrices X with $\kappa_2(X) \ge u^{-\frac{1}{2}}$ where $u$ is the unit roundoff. In this work we extend the applicability to $\kappa_2(X)=\mathcal{O}(u^{-1})$ by introducing a shift to the computed Gram matrix so as to guarantee the Cholesky factorization $R^T R = A^T A+sI$ succeeds numerically. We show that the computed $A R^{-1}$ has reduced condition number ${} \le u^{-\frac{1}{2*}}$, for which CholeskyQR2 safely computes the QR factorization, yielding a computed Q of orthogonality $\mid Q^T Q - I\mid_2$ and residual $\mid A-QR\mid _F/\mid A\mid_F$ both $\mathcal{O}(u)$. Thus we obtain the required QR factorization by essentially running Cholesky QR thrice. We extensively analyze the resulting algorithm shiftedCholeskyQR to reveal its excellent numerical stability. shiftedCholeskyQR is also highly parallelizable, and applicable and effective also when working in an oblique inner product space. We illustrate our findings through experiments, in which we achieve significant (up to $\times$40) speedup over alternative methods.},
  eprint     = {arXiv:1809.11085},
  eprinttype = {arXiv},
}

@TechReport{Kurzak2018,
  author      = {Kurzak, Jakub and Gates, Mark and Yamazaki, Ichitaro and Charara, Ali and YarKhan, Asim and Finney, Jamie and Ragghianti, Gerald and Luszczek, Piotr and Dongarra, Jack},
  title       = {{SLATE} Working Note 8: Linear Systems Performance Report},
  institution = {Innovative Computing Laboratory, University of Tennessee},
  year        = {2018},
  number      = {ICL-UT-XX-XX},
  note        = {revision 09-2018},
  month       = {9},
  abstract    = {Software for Linear Algebra Targeting Exascale (SLATE) is being developed as part of the Exascale Computing Project (ECP), which is a collaborative effort between two US Department of Energy (DOE) organizations, the Office of Science and the National Nuclear Security Administration (NNSA). The purpose of SLATE is to serve as a replacement for ScaLAPACK for the upcoming pre-exascale and exascale DOE machines. SLATE will accomplish this objective by leveraging recent progress in parallel programming models and by strongly focusing on
supporting hardware accelerators.

This report focuses on the set of SLATE routines that solve linear systems of equations. Specifically, initial performance numbers are reported, alongside ScaLAPACK performance numbers, on the SummitDev machine at the Oak Ridge Leadership Computing Facility (OLCF). More
details about the design of the SLATE software infrastructure can be found in the report by Kurzak et al.},
}

@Article{Su2018,
  author     = {Su, Xing and Liao, Xiangke and Jiang, Hao and Yang, Canqun and Xue, Jingling},
  title      = {{SCP}: Shared Cache Partitioning for High-Performance {GEMM}},
  journal    = {ACM Transactions on Architecture and Code Optimization},
  year       = {2018},
  series     = {TACO},
  volume     = {15},
  number     = {4},
  month      = oct,
  pages      = {43:1--43:21},
  issn       = {1544-3566},
  doi        = {10.1145/3274654},
  abstract   = {GEneral Matrix Multiply (GEMM) is the most fundamental computational kernel routine in the BLAS library. To achieve high performance, in-memory data must be prefetched into fast on-chip caches before they are used. Two techniques, software prefetching and data packing, have been used to effectively exploit the capability of on-chip least recent used (LRU) caches, which are popular in traditional high-performance processors used in high-end servers and supercomputers. However, the market has recently witnessed a new diversity in processor design, resulting in high-performance processors equipped with shared caches with non-LRU replacement policies. This poses a challenge to the development of high-performance GEMM in a multithreaded context. As several threads try to load data into a shared cache simultaneously, interthread cache conflicts will increase significantly. We present a Shared Cache Partitioning (SCP) method to eliminate interthread cache conflicts in the GEMM routines, by partitioning a shared cache into physically disjoint sets and assigning different sets to different threads. We have implemented SCP in the OpenBLAS library and evaluated it on Phytium 2000+, a 64-core AArch64 processor with private LRU L1 caches and shared pseudo-random L2 caches (per four-core cluster). Our evaluation shows that SCP has effectively reduced the conflict misses in both L1 and L2 caches in a highly optimized GEMM implementation, resulting in an improvement of its performance by 2.75\% to 6.91\%.},
  acmid      = {3274654},
  address    = {New York, NY, USA},
  articleno  = {43},
  issue_date = {October 2018},
  keywords   = {BLAS, GEMM, high-performance computing, linear algebra, optimization},
  numpages   = {21},
  publisher  = {ACM},
}

@Article{Bernaschi2018,
  author   = {Bernaschi, Massimo and D'Ambra, Pasqua and Pasquini, Dario},
  title    = {AMG based on compatible weighted matching},
  journal  = {Parallel Computing},
  year     = {2018},
  date     = {2018},
  abstract = {We describe main issues and design principles of an efficient implementation, tailored to recent generations of Nvidia Graphics Processing Units (GPUs), of an Algebraic MultiGrid (AMG) preconditioner previously proposed by one of the authors and already available in the open-source package BootCMatch: Bootstrap algebraic multigrid based on Compatible weighted Matching for standard CPU. The AMG method relies on a new approach for coarsening sparse symmetric positive definite (s.p.d.) matrices, named coarsening based on compatible weighted matching. It exploits maximum weight matching in the adjacency graph of the sparse matrix, driven by the principle of compatible relaxation, providing a suitable aggregation of unknowns which goes beyond the limits of the usual heuristics applied in the current methods. We adopt an approximate solution of the maximum weight matching problem, based on a recently proposed parallel algorithm, referred as the Suitor algorithm, and show that it allow us to obtain good quality coarse matrices for our AMG on GPUs. We exploit inherent parallelism of modern GPUs in all the kernels involving sparse matrix computations both for the setup of the preconditioner and for its application in a Krylov solver, outperforming preconditioners available in Nvidia AmgX library. We report results about a large set of linear systems arising from discretization of scalar and vector partial differential equations (PDEs).},
}

@Article{Kirmani2018,
  author   = {Shad Kirmani and Hongyang Sun and Padma Raghavan},
  title    = {A Scalability and Sensitivity Study of Parallel Geometric Algorithms for Graph Partitioning},
  year     = {2018},
  doi      = {10.13140/RG.2.2.32020.96644},
  abstract = {Graph partitioning arises in many computational simulation workloads, including those that involve finite difference or finite element methods, where partitioning enables efficient parallel processing of the entire simulation. We focus on parallel geometric algorithms for partitioning large graphs whose vertices are associated with coordinates in two-or three-dimensional space on multi-core processors. Compared with other types of partitioning algorithms, geometric schemes generally show better scalability on a large number of processors or cores. This paper studies the scalability and sensitivity of two parallel algorithms, namely, recursive coordinate bisection (denoted by pRCB) and geometric mesh partitioning (denoted by pGMP), in terms of their robustness to several key factors that affect the partition quality, including coordinate perturbation, approximate embedding, mesh quality and graph planarity. Our results indicate that the quality of a partition as measured by the size of the edge separator (or cutsize) remains consistently better for pGMP compared to pRCB. On average for our test suite, relative to pRCB, pGMP yields 25\% smaller cutsizes on the original embedding, and across all perturbations cutsizes that are smaller by at least 8\% and by as much as 50\%. Not surprisingly, higher quality cuts are obtained at the expense of longer execution times; on a single core, pGMP has an average execution time that is almost 10 times slower than that of pRCB, but it scales better and catches up at 32-cores to be slower by less than 20\%. With the current trends in core counts that continue to increase per chip, these results suggest that pGMP presents an attractive solution if a modest number of cores can be deployed to reduce execution times while providing high quality partitions.},
}

@InProceedings{Abe2018,
  author    = {Abe, Kuniyoshi},
  title     = {On Convergence Speed of Parallel Variants of BiCGSTAB for Solving Linear Equations},
  booktitle = {Methods and Applications for Modeling and Simulation of Complex Systems},
  year      = {2018},
  editor    = {Li, Liang and Hasegawa, Kyoko and Tanaka, Satoshi},
  publisher = {Springer Singapore},
  isbn      = {9789811328534},
  pages     = {401--413},
  abstract  = {A number of hybrid Bi-Conjugate Gradient (Bi-CG) methods such as the Bi-CG STABilized (BiCGSTAB) method have been developed for solving linear equations. BiCGSTAB has been most often used for efficiently solving the linear equations, but we have sometimes seen the convergence behavior with a long stagnation phase. In such cases, it is important to have Bi-CG coefficients that are as accurate as possible, and the stabilization strategy for improving the accuracy of the Bi-CG coefficients has been proposed. In present petascale high-performance computing hardware, the main bottleneck of Krylov subspace methods for efficient parallelization is the inner products which require a global reduction. The parallel variants of BiCGSTAB such as communication avoiding and pipelined BiCGSTAB reducing the number of global communication phases and hiding the communication latency have been proposed. However, the numerical stability, specifically, the convergence speed of the parallel variants of BiCGSTAB has not previously been clarified on problems with situations where the convergence is slow (strongly affected by rounding errors). In this paper, therefore, we examine the convergence speed between the standard BiCGSTAB and the parallel variants, and the effectiveness of the stabilization strategy by numerical experiments on the problems where the convergence has a long stagnation phase.},
  address   = {Singapore},
}

@Online{Rong2018,
  author     = {Hongbo Rong},
  title      = {Expressing Sparse Matrix Computations for Productive Performance on Spatial Architectures},
  year       = {2018},
  abstract   = {This paper addresses spatial programming of sparse matrix computations for productive performance. The challenge is how to express an irregular computation and its optimizations in a regular way.

A sparse matrix has (non-zero) values and a structure. In this paper, we propose to classify the implementations of a computation on a sparse matrix into two categories: (1) structure-driven, or top-down, approach, which traverses the structure with given row and column indices and locates the corresponding values, and (2) values-driven, or bottom-up, approach, which loads and processes the values in parallel streams, and decodes the structure for the values’ corresponding row and column indices. On a spatial architecture like FPGAs, the values-driven approach is the norm. We show how to express a sparse matrix computation and its optimizations for a values-driven implementation. A compiler automatically synthesizes a code to decode the structure. In this way, programmers focus on optimizing the processing of the values, using familiar optimizations for dense matrices, while leaving the complex, irregular structure traversal to an automatic compiler. We also attempt to regularize the optimizations of the reduction for a dynamic number of values, which is common in a sparse matrix computation.},
  eprint     = {arXiv:1810.07517},
  eprinttype = {arXiv},
}

@Article{Carson2018,
  author   = {Carson, E. and Rozložník, M. and Strakoš, Z. and Tichý, P. and Tůma, M.},
  title    = {The Numerical Stability Analysis of Pipelined Conjugate Gradient Methods: Historical Context and Methodology},
  journal  = {SIAM Journal on Scientific Computing},
  year     = {2018},
  volume   = {40},
  number   = {5},
  pages    = {A3549-A3580},
  doi      = {10.1137/16M1103361},
  abstract = {Algebraic solvers based on preconditioned Krylov subspace methods are among the most powerful tools for large-scale numerical computations in applied mathematics, sciences, technology, as well as in emerging applications in social sciences. As the name suggests, Krylov subspace methods can be viewed as a sequence of projections onto nested subspaces of increasing dimension. They are therefore by their nature implemented as synchronized recurrences. This is the fundamental obstacle to efficient parallel implementation. Standard approaches to overcoming this obstacle described in the literature involve reducing the number of global synchronization points and increasing parallelism in performing arithmetic operations within individual iterations. One such approach, employed by the so-called pipelined Krylov subspace methods, involves overlapping the global communication needed for computing inner products with local arithmetic computations. Inexact computations in Krylov subspace methods, due to either floating point roundoff error or intentional action motivated by savings in computing time or energy consumption, have two basic effects, namely, slowing down convergence and limiting attainable accuracy. Although the methodologies for their investigation are different, these phenomena are closely related and cannot be separated from one another. The study of mathematical properties of Krylov subspace methods, in both the cases of exact and inexact computations, is a very active area of research and many issues in the analytic theory of Krylov subspace methods remain open. Numerical stability issues have been studied since the formulation of the conjugate gradient method in the middle of the last century, with many remarkable results achieved since then. Recently, the issues of attainable accuracy and delayed convergence caused by inexact computations became of interest in relation to pipelined conjugate gradient methods and their generalizations. In this contribution we recall the related early results and developments in synchronization-reducing conjugate gradient methods, identify the main factors determining possible numerical instabilities, and present a methodology for the analysis and understanding of pipelined conjugate gradient methods. We derive an expression for the residual gap that applies to any conjugate gradient method variant that uses a particular auxiliary vector in updating the residual, including pipelined conjugate gradient methods, and show how this result can be used to perform a full-scale analysis for a particular implementation. The paper concludes with a brief perspective on Krylov subspace methods in the forthcoming exascale era.},
}

@Article{Mohammad2018,
  author   = {Hassan Mohammad and Mohammed Yusuf Waziri and Sandra Augusta Santos},
  title    = {A brief survey of methods for solving nonlinear least-squares problems},
  journal  = {Numerical Algebra, Control \& Optimization},
  year     = {2018},
  volume   = {9},
  number   = {2155-3289_2019_1_1},
  pages    = {1},
  issn     = {2155-3289},
  doi      = {10.3934/naco.2019001},
  url      = {http://aimsciences.org//article/id/7e25fb2d-b50c-46dd-9be5-23deee2b4242},
  abstract = {In this paper, we present a brief survey of methods for solving nonlinear least-squares problems. We pay specific attention to methods that take into account the special structure of the problems. Most of the methods discussed belong to the quasi-Newton family (i.e. the structured quasi-Newton methods (SQN)). Our survey comprises some of the traditional and modern developed methods for nonlinear least-squares problems. At the end, we suggest a few topics for further research.},
}

@Article{Aliaga2018,
  author   = {Aliaga, José I. and Dufrechou, Ernesto and Ezzatti, Pablo and Quintana-Ortíz, Enrique S.},
  title    = {An efficient GPU version of the preconditioned GMRES method},
  journal  = {The Journal of Supercomputing},
  year     = {2018},
  month    = {10},
  issn     = {1573-0484},
  doi      = {10.1007/s11227-018-2658-1},
  url      = {https://doi.org/10.1007/s11227-018-2658-1},
  abstract = {In a large number of scientific applications, the solution of sparse linear systems is the stage that concentrates most of the computational effort. This situation has motivated the study and development of several iterative solvers, among which preconditioned Krylov subspace methods occupy a place of privilege. In a previous effort, we developed a GPU-aware version of the GMRES method included in ILUPACK, a package of solvers distinguished by its inverse-based multilevel ILU preconditioner. In this work, we study the performance of our previous proposal and integrate several enhancements in order to mitigate its principal bottlenecks. The numerical evaluation shows that our novel proposal can reach important run-time reductions.},
  day      = {25},
}

@Article{Franchetti2018,
  author   = {Franz Franchetti and José M. F. Moura and David A. Padua and Jack Dongarra},
  title    = {From High-Level Specification to High-Performance Code},
  journal  = {Proceedings of the IEEE},
  year     = {2018},
  volume   = {106},
  issue    = {11},
  pages    = {1875--1878},
  abstract = {Computer architectures and systems are becoming ever more powerful but increasingly more complex. With the end of frequency scaling (about 2004) and the era of multicores/manycores/accelerators, it is exceedingly hard to extract the promised performance, in particular, at a reasonable energy budget. Only highly trained and educated experts can hope to conquer this barrier that, if not appropriately dealt with, can translate into multiple orders of magnitude of underutilization of computer systems when programmed by less specialized programmers or domain scientists. To overcome this challenge, the last ten years have seen a flurry of activity to automate the design and generation of highly efficient implementations for these multicore/ manycore architectures, and to translate high level descriptions of programs into high performance and power efficiency},
}

@Report{Cayrols2018,
  author      = {Sébastien Cayrols, Iain Duff, Florent Lopez},
  title       = {Parallelization of the solve phase in a task-based Cholesky solver using a sequential task flow model},
  type        = {Technical Report},
  institution = {Science \& Technology Facilities Council, UK},
  year        = {2018},
  abstract    = {We describe the parallelization of the solve phase in the sparse Cholesky solver SpLLT [Duff, Hogg, and Lopez. Numerical Algebra, Control and Optimization. Volume 8, 235-237, 2018] when using a sequential task flow (STF) model. In the context of direct methods, the solution of a sparse linear system is achieved through three main phases: the analyse, the factorization and the solve phases. In the last two phases which involve numerical computation, the factorization corresponds to the most computationally costly phase, and it is therefore crucial to parallelize this phase in order to reduce the time-to-solution on modern architectures. As a consequence, the solve phase is often not as optimized as the factorization in state-of-the-art solvers and opportunities for parallelism are often not exploited in this phase. However, in some applications, the time spent in the solve phase is comparable or even greater than the time for the factorization and the user could dramatically benefit from a faster solve routine. This is the case, for example, for a CG solver using a block Jacobi preconditioner. The diagonal blocks are factorized once only but their factors are used to solve subsystems at each CG iteration. In this study we design and implement a parallel version of a task-based solve routine for an OpenMP version of the SpLLT solver. We show that we can obtain good scalability on a multicore architecture enabling a dramatic reduction of the overall time-to-solution in some applications.},
}

@Online{Knigge2018,
  author     = {Timon E. Knigge and Rob H. Bisseling},
  title      = {An improved exact algorithm and an NP-completeness proof for sparse matrix bipartitioning},
  year       = {2018},
  abstract   = {We formulate the sparse matrix bipartitioning problem of minimizing the communication volume in parallel sparse matrix-vector multiplication. We prove its NP-completeness in the perfectly balanced case, where both parts of the partitioned matrix must have an equal number of nonzeros, by reduction from the graph bisection problem. We present an improved exact branch-and-bound algorithm which finds the minimum communication volume for a given maximum allowed imbalance. The algorithm is based on a maximum-flow bound and a pack- ing bound, which extend previous matching and packing bounds. We implemented the algorithm in a new program called MP (Matrix Partitioner), which solved 839 matrices from the SuiteSparse collection to optimality, each within 24 hours of CPU-time. Furthermore, MP solved the difficult problem of the matrix cage6 in about 3 days. The new program is about 13.8 times faster than the previous program MondriaanOpt.},
  eprint     = {arXiv:1811.02043},
  eprinttype = {arXiv},
}

@Article{Cartis2018,
  author     = {Coralia Cartis and Nick I. M. Gould and Philippe L. Toint},
  title      = {Sharp worst-case evaluation complexity bounds for arbitrary-order nonconvex optimization with inexpensive constraints},
  year       = {2018},
  eprint     = {arXiv:1811.01220},
  eprinttype = {arXiv},
  abstract   = {We provide sharp worst-case evaluation complexity bounds for non convex minimization problems with general inexpensive constraints, i.e. problems where the cost of evaluating/enforcing of the (possibly nonconvex or even disconnected) constraints, if any, is negligible compared to that of evaluating the objective function.  These bounds unify, extend or improve all known upper and lower complexity bounds for unconstrained and convexly-constrained problems. It is shown that, given an accuracy level $\epsilon$, a degree of highest available Lipschitz continuous derivatives $p$ and a desired optimality order $q$ between one and $p$, a conceptual regularization algorithm requires no more than $O(\epsilon^{-\frac{p+1}{p-q+1}}$ evaluations of the objective function and its derivatives to compute a suitably approximate $q$-th order minimizer. With an appropriate choice of the regularization, a similar result also holds if the $p$-th derivative is merely Holder rather than Lipschitz continuous. We provide an example that shows that the above complexity bound is sharp for unconstrained and a wide class of constrained problems; we also give reasons for the optimality of regularization methods from a worst-case complexity point of view, within a large class of algorithms that use the same derivative information.},
}

@TechReport{Buttari2018,
  author      = {Buttari, Alfredo},
  title       = {Scalability of parallel sparse direct solvers: methods, memory and performance},
  institution = {IRIT, Institut de recherche en informatique de Toulouse},
  year        = {2018},
  type        = {Habilitation {\`a} diriger des recherches},
  month       = Sep,
  url         = {https://hal.archives-ouvertes.fr/tel-01913033},
  abstract    = {The fast and accurate solution of large size sparse systems of linear equations is at the heart of numerical applications from a very broad range of domains including structural mechanics, fluid dynamics, geophysics, medical imaging, chemistry. Among the most commonly used techniques, direct methods, based on the factorization of the system matrix, are generally appreciated for their numerical robustness and ease of use. These advantages, however, come at the price of a considerable operations count and memory footprint. The work presented in this thesis is concerned with improving the scalability of sparse direct solvers, intended as the ability to solve problems of larger and larger size. More precisely, our work aims at developing solvers which are scalable in performance, memory consumption and complexity. We address performance scalability, that is the ability to reduce the execution time as more computational resources are available, introducing algorithms that improve parallelism by reducing communications and synchronizations. We discuss the use of novel parallel programming paradigms and tools to achieve their implementation in an efficient and portable way on modern, heterogeneous supercomputers. We present methods that make sparse direct solvers memory-scalable, that is, capable of taking advantage of parallelism without increasing the overall memory footprint. Finally we show how it is possible to use data sparsity to achieve an asymptotic reduction of the cost of such methods. The presented algorithms have been implemented in the freely distributed MUMPS and qr_mumps solver packages and their effectiveness assessed on real life problems from academic and industrial applications.},
  file        = {hdr_manuscript.pdf:https\://hal.archives-ouvertes.fr/tel-01913033/file/hdr_manuscript.pdf:PDF},
  hal_id      = {tel-01913033},
  hal_version = {v1},
  keywords    = {Sparse linear system ; linear algebra ; sparse direct methods ; parallel high performance computing ; Syst{\`e}mes lin{\'e}aires creux ; alg{\`e}bre lin{\'e}aire ; m{\'e}thodes directes ; calcul parall{\`e}le {\`a} haute performance},
  school      = {{Toulouse INP}},
}

@InProceedings{Stoltzfus2018,
  author    = {Stoltzfus, Larisa and Emani, Murali and Lin, Pei-Hung and Liao, Chunhua},
  title     = {Data Placement Optimization in GPU Memory Hierarchy Using Predictive Modeling},
  booktitle = {Proceedings of the Workshop on Memory Centric High Performance Computing},
  year      = {2018},
  series    = {MCHPC'18},
  publisher = {ACM},
  location  = {Dallas, TX, USA},
  isbn      = {978-1-4503-6113-2},
  pages     = {45--49},
  doi       = {10.1145/3286475.3286482},
  url       = {http://doi.acm.org/10.1145/3286475.3286482},
  abstract  = {Modern supercomputers often use Graphic Processing Units (or GPUs) to meet the ever-growing demands for high performance computing. GPUs typically have a complex memory architecture with various types of memories and caches, such as global memory, shared memory, constant memory, and texture memory. The placement of data on these memories has a tremendous impact on the performance of the HPC applications and identifying the optimal placement location is non-trivial.\\
In this paper, we propose a machine learning-based approach to build a classifier to determine the best class of GPU memory that will minimize GPU kernel execution time. This approach utilizes a set of performance counters obtained from profiling runs along with hardware features to generate the trained model. We evaluate our approach on several generations of NVIDIA GPUs, including Kepler, Maxwell, Pascal, and Volta on a set of benchmarks. The results show that the trained model achieves prediction accuracy over 90\% and given a global version, the classifier can accurately determine which data placement variant would yield the best performance.},
  acmid     = {3286482},
  address   = {New York, NY, USA},
  keywords  = {Data placement, GPU, Machine Learning, Memory},
  numpages  = {5},
}

@InProceedings{Yang2018,
  author    = {Carl Yang},
  title     = {Linear Algebra is the Right Way to Think About Graphs},
  booktitle = {Proceedings of the 2018 ACM/IEEE Supercomputing Conference},
  year      = {2018},
  series    = {SC'18},
  abstract  = {Graph algorithms are challenging to implement on new accelerators such as GPUs. To address this problem, GraphBLAS is an innovative on-going effort by the graph analytics community to formulate graph algorithms as sparse linear algebra, so that they can be expressed in a performant, succinct and in a backend-agnostic manner. Initial research efforts in implementing GraphBLAS on GPUs for graph processing and analytics have been promising, but challenges such as feature-incompleteness and poor performance still exist compared to their vertex-centric (“think like a vertex”) graph framework counterparts. For our thesis, we propose a multi-language graph framework aiming to simplify the development of graph algorithms, which 1) provides a multi-language GraphBLAS interface for the end-users to express, develop, and refine graph algorithms more succinctly than existing distributed graph frameworks; 2) abstracts away from the end-users performance tuning decisions; 3) utilizes the advantages of existing low-level GPU computing primitives to maintain high performance.},
}

@Article{Aliaga2018a,
  author   = {José I. Aliaga, María Barreda, Asunción Castaño},
  title    = {Energy-aware Strategies for Task-parallel Sparse Linear System Solvers},
  journal  = {Concurrency and Computation Practice and Experience},
  year     = {2018},
  doi      = {10.1002/cpe.4633},
  abstract = {We present some energy-aware strategies to improve the energy efficiency of a task-parallel preconditioned Conjugate Gradient (PCG) iterative solver on a Haswell-EP Intel Xeon. These techniques leverage the power-saving states of the processor, promoting the hardware into a more energy-efficient C-state and modifying the CPU frequency (P-states of the processors) of some operations of the PCG. We demonstrate that the application of these strategies during the main operations of the iterative solver can reduce its energy consumption considerably.},
}

@Article{Zhang2018,
  author     = {Zhang, Yunming and Yang, Mengjiao and Baghdadi, Riyadh and Kamil, Shoaib and Shun, Julian and Amarasinghe, Saman},
  title      = {GraphIt: A High-performance Graph DSL},
  journal    = {Proceedings of the ACM Conference on Programming Languages},
  year       = {2018},
  series     = {OOPSLA'18},
  volume     = {2},
  month      = oct,
  pages      = {121:1--121:30},
  issn       = {2475-1421},
  doi        = {10.1145/3276491},
  abstract   = {The performance bottlenecks of graph applications depend not only on the algorithm and the underlying hardware, but also on the size and structure of the input graph. As a result, programmers must try different combinations of a large set of techniques, which make tradeoffs among locality, work-efficiency, and parallelism, to develop the best implementation for a specific algorithm and type of graph. Existing graph frameworks and domain specific languages (DSLs) lack flexibility, supporting only a limited set of optimizations.\\
This paper introduces GraphIt, a new DSL for graph computations that generates fast implementations for algorithms with different performance characteristics running on graphs with different sizes and structures. GraphIt separates what is computed (algorithm) from how it is computed (schedule). Programmers specify the algorithm using an algorithm language, and performance optimizations are specified using a separate scheduling language. The algorithm language simplifies expressing the algorithms, while exposing opportunities for optimizations. We formulate graph optimizations, including edge traversal direction, data layout, parallelization, cache, NUMA, and kernel fusion optimizations, as tradeoffs among locality, parallelism, and work-efficiency. The scheduling language enables programmers to easily search through this complicated tradeoff space by composing together a large set of edge traversal, vertex data layout, and program structure optimizations. The separation of algorithm and schedule also enables us to build an autotuner on top of GraphIt to automatically find high-performance schedules. The compiler uses a new scheduling representation, the graph iteration space, to model, compose, and ensure the validity of the large number of optimizations. We evaluate GraphIt’s performance with seven algorithms on graphs with different structures and sizes. GraphIt outperforms the next fastest of six state-of-the-art shared-memory frameworks (Ligra, Green-Marl, GraphMat, Galois, Gemini, and Grazelle) on 24 out of 32 experiments by up to 4.8$\times$, and is never more than 43\% slower than the fastest framework on the other experiments. GraphIt also reduces the lines of code by up to an order of magnitude compared to the next fastest framework.},
  acmid      = {3276491},
  address    = {New York, NY, USA},
  articleno  = {121},
  issue_date = {November 2018},
  keywords   = {Big Data, Code Generation, Compiler Optimizations, Domain Specific Languages, Graph Algorithms, Parallel Programming Languages},
  numpages   = {30},
  publisher  = {ACM},
}

@Article{Neumann2018,
  author    = {Christoph Neumann and Oliver Stein},
  title     = {Generating feasible points for mixed-integer convex optimization problems by inner parallel cuts},
  journal   = {Optimization Online},
  year      = {2018},
  note      = {Preprint ID 2018-11-6947},
  abstract  = {In this article we introduce an inner parallel cutting plane method (IPCP) to compute good feasible points for mixed-integer convex optimization problems. The method iteratively generates polyhedral outer approximations of an enlarged inner parallel set (EIPS) of the continuously relaxed feasible set. This EIPS possesses the crucial property that any rounding of any of its elements is feasible for the original problem. The outer approximations are refined in each iteration by using modified Kelley cutting planes, which are defined via rounded optimal points of linear opti- mization problems (LPs).\\ We show that the method either computes a feasible point or certifies that the EIPS is empty. Moreover, we provide bounds on the objective value of the generated feasible point. As there exist consistent problems which possess an empty EIPS, the IPCP is not guaranteed to find a feasible point for the latter. Yet, the crucial advantage of the method lies in the complexity of each iteration: While other approaches need to solve a mixed-integer linear optimization problem, the IPCP only needs to solve an LP, which can be carried out efficiently. Our computational study indicates that the IPCP is able to quickly find feasible points for many practical applications. It further demonstrates that the objective values of the computed feasible points are generally of good quality and sometimes not easily obtainable by other methods.},
  timestamp = {2018.12.20},
}

@InProceedings{Franceschini2018,
  author    = {Andrea Franceschini and Massimiliano Ferronato and Carlo Janna and Victor A.P. Magri},
  title     = {Recent advancements in preconditioning techniques for large size linear systems suited for High Performance Computing},
  booktitle = {Seminari Padovani di Analisi Numerica 2018},
  year      = {2018},
  volume    = {11},
  series    = {SPAN2018},
  pages     = {11--22},
  abstract  = {The numerical simulations of real-world engineering problems create models with several millions or even billions of degrees of freedom. Most of these simulations are centered on the solution of systems of non-linear equations, that, once linearized, become a sequence of linear systems, whose solution is often the most time-demanding task. Thus, in order to increase the capability of modeling larger cases, it is of paramount importance to exploit the resources of High Performance Computing architectures. In this framework, the development of new algorithms to accelerate the solution of linear systems for many-core architectures is a really active research field.  Our main focus is algebraic preconditioning and, among the various options, we elect to develop approximate inverses for symmetric and positive definite (SPD) linear systems [22], both as stand-alone preconditioner or smoother for AMG techniques. This choice is mainly supported by the almost perfect parallelism that intrinsically characterizes these algorithms. As basic kernel, the Factorized Sparse Approximate Inverse (FSAI) developed in its adaptive form by Janna and Ferronato [18] is selected. Recent developments are i) a robust multilevel approach for SPD problems based on FSAI preconditioning, which eliminates the chance of algorithmic breakdowns independently of the preconditioner sparsity [14] and ii) a novel AMG approach featuring the adaptive FSAI method as a flexible smoother as well as new approaches to adaptively compute the prolongation operator. In this latter work, a new technique to build the prolongation is also presented.},
  timestamp = {2019.01.01},
}

@InProceedings{Sun2018,
  author    = {X. Sun and K. Wei and L. Lai and S. Tsai and C. Wu},
  title     = {Optimizing Sparse Matrix-Vector Multiplication on {GPUs} via Index Compression},
  booktitle = {Proceedings of the 3rd IEEE Advanced Information Technology, Electronic and Automation Control Conference},
  year      = {2018},
  series    = {IAEAC},
  month     = {10},
  pages     = {598--602},
  doi       = {10.1109/IAEAC.2018.8577693},
  abstract  = {Sparse matrix-vector multiplication (SpMV) as one of the most significant scientific kernels has been widely used in many scientific disciplines. In practical applications, large-scale spare matrices are usually used for calculation. During these years, Graphic Processing Unit (GPU) has become a powerful platform for high-performance computing, and optimizing$S$pMV on GPU based systems for efficient performance is the principal interest in many researches. In this paper, we proposed a new method to optimize SpMV on GPUs via index compression. Our index compression method can reduce the index value of the access space. The memory space for recording each column index is significantly reduced from two bytes to one byte, which outperforms the previous work on access performance. The main contributions we make are as follows: (1) Only one byte for each column index is required, which can significantly reduce the working set of the column index and further improve the cache hit ration. (2) Our method can be applied to any kind of matrices, while the previous work can only apply to subset of the matrices. Computational experiments on problems according to the previous work reveal that the best performance improvement ration for ours is up to about 1.5.},
  issn      = {2381-0947},
  keywords  = {Indexes;Sparse matrices;Graphics processing units;Kernel;Bandwidth;Optimization;Memory management;Sparse Matrix-Vector Multiplication;GPU;CSR;CUDA},
}

@Online{Booth2018,
  author      = {Booth, Joshua Dennis and Bolet, Gregory},
  title       = {Javelin: A Scalable Implementation for Sparse Incomplete {LU} Factorization},
  year        = {2018},
  date        = {2018-12-13},
  month       = Dec,
  abstract    = {In this work, we present a new scalable incomplete LU factorization framework called Javelin to be used as a preconditioner for solving sparse linear systems with iterative methods. Javelin allows for improved parallel factorization on shared-memory many-core systems, while packaging the coefficient matrix into a format that allows for high performance sparse matrix-vector multiplication and sparse triangular solves with minimal overheads. The framework achieves these goals by using a collection of traditional permutations, point-to-point thread synchronizations, tasking, and segmented prefix scans in a conventional compressed sparse row format. Using these changes, traditional fill-in and drop tolerance methods can be used, while still being able to have observed speedups of up to ~42$\times$ on 68 Intel Knights Landing cores and ~12$\times$ on 14 Intel Haswell cores.},
  eprint      = {1812.06160v1},
  eprintclass = {cs.MS},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1812.06160v1:PDF},
}

@Article{Xu2019,
  author     = {Xu, Zhen and Chen, Xuhao and Shen, Jie and Zhang, Yang and Chen, Cheng and Yang, Canqun},
  title      = {{GARDENIA}: A Graph Processing Benchmark Suite for Next-Generation Accelerators},
  journal    = {ACM Journal on Emerging Technologies in Computing Systems},
  year       = {2019},
  volume     = {15},
  number     = {1},
  month      = jan,
  pages      = {9:1--9:13},
  issn       = {1550-4832},
  doi        = {10.1145/3283450},
  abstract   = {This article presents the Graph Algorithm Repository for Designing Next-generation Accelerators (GARDENIA), a benchmark suite for studying irregular graph algorithms on massively parallel accelerators. Applications with limited control and data irregularity are the main focus of existing generic benchmarks for accelerators, while available graph processing benchmarks do not apply state-of-the-art algorithms and/or optimization techniques. GARDENIA includes emerging graph processing workloads from graph analytics, sparse linear algebra, and machine-learning domains, which mimic massively multithreaded commercial programs running on modern large-scale datacenters. Our characterization shows that GARDENIA exhibits irregular microarchitectural behavior, which is quite different from structured workloads and straightforward-implemented graph benchmarks.},
  acmid      = {3283450},
  address    = {New York, NY, USA},
  articleno  = {9},
  issue_date = {January 2019},
  keywords   = {Benchmark suite, graph processing, irregular workloads, massive multithreading},
  numpages   = {13},
  publisher  = {ACM},
}

@InProceedings{Loncaric2018,
  author    = {Loncaric, Calvin and Ernst, Michael D. and Torlak, Emina},
  title     = {Generalized Data Structure Synthesis},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  year      = {2018},
  series    = {ICSE'18},
  publisher = {ACM},
  location  = {Gothenburg, Sweden},
  isbn      = {978-1-4503-5638-1},
  pages     = {958--968},
  doi       = {10.1145/3180155.3180211},
  url       = {http://doi.acm.org/10.1145/3180155.3180211},
  abstract  = {Data structure synthesis is the task of generating data structure implementations from high-level specifications. Recent work in this area has shown potential to save programmer time and reduce the risk of defects. Existing techniques focus on data structures for manipulating subsets of a single collection, but real-world programs often track multiple related collections and aggregate properties such as sums, counts, minimums, and maximums.\\This paper shows how to synthesize data structures that track subsets and aggregations of multiple related collections. Our technique decomposes the synthesis task into alternating steps of query synthesis and incrementalization. The query synthesis step implements pure operations over the data structure state by leveraging existing enumerative synthesis techniques, specialized to the data structures domain. The incrementalization step implements imperative state modifications by re-framing them as fresh queries that determine what to change, coupled with a small amount of code to apply the change. As an added benefit of this approach over previous work, the synthesized data structure is optimized for not only the queries in the specification but also the required update operations. We have evaluated our approach in four large case studies, demonstrating that these extensions are broadly applicable.},
  acmid     = {3180211},
  address   = {New York, NY, USA},
  keywords  = {automatic programming, data structures, program synthesis},
  numpages  = {11},
}

@InProceedings{Idreos2019,
  author    = {Idreos, Stratos and Dayan, Niv and Qin, Wilson and Akmanalp, Mali and Hilgard, Sophie and Ross, Andrew and Lennon, James and Jain, Varun and Gupta, Harshita and Li, David and Zhu, Zichen},
  title     = {Design Continuums and the Path Toward Self-Designing Key-Value Stores that Know and Learn},
  booktitle = {Biennial Conference on Innovative Data Systems Research},
  year      = {2019},
  abstract  = {We introduce the concept of design continuums for the data layout of key-value stores. A design continuum unifies major distinct data structure designs under the same model. The critical insight and potential long-term impact is that such unifying models 1)~render what we consider up to now as fundamentally different data structures to be seen as views'' of the very same overall design space, and 2)~allow seeing'' new data structure designs with performance properties that are not feasible by existing designs. The core intuition behind the construction of design continuums is that all data structures arise from the very same set of fundamental design principles, i.e., a small set of data layout design concepts out of which we can synthesize any design that exists in the literature as well as new ones. We show how to construct, evaluate, and expand, design continuums and we also present the first continuum that unifies major data structure designs, i.e., B+Tree, BeTree, LSM-tree, and LSH-Table.\\The practical benefit of a design continuum is that it creates a fast inference engine for the design of data structures. For example, we can near instantly predict how a specific design change in the underlying storage of a data system would affect performance, or reversely what would be the optimal data structure (from a given set of designs) given workload characteristics and a memory budget. In turn, these properties allow us to envision a new class of self-designing key-value stores with a substantially improved ability to adapt to workload and hardware changes by transitioning between drastically different data structure designs to assume a diverse set of performance properties at will. },
}

@Report{Duff2019,
  author      = {Iain Duff, Jonathan Hogg and Florent Lopez},
  title       = {A new sparse symmetric indefinite solver using A Posteriori Threshold Pivoting},
  type        = {Technical Report},
  institution = {Science \& Technology Facilities Council, UK},
  year        = {2019},
  number      = {RAL-TR-2018-008},
  abstract    = {The factorization of sparse symmetric indefinite systems is particularly challenging since pivoting is required to maintain stability of the factorization. Pivoting techniques generally offer limited parallelism and are associated with significant data movement hindering the scalability of these methods. Variants of the Threshold Partial Pivoting (TPP) algorithm for example have been often used because of its numerical robustness but standard implementations exhibit poor parallel performance. On the other hand, some methods trade stability for performance on parallel architectures such as the Supernode Bunch-Kaufman (SBK) used in the PARDISO solver. In this case, however, the factors obtained might not be used to accurately compute the solution of the system. For this reason we have designed a task-based $LDL^T$ factorization algorithm based on a new pivoting strategy called A Posteriori Threshold Pivoting (APTP) that is much more suitable for modern multicore architectures and has the same numerical robustness as the TPP strategy. We implemented our algorithm in a new version of the SPRAL Sparse Symmetric Indefinite Direct Solver (SSIDS) which initially supported GPU-only factorization. We have used OpenMP 4 task features to implement a multifrontal algorithm with dense factorizations using the novel APTP, and we show that it performs favourably compared to the state-of-the-art solvers HSL_MA86, HSL_MA97 and PARDISO both in terms of performance on a multicore machine and in terms of numerical robustness. Finally we show that this new solver is able to make use of GPU devices for accelerating the factorization on heterogeneous architectures.},
}

@Article{Rais2019,
  author   = {Helmi M.D. Rais and Saad Adnan Abed and Junzo Watada},
  title    = {Computational Comparison of Major Proposed Methods for Graph Partitioning Problem},
  journal  = {Journal of Advanced Computational Intelligence and Intelligent Informatics},
  year     = {2019},
  volume   = {23},
  number   = {1},
  pages    = {5-17},
  doi      = {10.20965/jaciii.2019.p0005},
  abstract = {$k$-way graph partitioning is an NP-complete problem, which is applied to various tasks such as route planning, image segmentation, community detection, and high-performance computing. The approximate methods constitute a useful solution for these types of problems. Thus, many research studies have focused on developing meta-heuristic algorithms to tackle the graph partitioning problem. Local search is one of the earliest methods that has been applied efficiently to this type of problem. Recent studies have explored various types of local search methods and have improved them such that they can be used with the partitioning process. Moreover, local search methods are widely integrated with population-based approaches, to provide the best diversification and intensification for the problem space. This study emphasizes the local search approaches, as well as their combination with other graph partitioning approaches. At present, none of the surveys in the literature has focused on this class of state of the art approaches in much detail. In this study, the vital parts of these approaches including neighborhood structure, acceptance criterion, and the ways of combining them with other approaches, are highlighted. Additionally, we provide an experimental comparison that shows the variance in the performance of the reviewed methods. Hence, this study clarifies these methods to show their advantages and limitations for the targeted problem, and thus can aid in the direction of research flow towards the area of graph partitioning.},
}

@InProceedings{Muro2019,
  author    = {Muro, Ryo and Fujii, Akihiro and Tanaka, Teruo},
  title     = {Acceleration of Symmetric Sparse Matrix-Vector Product Using Improved Hierarchical Diagonal Blocking Format},
  booktitle = {Proceedings of the International Conference on High Performance Computing in Asia-Pacific Region},
  year      = {2019},
  series    = {HPC Asia 2019},
  publisher = {ACM},
  location  = {Guangzhou, China},
  isbn      = {978-1-4503-6632-8},
  pages     = {63--70},
  doi       = {10.1145/3293320.3293332},
  abstract  = {In the previous study, Guy et al. proposed sparse matrix-vector product (SpMV) acceleration using the Hierarchical Diagonal Blocking (HDB) format that recursively repeated partitioning, reordering, and blocking on symmetric sparse matrix. The HDB format stores sparse matrix hierarchically using tree structure. Each node of tree structure of HDB format store small sparse matrices using CSR format.\\
In this present study, we examined two problems with the HDB format and provided a solution for each problem.\\
First, SpMV using the HDB format has a partial dependent relationship among hierarchies. The problem with the HDB format is that the parallelism of computation decreases as the hierarchy of nodes gets closer to the root. Thus, we propose cutting of dependency using work vectors to solve this problem.\\
Second, each node of the conventional HDB format is stored in Compressed Sparse Row (CSR) format. Block compressed Sparse Row (BSR) format often becomes faster than CSR format in SpMV performance. Thus, we evaluated the effectiveness of our proposed method with work vectors also for BSR-HDB format.\\
In addition, we compare the performance in the general format (CSR format, BSR format) using the Intel Math Kernel Library (MKL), the conventional HDB format, and the expanded HDB format by using 22 types of sparse matrix that from various field. The results showed that the SpMV performance was highest in the HDB format that we expanded in 19 types of sparse matrix, which was 1.99 times faster than the CSR format.},
  acmid     = {3293332},
  address   = {New York, NY, USA},
  keywords  = {Sparse Matrix Storage Format, Sparse Matrix-Vector Product, Task Parallelism},
  numpages  = {8},
}

@Article{Demirci2019,
  author   = {Demirci, Gunduz Vehbi and Aykanat, Cevdet},
  title    = {Scaling sparse matrix-matrix multiplication in the accumulo database},
  journal  = {Distributed and Parallel Databases},
  year     = {2019},
  month    = {1},
  issn     = {1573-7578},
  doi      = {10.1007/s10619-019-07257-y},
  abstract = {We propose and implement a sparse matrix-matrix multiplication (SpGEMM) algorithm running on top of Accumulo's iterator framework which enables high performance distributed parallelism. The proposed algorithm provides write-locality while ingesting the output matrix back to database via utilizing row-by-row parallel SpGEMM. The proposed solution also alleviates scanning of input matrices multiple times by making use of Accumulo's batch scanning capability which is used for accessing multiple ranges of key-value pairs in parallel. Even though the use of batch-scanning introduces some latency overheads, these overheads are alleviated by the proposed solution and by using node-level parallelism structures. We also propose a matrix partitioning scheme which reduces the total communication volume and provides a balance of workload among servers. The results of extensive experiments performed on both real-world and synthetic sparse matrices show that the proposed algorithm scales significantly better than the outer-product parallel SpGEMM algorithm available in the Graphulo library. By applying the proposed matrix partitioning, the performance of the proposed algorithm is further improved considerably.},
  day      = {28},
}

@TechReport{Hoemmen2019,
  author      = {Hoemmen, Mark and Badwaik, Jayesh and Brucher, Matthieu and Iliopoulos, Athanasios (Nasos) and Michopoulos, John},
  title       = {Historical lessons for C++ linear algebra library standardization},
  institution = {ISO C++ standards meeting (Kona)},
  year        = {2019},
  type        = {techreport},
  number      = {P1417R0},
  url         = {http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2019/p1417r0.pdf},
  timestamp   = {2019.02.05},
}

@InProceedings{Hong2019,
  author    = {Hong, Changwan and Sukumaran-Rajam, Aravind and Nisa, Israt and Singh, Kunal and Sadayappan, P.},
  title     = {Adaptive Sparse Tiling for Sparse Matrix Multiplication},
  booktitle = {Proceedings of the 24th Symposium on Principles and Practice of Parallel Programming},
  year      = {2019},
  series    = {PPoPP '19},
  publisher = {ACM},
  location  = {Washington, District of Columbia},
  isbn      = {978-1-4503-6225-2},
  pages     = {300--314},
  doi       = {10.1145/3293883.3295712},
  abstract  = {Tiling is a key technique for data locality optimization and is widely used in high-performance implementations of dense matrix-matrix multiplication for multicore/manycore CPUs and GPUs. However, the irregular and matrix-dependent data access pattern of sparse matrix multiplication makes it challenging to use tiling to enhance data reuse. In this paper, we devise an adaptive tiling strategy and apply it to enhance the performance of two primitives: SpMM (product of sparse matrix and dense matrix) and SDDMM (sampled dense-dense matrix multiplication). In contrast to studies that have resorted to non-standard sparse-matrix representations to enhance performance, we use the standard Compressed Sparse Row (CSR) representation, within which intra-row reordering is performed to enable adaptive tiling. Experimental evaluation using an extensive set of matrices from the Sparse Suite collection demonstrates significant performance improvement over currently available state-of-the-art alternatives.},
  acmid     = {3295712},
  address   = {New York, NY, USA},
  keywords  = {GPU, SDDMM, SpMM, multicore/manycore, sampled dense-dense matrix multiplication, sparse matrix-matrix multiplication, tiling},
  numpages  = {15},
}

@InProceedings{Winter2019,
  author    = {Winter, Martin and Mlakar, Daniel and Zayer, Rhaleb and Seidel, Hans-Peter and Steinberger, Markus},
  title     = {Adaptive Sparse Matrix-matrix Multiplication on the GPU},
  booktitle = {Proceedings of the 24th Symposium on Principles and Practice of Parallel Programming},
  year      = {2019},
  series    = {PPoPP '19},
  publisher = {ACM},
  location  = {Washington, District of Columbia},
  isbn      = {978-1-4503-6225-2},
  pages     = {68--81},
  doi       = {10.1145/3293883.3295701},
  abstract  = {In the ongoing efforts targeting the vectorization of linear algebra primitives, sparse matrix-matrix multiplication (SpGEMM) has received considerably less attention than sparse Matrix-Vector multiplication (SpMV). While both are equally important, this disparity can be attributed mainly to the additional formidable challenges raised by SpGEMM.\\ In this paper, we present a dynamic approach for addressing SpGEMM on the GPU. Our approach works directly on the standard compressed sparse rows (CSR) data format. In comparison to previous SpGEMM implementations, our approach guarantees a homogeneous, load-balanced access pattern to the first input matrix and improves memory access to the second input matrix. It adaptively re-purposes GPU threads during execution and maximizes the time efficient on-chip scratchpad memory can be used. Adhering to a completely deterministic scheduling pattern guarantees bit-stable results during repetitive execution, a property missing from other approaches. Evaluation on an extensive sparse matrix benchmark suggests our approach being the fastest SpGEMM implementation for highly sparse matrices (80\% of the set). When bit-stable results are sought, our approach is the fastest across the entire test set.},
  acmid     = {3295701},
  address   = {New York, NY, USA},
  keywords  = {ESC, GPU, SpGEMM, adaptive, bit-stable, sparse matrix},
  numpages  = {14},
}

@InProceedings{Meng2019,
  author    = {Meng, Ke and Li, Jiajia and Tan, Guangming and Sun, Ninghui},
  title     = {A Pattern Based Algorithmic Autotuner for Graph Processing on GPUs},
  booktitle = {Proceedings of the 24th Symposium on Principles and Practice of Parallel Programming},
  year      = {2019},
  series    = {PPoPP '19},
  publisher = {ACM},
  location  = {Washington, District of Columbia},
  isbn      = {978-1-4503-6225-2},
  pages     = {201--213},
  doi       = {10.1145/3293883.3295716},
  abstract  = {This paper proposes Gswitch, a pattern-based algorithmic auto-tuning system that dynamically switches between optimization variants with negligible overhead. Its novelty lies in a small set of algorithmic patterns that allow for the configurable assembly of variants of the algorithm. The fast transition of Gswitch is based on a machine learning model trained using 644 real graphs. Moreover, Gswitch provides a simple programming interface that conceals low-level tuning details from the user. We evaluate Gswitch on typical graph algorithms (BFS, CC, PR, SSSP, and BC) using Nvidia Kepler and Pascal GPUs. The results show that Gswitch runs up to 10$times$ faster than the best configuration of the state-of-the-art programmable GPU-based graph processing libraries on 10 representative graphs. Gswitch outperforms Gunrock on 92.4\% cases of 644 graphs which is the largest dataset evaluation reported to date.},
  acmid     = {3295716},
  address   = {New York, NY, USA},
  keywords  = {GPU, auto-tuning, graph processing},
  numpages  = {13},
}

@Article{Reguly2019,
  author   = {Reguly, I. Z. and Mudalige, G. R. and Giles, M. B. and Maheswaran, S.},
  title    = {Improving resilience of scientific software through a domain-specific approach},
  journal  = {Journal of Parallel and Distributed Computing},
  year     = {2019},
  issn     = {0743-7315},
  doi      = {10.1016/j.jpdc.2019.01.015},
  url      = {http://www.sciencedirect.com/science/article/pii/S0743731519300917},
  abstract = {In this paper we present research on improving the resilience of the execution of scientific software, an increasingly important concern in High Performance Computing (HPC). We build on an existing high-level abstraction framework, the Oxford Parallel library for Structured meshes (OPS), developed for the solution of multi-block structured mesh-based applications, and implement an algorithm in the library to carry out checkpointing automatically, without the intervention of the user. The target applications are a hydrodynamics benchmark application from the Mantevo Suite, CloverLeaf 3D, the sparse linear solver proxy application TeaLeaf, and the OpenSBLI compressible Navier–Stokes direct numerical simulation (DNS) solver. We present (1) the basic algorithm that OPS relies on to determine the optimal checkpoint in terms of size and location, (2) improvements that supply additional information to improve the decision, (3) techniques that reduce the cost of writing the checkpoints to non-volatile storage, (4) a performance analysis of the developed techniques on a single workstation and on several supercomputers, including ORNL’s Titan. Our results demonstrate the utility of the high-level abstractions approach in automating the checkpointing process and show that performance is comparable to, or better than the reference in all cases.},
  keywords = {Domain specific language, High performance computing, Checkpointing, Resilience, Parallel I/O},
}

@Article{Zheng2019,
  author   = {Hua Zheng and Seakweng Vong and Ling Liu},
  title    = {A direct preconditioned modulus-based iteration method for solving nonlinear complementarity problems of H-matrices},
  journal  = {Applied Mathematics and Computation},
  year     = {2019},
  volume   = {353},
  pages    = {396--405},
  issn     = {0096-3003},
  doi      = {10.1016/j.amc.2019.02.015},
  url      = {http://www.sciencedirect.com/science/article/pii/S0096300319301134},
  abstract = {In this paper, we establish a direct preconditioned modulus-based iteration method for solving a class of nonlinear complementarity problems with the system matrix being an H-matrix. The convergence theorems of the proposed method are given, which generalize and improve the existing ones. Numerical examples show that the proposed method is efficient.},
  keywords = {Nonlinear complementarity problem, Modulus-based matrix splitting iteration method, Precondition},
}

@Article{Aliaga2019,
  author   = {José I. Aliaga and Ernesto Dufrechou and Pablo Ezzatti and Enrique S. Quintana-Ortí},
  title    = {Accelerating the task/data-parallel version of ILUPACK’s BiCG in multi-CPU/GPU configurations},
  journal  = {Parallel Computing},
  year     = {2019},
  issn     = {0167-8191},
  doi      = {10.1016/j.parco.2019.02.005},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167819118301777},
  abstract = {ILUPACK is a valuable tool for the solution of sparse linear systems via iterative Krylov subspace-based methods. Its relevance for the solution of real problems has motivated several efforts to enhance its performance on parallel machines. In this work we focus on exploiting the task-level parallelism derived from the structure of the BiCG method, in addition to the data-level parallelism of the internal matrix computations, with the goal of boosting the performance of a GPU (graphics processing unit) implementation of this solver. First, we revisit the use of dual-GPU systems to execute independent stages of the BiCG concurrently on both accelerators, while leveraging the extra memory space to improve the data access patterns. In addition, we extend our ideas to compute the BiCG method efficiently in multicore platforms with a single GPU. In this line, we study the possibilities offered by hybrid CPU-GPU computations, as well as a novel synchronization-free sparse triangular linear solver. The experimental results with the new solvers show important acceleration factors with respect to the previous data-parallel CPU and GPU versions.},
  keywords = {Sparse linear systems, Iterative Krylov-subspace methods, Data parallelism, ILUPACK preconditioner, Graphics processing units (GPUs)},
}

@Article{Gould2019,
  author   = {Nicholas I. M. Gould, Tyrone Rees and Jennifer A. Scott},
  title    = {Convergence and evaluation-complexity analysis of a regularized tensor-Newton method for solving nonlinear least-squares problems},
  journal  = {Computational Optimization and Applications},
  doi      = {10.1007/s10589-019-00064-2},
  abstract = {Given a twice-continuously differentiable vector-valued function $r(x)$, a local minimizer of $\Vert r(x) \Vert_2$ is sought. We propose and analyse tensor-Newton methods, in which $r(x)$ is replaced locally by its second-order Taylor approximation. Convergence is controlled by regularization of various orders. We establish global convergence to a first-order critical point of $\Vert r(x) \Vert_2$, and provide function evaluation bounds that agree with the best-known bounds for methods using second derivatives. Numerical experiments comparing tensor-Newton methods with regularized Gauss–Newton and Newton methods demonstrate the practical performance of the newly proposed method.},
}

@InProceedings{Flegar2017,
  author    = {Flegar, Goran and Anzt, Hartwig},
  title     = {Overcoming Load Imbalance for Irregular Sparse Matrices},
  booktitle = {Proceedings of the Seventh Workshop on Irregular Applications: Architectures and Algorithms},
  year      = {2017},
  series    = {IA3 2017},
  month     = {11},
  pages     = {1-8},
  doi       = {10.1145/3149704.3149767},
  abstract  = {In this paper we propose a load-balanced GPU kernel for computing the sparse matrix vector (SpMV) product. Making heavy use of the latest GPU programming features, we also enable satisfying performance for irregular and unbalanced matrices. In a performance comparison using 400 test matrices we reveal the new kernel being superior to the most popular SpMV implementations.},
  timestamp = {2019.03.07},
}

@Article{Lagraviere2019,
  author    = {Jèrèmie Lagravière and Johannes Langguth and Martina Prugger and Lukas Einkemmer and Phuong Hoai Ha and Xing Cai},
  title     = {Performance Optimization and Modeling of Fine-Grained Irregular Communication in {UPC}},
  journal   = {Scientific Programming},
  year      = {2019},
  volume    = {2019},
  doi       = {10.1155/2019/6825728},
  abstract  = {.e Unified Parallel C (UPC) programming language offers parallelism via logically partitioned shared memory, which typically spans physically disjoint memory subsystems. One convenient feature of UPC is its ability to automatically execute betweenthread data movement, such that the entire content of a shared data array appears to be freely accessible by all the threads. .e programmer friendliness, however, can come at the cost of substantial performance penalties. .is is especially true when indirectly indexing the elements of a shared array, for which the induced between-thread data communication can be irregular and have a fine-grained pattern. In this paper, we study performance enhancement strategies specifically targeting such finegrained irregular communication in UPC. Starting from explicit thread privatization, continuing with block-wise communication, and arriving at message condensing and consolidation, we obtained considerable performance improvement of UPC programs that originally require fine-grained irregular communication. Besides the performance enhancement strategies, the main contribution of the present paper is to propose performance models for the different scenarios, in the form of quantifiable formulas that hinge on the actual volumes of various data movements plus a small number of easily obtainable hardware characteristic parameters. .ese performance models help to verify the enhancements obtained, while also providing insightful predictions of similar parallel implementations, not limited to UPC, that also involve between-thread or between-process irregular communication. As a further validation, we also apply our performance modeling methodology and hardware characteristic parameters to an existing UPC code for solving a 2D heat equation on a uniform mesh.},
  timestamp = {2019.03.10},
}

@Article{Demmel2014,
  author   = {Demmel, James and Diep Nguyen, Hong},
  title    = {Parallel Reproducible Summation},
  journal  = {IEEE Transactions on Computers},
  year     = {2014},
  volume   = {64},
  month    = {01},
  pages    = {1--1},
  doi      = {10.1109/TC.2014.2345391},
  abstract = {Reproducibility, i.e. getting bitwise identical floating point results from multiple runs of the same program, is a property that many users depend on either for debugging or correctness checking in many codes [10]. However, the combination of dynamic scheduling of parallel computing resources, and floating point nonassociativity, makes attaining reproducibility a challenge even for simple reduction operations like computing the sum of a vector of numbers in parallel. We propose a technique for floating point summation that is reproducible independent of the order of summation. Our technique uses Rump’s algorithm for error-free vector transformation [7], and is much more efficient than using (possibly very) high precision arithmetic. Our algorithm reproducibly computes highly accurate results with an absolute error bound of $n cdot 2^{-28} \cdot macheps \cdot max _i |v_i|$ at a cost of $7n$ FLOPs and a small constant amount of extra memory usage. Higher accuracies are also possible by increasing the number of error-free transformations. As long as all operations are performed in to-nearest rounding mode, results computed by the proposed algorithms are reproducible for any run on any platform. In particular, our algorithm requires the minimum number of reductions, i.e. one reduction of an array of six double precision floating point numbers per sum, and hence is well suited for massively parallel environments.},
}

@Article{Villa2009,
  author   = {Villa, Oreste and Chavarría-Miranda, Daniel and Gurumoorthi, Vidhya and Marquez, Andres and Krishamoorthy, Sriram},
  title    = {Effects of Floating-Point non-Associativity on Numerical Computations on Massively Multithreaded Systems},
  journal  = {Cray User Group},
  year     = {2009},
  month    = {12},
  abstract = {Floating-point operations, as defined in the IEEE-754 standard, are not associative. The ordering of large numbers of operations (such as summa-tions) that deal with operands of substantially dif-ferent magnitudes can significantly affect the final result. On massively multi-threaded systems, the non-deterministic nature of how machine floating-point operations are interleaved, combined with the fact that intermediate values have to be rounded or truncated to fit in the available precision leads to non-deterministic numerical error propagation. We have investigated on a Cray XMT system the effect of non-deterministic error propagation by observing the convergence rate of a conjugate gradient calcula-tion used as part of a Power State Estimation (PSE) application. As a possible mitigation strategy, we have explored quadruple precision accumulation, as well as a deterministic parallel tree scheme. The tree based approach has consistently outperformed the quadruple precision approach due to an improved convergence rate. As a consequence, we motivate the need for compile time mechanisms that enable enforcement of parallel deterministic operations on the Cray XMT.},
}

@TechReport{Harvey2019,
  author      = {David Harvey and Joris van der Hoeven},
  title       = {Integer multiplication in time $O(n log n)$},
  institution = {HAL archives},
  year        = {2019},
  number      = {hal-02070778},
  url         = {https://hal.archives-ouvertes.fr/hal-02070778},
  abstract    = {We present an algorithm that computes the product of two $n$-bitintegers in $O(n log n)$ bit operations.},
}

@Article{Scott2019,
  author    = {Scott, J. and Tuma, M.},
  title     = {Sparse stretching for solving sparse-dense linear least-squares problems},
  journal   = {SIAM Journal on Scientific Computing},
  year      = {2019},
  issn      = {1095-7197},
  abstract  = {Large-scale linear least-squares problems arise in a wide range of practical applications. In some cases, the system matrix contains a small number of dense rows. These make the problem significantly harder to solve because their presence limits the direct applicability of sparse matrix techniques. In particular, the normal matrix is (close to) dense,
 so that forming it is impractical. One way to help overcome the dense row problem is to employ matrix stretching.
 Stretching is a sparse matrix technique that improves sparsity by making the least-squares problem larger.
 We show that standard stretching can still result in the normal matrix for the stretched problem having an unacceptably large amount of fill. This motivates us to propose a new sparse stretching strategy that performs the stretching so as to limit the fill in the normal matrix and its Cholesky factor. Numerical examples from real problems
 are used to illustrate the potential gains.},
  timestamp = {2019.03.31},
}

@InProceedings{Blass2019,
  author    = {Blaß, Thorsten and Philippsen, Michael},
  title     = {Which Graph Representation to Select for Static Graph-Algorithms on a CUDA-capable GPU},
  booktitle = {Proceedings of the 12th Workshop on General Purpose Processing Using GPUs},
  year      = {2019},
  series    = {GPGPU '19},
  publisher = {ACM},
  location  = {Providence, RI, USA},
  isbn      = {978-1-4503-6255-9},
  pages     = {22--31},
  doi       = {10.1145/3300053.3319416},
  url       = {http://doi.acm.org/10.1145/3300053.3319416},
  abstract  = {GPUs seem to be ideal for algorithms that work in parallel. A number of ways to represent graphs in GPU memory are known. But so far there are no guidelines to select the representation that is likely to result in the best performance.\\
This a comprehensive study investigates for CUDA-capable GPUs how different graph representations influence the performance of highly optimized graph processing algorithms that traverse the graphs without modifying them. We evaluate three different graph exchange formats and how efficiently they can be imported into eight graph data structures. We use ten state-of-the-art benchmarks that employ different traversals pattern. We evaluate them on 19 input graphs with different characteristics. The measurements show that there is not a single best data structure; the runtime performance can vary up to a factor of 2 between two representations.\\
The main contribution is a set of rules that helps in picking the best-performing graph representation for a given situation.},
  acmid     = {3319416},
  address   = {New York, NY, USA},
  keywords  = {CUDA, graph data structure, static graph algorithms},
  numpages  = {10},
}

@InProceedings{Nisa2019,
  author    = {Nisa, Israt and Li, Jiajia and Sukumaran-Rajam, Aravind and Vuduc, Richard and Sadayappan, P.},
  title     = {Load-Balanced Sparse MTTKRP on GPUs},
  booktitle = {Proceedings of the 2019 International Parallel and Distributed Processing Symposium},
  year      = {2019},
  series    = {IPDPS'19},
  abstract  = {Sparse matricized tensor times Khatri-Rao product (MTTKRP) is one of the most computationally expensive kernels in sparse tensor computations. This work focuses on optimizing the MTTKRP operation on GPUs, addressing both performance and storage requirements. We begin by identifying the performance bottlenecks in directly extending the state-ofthe-art CSF (compressed sparse fiber) format from CPUs to GPUs. A significant challenge with GPUs compared to multicore CPUs is that of utilizing the much greater degree of parallelism in a load-balanced fashion for irregular computations like sparse MTTKRP. To address this issue, we develop a new storage-efficient representation for tensors that enables highperformance, load-balanced execution of MTTKRP on GPUs. A GPU implementation of sparse MTTKRP using the new sparse tensor representation is shown to outperform all currently known parallel sparse CPU and GPU MTTKRP implementations.},
  timestamp = {2019.04.14},
}

@Online{Kawaguchi2019,
  author       = {{Kawaguchi}, Kenji and {Pack Kaelbling}, Leslie},
  title        = {Every Local Minimum is a Global Minimum of an Induced Model},
  year         = {2019},
  month        = {4},
  abstract     = {For non-convex optimization in machine learning, this paper proves that every local minimum achieves the global optimality of the perturbable gradient basis model at any differentiable point. As a result, non-convex machine learning is theoretically as supported as convex machine learning with a hand-crafted basis in terms of the loss at differentiable local minima, except in the case when a preference is given to the hand-crafted basis over the perturbable gradient basis. The proofs of these results are derived under mild assumptions. Accordingly, the proven results are directly applicable to many machine learning models, including practical deep neural networks, without any modification of practical methods. Furthermore, as special cases of our general results, this paper improves or complements several state-of-the-art theoretical results in the literature with a simple and unified proof technique.},
  eprint       = {arXiv:1904.03673},
  eprinttype   = {arXiv},
  keywords     = {Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
  primaryclass = {stat.ML},
}

@Online{Barratt2019,
  author     = {Shane Barratt and Stephen Boyd},
  title      = {Least Squares Auto-Tuning},
  year       = {2019},
  abstract   = {Least squares is by far the simplest and most commonly applied computational method in many fields. In almost all applications, the least squares objective is rarely the true objective. We account for this discrepancy by parametrizing the least squares problem and automatically adjusting these parameters using an optimization algorithm. We apply our method, which we call least squares auto-tuning, to data fitting.},
  eprint     = {arXiv:1904.05460},
  eprinttype = {arXiv},
}

@Article{Li2019,
  author   = {Li, Yishui and Xie, Peizhen and Chen, Xinhai and Liu, Jie and Yang, Bo and Li, Shengguo and Gong, Chunye and Gan, Xinbiao and Xu, Han},
  title    = {VBSF: a new storage format for SIMD sparse matrix--vector multiplication on modern processors},
  journal  = {The Journal of Supercomputing},
  year     = {2019},
  month    = {Apr},
  issn     = {1573-0484},
  doi      = {10.1007/s11227-019-02835-4},
  url      = {https://doi.org/10.1007/s11227-019-02835-4},
  abstract = {Sparse matrix--vector multiplication (SpMV) is one of the most indispensable kernels of solving problems in numerous applications, but its performance of SpMV is limited by the need for frequent memory access. Modern processors exploit data-level parallelism to improve the performance using single-instruction multiple data (SIMD). In order to take full advantage of SIMD acceleration technology, a new storage format called Variable Blocked-$\sigma$-SIMD Format (VBSF) is proposed in this paper to change the irregular nature of traditional matrix storage formats. This format combines the adjacent nonzero elements into variable size blocks to ensure that SpMV can be computed with SIMD vector units. We compare the VBSF-based SpMV with traditional storage formats using 15 matrices as a benchmark suite on three computing platforms (FT2000, Intel Xeon E5 and Intel Silver) with different SIMD length. For the matrices in the benchmark suite, the VBSF obtains great performance improvement on three platforms, respectively, and it proves to have better storage efficiency compared with other storage formats.},
  day      = {10},
}

@Article{Solomonik2016,
  author     = {Solomonik, Edgar and Carson, Erin and Knight, Nicholas and Demmel, James},
  title      = {Trade-Offs Between Synchronization, Communication, and Computation in Parallel Linear Algebra Computations},
  journal    = {ACM Transaction on Parallel Computing},
  year       = {2016},
  volume     = {3},
  number     = {1},
  month      = jan,
  pages      = {3:1--3:47},
  issn       = {2329-4949},
  doi        = {10.1145/2897188},
  url        = {http://doi.acm.org/10.1145/2897188},
  abstract   = {This article derives trade-offs between three basic costs of a parallel algorithm: synchronization, data movement, and computational cost. These trade-offs are lower bounds on the execution time of the algorithm that are independent of the number of processors but dependent on the problem size. Therefore, they provide lower bounds on the execution time of any parallel schedule of an algorithm computed by a system composed of any number of homogeneous processors, each with associated computational, communication, and synchronization costs. We employ a theoretical model that measures the amount of work and data movement as a maximum over that incurred along any execution path during the parallel computation. By considering this metric rather than the total communication volume over the whole machine, we obtain new insights into the characteristics of parallel schedules for algorithms with nontrivial dependency structures. We also present reductions from BSP and LogGP algorithms to our execution model, extending our lower bounds to these two models of parallel computation. We first develop our results for general dependency graphs and hypergraphs based on their expansion properties, and then we apply the theorem to a number of specific algorithms in numerical linear algebra, namely triangular substitution, Cholesky factorization, and stencil computations. We represent some of these algorithms as families of dependency graphs. We derive their communication lower bounds by studying the communication requirements of the hypergraph structures shared by these dependency graphs. In addition to these lower bounds, we introduce a new communication-efficient parallelization for stencil computation algorithms, which is motivated by results of our lower bound analysis and the properties of previously existing parallelizations of the algorithms.},
  acmid      = {2897188},
  address    = {New York, NY, USA},
  articleno  = {3},
  issue_date = {June 2016},
  keywords   = {Communication lower bounds, graph expansion, numerical linear algebra, stencil computations},
  numpages   = {47},
  publisher  = {ACM},
}

@Online{Huckle2019,
  author    = {Thomas K. Huckle},
  title     = {Accelerated Jacobi iterations for bidiagonal and sparse triangular matrices},
  year      = {2019},
  url       = {https://www5.in.tum.de/persons/huckle/it_triang.pdf},
  abstract  = {In many applications a sparse linear system of equations $Ax = b$ has to be solved. For applying iterative solvers like preconditioned conjugate gradient (pcg) or GMRES, effective preconditioners are necessary, e.g. Jacobi, Gauss-Seidel, or incomplete LU factorization (ILU). Often, effective preconditioners are given via sparse triangular matrices $L$, that have to be solved in every iteration step. Recent work by Edmond Chow introduced an easy to parallelize fixed-point iteration for computing approximations to (I)LU factorizations. Therefore, the aching handicap in parallel solution methods for sparse matrices is the solving of sparse triangular systems, e.g. bidiagonal matrices. In a parallel environment direct solvers can take only restricted advantage of parallelism. Therefore, in this paper we develop a fast iterative solution method for sparse triangular matrices. In contrast to direct solvers for triangular matrices $L$ like graph-based methods, sparse factorization methods, or Sherman-Morrison-Woodbury, here we want to consider stationary Jacobi iterations. In its original form the Jacobi iteration for ill-conditioned matrices can lead to very slow convergence. Therefore, we introduce different acceleration tools like preconditioning (block Jacobi and Incomplete Sparse Approximate Inverse ISAI), and a recursive acceleration of the Jacobi method. Here the Neumann series is replaced by the Euler expansion (see [4, 19, 8]). This is derived by a recursive computation of the Neumann series using powers of the initial Jacobi iteration matrix. The goal is to shift the major part of the operations from cheap but numerous iteration steps to better parallelizable cheap and sparse matrix-matrix products reducing the number of necessary iterations considerably, e.g. to less than $\log_2(n)$ for an $n \times n$ matrix.},
  timestamp = {2019.04.28},
}

@InProceedings{Nie2019,
  author    = {Q. Nie and S. Malik},
  title     = {{SpFlow}: Memory-Driven Data Flow Optimization for Sparse Matrix-Matrix Multiplication},
  booktitle = {Proceedings of the IEEE International Symposium on Circuits and Systems},
  year      = {2019},
  series    = {ISCAS'19},
  month     = may,
  pages     = {1--5},
  doi       = {10.1109/ISCAS.2019.8702111},
  abstract  = {To improve the performance of sparse matrix-matrix multiplication (SpMM) running on a specialized architecture, orchestrating a data flow that maximizes data reuse in local memory is critical but challenging due to the irregular non-zero element locations and the wide range of sparsity. In this work, we proposed SpFlow, a memory-driven data flow optimization framework for SpMM. SpFlow can realize 54X fewer DRAM accesses and 97X fewer SRAM accesses on average than a GPU running the cuSPARSE kernel. And in comparison with a state-of-the-art accelerator, the performance can be improved by 3X, and SRAM accesses reduced by 5X on average.},
  issn      = {2158-1525},
  keywords  = {Random access memory;Sparse matrices;Graphics processing units;Indexes;Optimization;Memory management},
}

@Article{Lei2019,
  author   = {D. Lei and M. Du and H. Chen and Z. Li and Y. Wu},
  title    = {Distributed Parallel Sparse Multinomial Logistic Regression},
  journal  = {IEEE Access},
  year     = {2019},
  volume   = {7},
  pages    = {55496--55508},
  issn     = {2169-3536},
  doi      = {10.1109/ACCESS.2019.2913280},
  abstract = {Sparse Multinomial Logistic Regression (SMLR) is widely used in the field of image classification, multi-class object recognition, and so on, because it has the function of embedding feature selection during classification. However, it cannot meet the time and memory requirements for processing large-scale data. We have reinvestigated the classification accuracy and running efficiency of the algorithm for solving SMLR problems using the Alternating Direction Method of Multipliers (ADMM), which is called fast SMLR (FSMLR) algorithm in this paper. By reformulating the optimization problem of FSMLR, we transform the serial convex optimization problem to the distributed convex optimization problem, i.e., global consensus problem and sharing problem. Based on the distributed optimization problem, we propose two distribute parallel SMLR algorithms, sample partitioning-based distributed SMLR (SP-SMLR), and feature partitioning-based distributed SMLR (FP-SMLR), for a large-scale sample and large-scale feature datasets in big data scenario, respectively. The experimental results show that the FSMLR algorithm has higher accuracy than the original SMLR algorithm. The big data experiments show that our distributed parallel SMLR algorithms can scale for massive samples and large-scale features, with high precision. In a word, our proposed serial and distribute SMLR algorithms outperform the state-of-the-art algorithms.},
  keywords = {Logistics;Convex functions;Optimization;Distributed databases;Partitioning algorithms;Machine learning algorithms;Task analysis;Alternating Direction Method of Multipliers;big data;distributed parallel;sparse multinomial logistic regression},
}

@InProceedings{Balaji2019,
  author    = {Vignesh Balaji and Brandon Lucia},
  title     = {Combining Data Duplication and Graph Reordering to Accelerate Parallel Graph Processing},
  booktitle = {Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing},
  year      = {2019},
  location  = {Phoenix, AX, USA},
  month     = {6},
  abstract  = {Performance of single-machine, shared memory graph processing is affected by expensive atomic updates and poor cache locality. Data duplication, a popular approach to eliminate atomic updates by creating thread-local copies of shared data, incurs extreme memory overheads due to the large sizes of typical input graphs. Even memory-efficient duplication strategies that exploit the power-law structure common to many graphs (by duplicating only the highly-connected "hub" vertices) suffer from overheads for having to dynamically identify the hub vertices. Degree Sorting, a popular graph reordering technique that re-assigns hub vertices consecutive IDs in a bid to improve spatial locality, is effective for single-threaded graph applications but suffers from increased false sharing in parallel executions. \\
The main insight of this work is that the combination of data duplication and Degree Sorting eliminates the overheads of each optimization. Degree Sorting improves the efficiency of data duplication by assigning hub vertices consecutive IDs which enables easy identification of the hub vertices. Additionally, duplicating the hub vertex data eliminates false sharing in Degree Sorting since each thread updates its local copy of the hub vertex data. We evaluate this mutually-enabling combination of power-law-specific data duplication and Degree Sorting in a system called RADAR. RADAR improves performance by eliminating atomic updates for hub vertices and improving the cache locality of graph applications, providing speedups of up to 166x (1.88x on average) across different graph applications and input graphs.},
  timestamp = {2019.05.09},
}

@Article{Anzt2019,
  author   = {Hartwig Anzt and Goran Flegar and Thomas Grützmacher and Enrique S Quintana-Ortí},
  title    = {Toward a modular precision ecosystem for high-performance computing},
  journal  = {The International Journal of High Performance Computing Applications},
  year     = {2019},
  doi      = {10.1177/1094342019846547},
  abstract = {With the memory bandwidth of current computer architectures being significantly slower than the (floating point) arithmetic performance, many scientific computations only leverage a fraction of the computational power in today’s high-performance architectures. At the same time, memory operations are the primary energy consumer of modern architectures, heavily impacting the resource cost of large-scale applications and the battery life of mobile devices. This article tackles this mismatch between floating point arithmetic throughput and memory bandwidth by advocating a disruptive paradigm change with respect to how data are stored and processed in scientific applications. Concretely, the goal is to radically decouple the data storage format from the processing format and, ultimately, design a “modular precision ecosystem” that allows for more flexibility in terms of customized data access. For memory-bounded scientific applications, dynamically adapting the memory precision to the numerical requirements allows for attractive resource savings. In this article, we demonstrate the potential of employing a modular precision ecosystem for the block-Jacobi preconditioner and the PageRank algorithm -- two applications that are popular in the communities and at the same characteristic representatives for the field of numerical linear algebra and data analytics, respectively.},
}

@Article{Bernaschi2019,
  author   = {Bernaschi, M. and Carrozzo, M. and Franceschini, A. and Janna, C.},
  title    = {A Dynamic Pattern Factored Sparse Approximate Inverse Preconditioner on Graphics Processing Units},
  journal  = {SIAM Journal on Scientific Computing},
  year     = {2019},
  volume   = {41},
  number   = {3},
  pages    = {C139--C160},
  doi      = {10.1137/18M1197461},
  abstract = {One of the most time-consuming tasks in the procedures for the numerical study of PDEs is the solution to linear systems of equations. To that purpose, iterative solvers are viewed as a promising alternative to direct methods on high-performance computers since, in theory, they are almost perfectly parallelizable. Their main drawback is the need of finding a suitable preconditioner to accelerate convergence. The factorized sparse approximate inverse (FSAI), mainly in its adaptive form, has proven to be an effective parallel preconditioner for several problems. In the present work, we report about two novel ideas to dynamically compute, on graphics processing units (GPUs), the FSAI sparsity pattern, which is the main task in its setup. The first approach, borrowed from the CPU implementation, uses a global array as a nonzero indicator, whereas the second one relies on a merge-sort procedure of multiple arrays. We will show that the second approach requires significantly less memory and overcomes issues related to the limited global memory available on GPUs. Numerical tests prove that the GPU implementation of FSAI allows for an average speed-up of 7.5 over a parallel CPU implementation. Moreover, we will show that the preconditioner computation is still feasible using single precision arithmetic with a further 20\% reduction of the setup cost. Finally, the strong scalability of the overall approach in shown in a multi-GPU setting.},
}

@Article{Ernst2019,
  author     = {Dominik Ernst, Georg Hager, Jonas Thies and Wellein, Gerhard},
  title      = {Performance Engineering for a Tall \& Skinny Matrix Multiplication Kernel on GPUs},
  year       = {2019},
  eprint     = {arXiv:1905.03136},
  eprinttype = {arXiv},
  abstract   = {General matrix-matrix multiplications (GEMM) in vendor-supplied BLAS libraries are best optimized for square matrices but often show bad performance for tall and skinny matrices, which are much taller than wide. Nvidia’s current CUBLAS implementation delivers only a fraction of the potential performance (as given by the roofline model) in this case. We describe the challenges and key properties of an implementation that can achieve perfect performance. We further evaluate different approaches of parallelization and thread distribution, and devise a flexible, configurable mapping scheme. A code generation approach enables a simultaneously flexible and specialized implementation with autotuning. This results in perfect performance for a large range of matrix sizes in the domain of interest, and at least 2/3 of maximum performance for the rest on an Nvidia Volta GPGPU.},
}

@Article{Hassan2019,
  author   = {Abdullahi Hassan, Ambra and Cardellini, Valeria and D’Ambra, Pasqua and di Serafino, Daniela and Filippone, Salvatore},
  title    = {Efficient Algebraic Multigrid Preconditioners on Clusters of {GPUs}},
  journal  = {Parallel Processing Letters},
  year     = {2019},
  volume   = {29},
  number   = {01},
  pages    = {1950001},
  doi      = {10.1142/S0129626419500014},
  abstract = {Many scientific applications require the solution of large and sparse linear systems of equations using Krylov subspace methods; in this case, the choice of an effective preconditioner may be crucial for the convergence of the Krylov solver. Algebraic MultiGrid (AMG) methods are widely used as preconditioners, because of their optimal computational cost and their algorithmic scalability. The wide availability of GPUs, now found in many of the fastest supercomputers, poses the problem of implementing efficiently these methods on high-throughput processors. In this work we focus on the application phase of AMG preconditioners, and in particular on the choice and implementation of smoothers and coarsest-level solvers capable of exploiting the computational power of clusters of GPUs. We consider block-Jacobi smoothers using sparse approximate inverses in the solve phase associated with the local blocks. The choice of approximate inverses instead of sparse matrix factorizations is driven by the large amount of parallelism exposed by the matrix-vector product as compared to the solution of large triangular systems on GPUs. The selected smoothers and solvers are implemented within the AMG preconditioning framework provided by the MLD2P4 library, using suitable sparse matrix data structures from the PSBLAS library. Their behaviour is illustrated in terms of execution speed and scalability, on a test case concerning groundwater modelling, provided by the Jülich Supercomputing Center within the Horizon 2020 Project EoCoE.},
}

@InProceedings{Cools2019,
  author     = {Siegfried Cools and Jeffrey Cornelis and Pieter Ghysels and Wim Vanroose},
  title      = {Improving strong scaling of the Conjugate Gradient method for solving large linear systems using global reduction pipelining},
  booktitle  = {Proceedings of the 2019 EuroMPI conference},
  year       = {2019},
  series     = {EuroMPI'19},
  eprint     = {arXiv:1905.06850},
  eprinttype = {arXiv},
  abstract   = {This paper presents performance results comparing MPI-based implementations of the popular Conjugate Gradient (CG) method and several of its communication hiding (or “pipelined”) variants. Pipelined CG methods are designed to efficiently solve SPD linear systems on massively parallel distributed memory hardware, and typically display significantly improved strong scaling compared to classic CG. This increase in parallel performance is achieved by overlapping the global reduction phase (MPI_Iallreduce) required to compute the inner products in each iteration by (chiefly local) computational work such as the matrix-vector product as well as other global communication. This work includes a brief introduction to the deep pipelined CG method for readers that may be unfamiliar with the specifics of the method. A brief overview of implementation details provides the practical tools required for implementation of the algorithm. Subsequently, easily reproducible strong scaling results on the US Department of Energy (DoE) NERSC machine “Cori” (Phase I – Haswell nodes) on up to 1024 nodes with 16 MPI ranks per node are presented using an implementation of $p(l)$-CG that is available in the open source PETSc library. Observations on the staggering and overlap of the asynchronous, non-blocking global communication phases with communication and computational kernels are drawn from the experiments.},
}

@Article{Kong2019a,
  author     = {Fande Kong},
  title      = {Parallel memory-efficient all-at-once algorithms for the sparse matrix triple products in multigrid methods},
  journal    = {The International Journal of High Performance Computing Applications},
  year       = {2019},
  eprint     = {arXiv:1905.08423},
  eprinttype = {arXiv},
  annotation = {Multilevel/multigrid methods is one of the most popular approaches for solving a large sparse linear system of equations, typically, arising from the discretization of partial differential equations. One critical step in the multilevel/multigrid methods is to form coarse matrices through a sequence of sparse matrix triple products. A commonly used approach for the triple products explicitly involves two steps, and during each step a sparse matrix-matrix multiplication is employed. This approach works well for many applications with a good computational efficiency, but it has a high memory overhead since some auxiliary matrices need to be temporarily stored for accomplishing the calculations. In this work, we propose two new algorithms that construct a coarse matrix with taking one pass through the input matrices without involving any auxiliary matrices for saving memory. The new approaches are referred to as “all-atonce” and “merged all-at-once” (a modified version of “all-at-once”) since the new algorithms calculate the two sparse matrix-matrix multiplications simultaneously, and the traditional method is denoted as “two-step”. The all-at-once and the merged all-at-once algorithms are implemented based on hash tables in PETSc as part of this work with a careful consideration on the performance in terms of the compute time and the memory usage. In the new methods, the first sparse matrix-matrix multiplication is implemented using a row-wise algorithm, and the second one is based on an outer product. We numerically show that the proposed algorithms and their implementations are perfectly scalable in both the compute time and the memory usage with up to 32,768 processor cores for a model problem with 27 billions of unknowns. The scalability is also demonstrated for a realistic neutron transport problem with over 2 billion unknowns on a supercomputer with 10,000 processor cores. Compared with the traditional two-step method, the all-at-once and the merged all-at-once algorithms consume much less memory for both the model problem and the realistic neutron transport problem meanwhile they are able to maintain the computational efficiency.},
  timestamp  = {2019.05.26},
}

@InBook{Yamamoto2019,
  author    = {Yamamoto, Yusaku},
  title     = {High-Performance Algorithms for Numerical Linear Algebra},
  booktitle = {The Art of High Performance Computing for Computational Science, Vol. 1: Techniques of Speedup and Parallelization for General Purposes},
  year      = {2019},
  editor    = {Geshi, Masaaki},
  publisher = {Springer Singapore},
  isbn      = {9789811361944},
  pages     = {113--136},
  doi       = {10.1007/978-981-13-6194-4_7},
  abstract  = {Matrix computations lie at the heart of many scientific computations. While sophisticated algorithms have been established for various numerical linear algebra problems such as the solution of linear simultaneous equationsLinear simultaneous equation and eigenvalue problemsEigenvalue problem, they require considerable modification with the advent of exaFLOPS- scale supercomputers, which are expected to have a huge number of computing cores, deep memory hierarchyMemory hierarchy, and increased probability of hardware errors. In this chapter, we discuss projected hardware characteristics of exaFLOPS machines and summarize the challenges to be faced by numerical linear algebra algorithms in the near future. Based on these preparations, we present a brief survey of recent research efforts in the field of numerical linear algebra targeted at meeting these challenges.},
  address   = {Singapore},
}

@InBook{Mendoza2019,
  author    = {Mendoza, Hector and Klein, Aaron and Feurer, Matthias and Springenberg, Jost Tobias and Urban, Matthias and Burkart, Michael and Dippel, Maximilian and Lindauer, Marius and Hutter, Frank},
  title     = {Towards Automatically-Tuned Deep Neural Networks},
  booktitle = {Automated Machine Learning: Methods, Systems, Challenges},
  year      = {2019},
  editor    = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  publisher = {Springer International Publishing},
  isbn      = {978-3-030-05318-5},
  pages     = {135--149},
  doi       = {10.1007/978-3-030-05318-5_7},
  abstract  = {Recent advances in AutoML have led to automated tools that can compete with machine learning experts on supervised learning tasks. In this work, we present two versions of Auto-Net, which provide automatically-tuned deep neural networks without any human intervention. The first version, Auto-Net 1.0, builds upon ideas from the competition-winning system Auto-sklearn by using the Bayesian Optimization method SMAC and uses Lasagne as the underlying deep learning (DL) library. The more recent Auto-Net 2.0 builds upon a recent combination of Bayesian Optimization and HyperBand, called BOHB, and uses PyTorch as DL library. To the best of our knowledge, Auto-Net 1.0 was the first automatically-tuned neural network to win competition datasets against human experts (as part of the first AutoML challenge). Further empirical results show that ensembling Auto-Net 1.0 with Auto-sklearn can perform better than either approach alone, and that Auto-Net 2.0 can perform better yet.},
  address   = {Cham},
}

@Article{Jagode2019,
  author   = {Jagode, Heike and Danalis, Anthony and Anzt, Hartwig and Dongarra, Jack},
  title    = {PAPI software-defined events for in-depth performance analysis},
  journal  = {The International Journal of High Performance Computing Applications},
  year     = {2019},
  doi      = {10.1177/1094342019846287},
  abstract = {The methodology and standardization layer provided by the Performance Application Programming Interface (PAPI) has played a vital role in application profiling for almost two decades. It has enabled sophisticated performance analysis tool designers and performance-conscious scientists to gain insights into their applications by simply instrumenting their code using a handful of PAPI functions that “just work” across different hardware components. In the past, PAPI development had focused primarily on hardware-specific performance metrics. However, the rapidly increasing complexity of software infrastructure poses new measurement and analysis challenges for the developers of large-scale applications. In particular, acquiring information regarding the behavior of libraries and runtimes—used by scientific applications—requires low-level binary instrumentation, or APIs specific to each library and runtime. No uniform API for monitoring events that originate from inside the software stack has emerged. In this article, we present our efforts to extend PAPI’s role so that it becomes the de facto standard for exposing performance-critical events, which we refer to as software-defined events (SDEs), from different software layers. Upgrading PAPI with SDEs enables monitoring of both types of performance events—hardware- and software-related events—in a uniform way, through the same consistent PAPI. The goal of this article is threefold. First, we motivate the need for SDEs and describe our design decisions regarding the functionality we offer through PAPI’s new SDE interface. Second, we illustrate how SDEs can be utilized by different software packages, specifically, by showcasing their use in the numerical linear algebra library MAGMA-Sparse, the tensor algebra library TAMM that is part of the NWChem suite, and the compiler-based performance analysis tool Byfl. Third, we provide a performance analysis of the overhead that results from monitoring SDEs and discuss the trade-offs between overhead and functionality.},
}

@InProceedings{Zhang2019,
  author    = {Zhang, Kai and Liu, Jun and Zhang, Jie and Wang, Jun},
  title     = {Greedy Orthogonal Pivoting Algorithm for Non-negative Matrix Factorization},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  year      = {2019},
  series    = {PMLR'19},
  url       = {http://proceedings.mlr.press/v97/zhang19r/zhang19r.pdf},
  abstract  = {Non-negative matrix factorization is a powerful tool for learning useful representations in the data and has been widely applied in many problems such as data mining and signal processing. Orthogonal NMF, which can further improve the locality of decomposition, has drawn considerable interest in clustering problems. However, imposing simultaneous non-negative and orthogonal structure can be difficult, and so existing algorithms can only solve it approximately. To address this challenge, we propose an innovative procedure called Greedy Orthogonal Pivoting Algorithm (GOPA). The GOPA method fully exploits the sparsity of non-negative orthogonal solutions to break the global problem into a series of local optimizations, in which an adaptive subset of coordinates are updated in a greedy, closed-form manner. The biggest advantage of GOPA is that it promotes exact orthogonality and provides solid empirical evidence that stronger orthogonality does contribute favorably to better clustering performance. On the other hand, we have designed randomized and batch-mode version of GOPA, which can further reduce the computational cost and improve accuracy, making it suitable for large data.},
}

@Article{Yuan2019,
  author     = {Ganzhao Yuan, Li Shen, Wei-Shi Zheng},
  title      = {A Block Decomposition Algorithm for Sparse Optimization},
  year       = {2019},
  eprint     = {arXiv:1905.11031},
  eprinttype = {arXiv},
  abstract   = {Sparse optimization is a central problem in machine learning and computer vision. However, this problem is inherently NP-hard and thus difficult to solve in general. Combinatorial search methods find the global optimal solution but are confined to small-sized problems, while coordinate descent methods are efficient but often suffer from poor local minima. This paper considers a new block decomposition algorithm that combines the effectiveness of combinatorial search methods and the efficiency of coordinate descent methods. Specifically, we consider a random strategy or/and a greedy strategy to select a subset of coordinates as the working set, and then perform a global combinatorial search over the working set based on the original objective function. We show that our method finds stronger stationary points than Amir Beck et al.’s coordinate-wise optimization method. In addition, we establish the global convergence and convergence rate of our block decomposition algorithm. Our experiments on solving sparse regularized and sparsity constrained least squares optimization problems demonstrate that our method achieves state-ofthe-art performance in terms of accuracy.},
  timestamp  = {2019.06.02},
}

@Article{Yu2019,
  author   = {Ting Yu and Mengchi Liu},
  title    = {A Memory Efficient Clique Enumeration Method for Sparse Graphs with a Parallel Implementation},
  journal  = {Parallel Computing},
  year     = {2019},
  issn     = {0167-8191},
  doi      = {https://doi.org/10.1016/j.parco.2019.05.005},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167819118301297},
  abstract = {Maximal clique enumeration (MCE) is a widely studied problem that plays a crucial role in structure mining of undirected graphs. The increasing scale of real-world graphs has brought the challenges of high memory cost and high CPU workload to the problem. In this paper, we propose a memory efficient method named CMC-bit for MCE on sparse graphs. It reduces the memory cost via minimizing the candidate cliques and representing them by the data structure bitset. It generates an appropriate order for the vertex set according to two optimized principles to reduce the CPU cost. We further design a partition-based CMC-bit algorithm with a one-side extending strategy to solve the memory-limited problem. We parallelize the CMC-bit algorithm based on MapReduce with a range-based partition strategy to make an optimal trade-off between the shuffling workload of graph decomposition and load balance in the Reduce phase. We conduct extensive experiments on 30 real-world datasets. The results demonstrate that both the CMC-bit algorithm and its parallel implementation significantly outperform the respective state-of-the-art algorithms in speed. We also show that the parallel CMC-bit algorithm achieves good performance on the scalability with respect to both the reducer number and the CPU number.},
  keywords = {Maximal clique enumeration, Graph algorithms, MapReduce, Parallel graph algorithms},
}

@Article{Das2019,
  author     = {Das, Swapnil and Demmel, James and Fountoulakis, Kimon and Grigori, Laura and Mahoney, Michael. W.},
  title      = {Parallel and Communication Avoiding Least Angle Regression},
  year       = {2019},
  eprint     = {arXiv:1905.11340},
  eprinttype = {arXiv},
  abstract   = {We are interested in parallelizing the Least Angle Regression (LARS) algorithm for fitting linear regression models to high-dimensional data. We consider two parallel and communication avoiding versions of the basic LARS algorithm. The two algorithms apply to data that have different layout patterns (one is appropriate for row-partitioned data, and the other is appropriate for column-partitioned data), and they have different asymptotic costs and practical performance. The first is bLARS, a block version of LARS algorithm, where we update b columns at each iteration. Assuming that the data are row-partitioned, bLARS reduces the number of arithmetic operations, latency, and bandwidth by a factor of b. The second is Tournament-bLARS (T-bLARS), a tournament version of LARS, in which case processors compete, by running several LARS computations in parallel, to choose b new columns to be added into the solution. Assuming that the data are column-partitioned, T-bLARS reduces latency by a factor of b. Similarly to LARS, our proposed methods generate a sequence of linear models. We present extensive numerical experiments that illustrate speed-ups up to 25$\times$ compared to LARS.},
  timestamp  = {2019.06.02},
}

@InProceedings{Fuchs2019,
  author    = {Adi Fuchs and David Wentzlaff},
  title     = {The Accelerator Wall: Limits of Chip Specialization},
  booktitle = {Proceedings of the 25th IEEE International Symposium on High-Performance Computer Architecture},
  year      = {2019},
  series    = {HPCA'18},
  abstract  = {Specializing chips using hardware accelerators has become the prime means to alleviate the gap between the growing computational demands and the stagnating transistor budgets caused by the slowdown of CMOS scaling. Much of the benefits of chip specialization stems from optimizing a computational problem within a given chip’s transistor budget. Unfortunately, the stagnation of the number of transistors available on a chip will limit the accelerator design optimization space, leading to diminishing specialization returns, ultimately hitting an accelerator wall.\\ In this work, we tackle the question of what are the limits of future accelerators and chip specialization? We do this by characterizing how current accelerators depend on CMOS scaling, based on a physical modeling tool that we constructed using datasheets of thousands of chips. We identify key concepts used in chip specialization, and explore case studies to understand how specialization has progressed over time in different applications and chip platforms (e.g., GPUs, FPGAs, ASICs). Utilizing these insights, we build a model which projects forward to see what future gains can and cannot be enabled from chip specialization. A quantitative analysis of specialization returns and technological boundaries is critical to help researchers understand the limits of accelerators and develop methods to surmount them.},
  timestamp = {2019.06.02},
}

@Article{Liu2019,
  author   = {Hui Liu and Ye Tian and Hongming Zong and Qingping Ma and Michael Yu Wang and Liang Zhang},
  title    = {Fully parallel level set method for large-scale structural topology optimization},
  journal  = {Computers \& Structures},
  year     = {2019},
  volume   = {221},
  pages    = {13--27},
  issn     = {0045-7949},
  doi      = {10.1016/j.compstruc.2019.05.010},
  url      = {http://www.sciencedirect.com/science/article/pii/S0045794918316511},
  abstract = {To realize large-scale or high-resolution structural topology optimization design, a fully parallel parameterized level set method with compactly supported radial basis functions (CSRBFs) is developed based on both the uniform and non-uniform structured meshes. In this work, the whole computation process is parallelized, including mesh generation, sensitivity analysis, calculation and assembly of the element stiffness matrices, solving of the structural state equation, parameterization and updating of the level set function, and output of the computational results during the optimization iterations. In addition, some typical numerical examples, in which the calculation scale is up to 7 million 8-node hexahedral elements, are carried out for verifying the effectiveness of the proposed method. Finally, the computing time is also analyzed in detail. It is found that: (1) In the optimized structures, the thin sheet-like components gradually replace the truss-like ones when refining the mesh, (2) the parameterization process of the level set function will become fast as long as the non-uniformity of mesh is not very high and the supported radius of CSRBF is small enough, and (3) more than 80\% of the total computing time is always consumed for solving the structural state equation during the finite element analysis (FEA).},
  keywords = {Parallel computing, Level set method, Large-scale structural topology optimization, Uniform and non-uniform structured meshes, Compactly supported radial basis function},
}

@Article{Wu2019,
  author   = {Rongteng Wu},
  title    = {Dynamic Scheduling Strategy for Block Parallel Cholesky Factorization Based on Activity on Edge Network},
  journal  = {{IEEE} Access},
  year     = {2019},
  volume   = {7},
  pages    = {66317--66324},
  issn     = {2169-3536},
  doi      = {10.1109/ACCESS.2019.2917714},
  abstract = {The efficient development of system software and design applications in parallel architecture is a notable challenge considering various aspects, such as load balancing, memory spaces, communication, and synchronization. This paper presents a block parallel Cholesky factorization algorithm for a multicore system, which is developed based on activity on edge network. First, the basic block computing tasks and their dependencies are taken as vertices and edges, respectively, and a directed acyclic graph corresponding to the specific block parallel Cholesky factorization is generated. Next, each edge of the directed acyclic graph is assigned to a weight equal to the processing time of the initial vertex of the edge, and the directed acyclic graph becomes an activity on edge network with only one starting and one ending vertex. Finally, a queuing algorithm is designed for the basic block computing tasks according to the edge activity on edge network, and a dynamic scheduling strategy is developed for block parallel Cholesky factorization. The results of the experiments concerning the parallel execution time of the algorithm in multicore systems with different configurations demonstrate that the proposed algorithm has notable advantages compared with the traditional static scheduling algorithm, and it exhibits satisfactory load balancing, parallelism, and scalability capacities.},
  keywords = {Task analysis;Load management;Multicore processing;Program processors;Heuristic algorithms;Linear algebra;Dynamic scheduling;Cholesky factorization;dense linear algebra;dynamic schedule strategy;load balancing;multicore computing},
}

@InProceedings{Jun2018,
  author    = {S. {Jun} and A. {Wright} and S. {Zhang} and S. {Xu} and {Arvind}},
  title     = {GraFBoost: Using Accelerated Flash Storage for External Graph Analytics},
  booktitle = {ACM/IEEE 45th Annual International Symposium on Computer Architecture},
  year      = {2018},
  month     = {6},
  pages     = {411--424},
  doi       = {10.1109/ISCA.2018.00042},
  abstract  = {We describe GraFBoost, a flash-based architecture with hardware acceleration for external analytics of multi-terabyte graphs. We compare the performance of GraFBoost with 1 GB of DRAM against various state-of-the-art graph analytics software including FlashGraph, running on a 32-thread Xeon server with 128 GB of DRAM. We demonstrate that despite the relatively small amount of DRAM, GraFBoost achieves high performance with very large graphs no other system can handle, and rivals the performance of the fastest software platforms on sizes of graphs that existing platforms can handle. Unlike in-memory and semi-external systems, GraFBoost uses a constant amount of memory for all problems, and its performance decreases very slowly as graph sizes increase, allowing GraFBoost to scale to much larger problems than possible with existing systems while using much less resources on a single-node system. The key component of GraFBoost is the sort-reduce accelerator, which implements a novel method to sequentialize fine-grained random accesses to flash storage. The sort-reduce accelerator logs random update requests and then uses hardware-accelerated external sorting with interleaved reduction functions. GraFBoost also stores newly updated vertex values generated in each superstep of the algorithm lazily with the old vertex values to further reduce I/O traffic. We evaluate the performance of GraFBoost for PageRank, breadth-first search and betweenness centrality on our FPGA-based prototype (Xilinx VC707 with 1 GB DRAM and 1 TB flash) and compare it to other graph processing systems including a pure software implementation of GrapFBoost.},
  issn      = {2575-713X},
  keywords  = {DRAM chips;field programmable gate arrays;graph theory;sorting;DRAM;sort-reduce accelerator;graph analytics software;FlashGraph;I-O traffic;PageRank;breadth-first search;betweenness centrality;FPGA;Xilinx VC707;Xeon server;semiexternal systems;multiterabyte graphs;external graph analytics;accelerated flash storage;graph processing systems;GraFBoost;hardware-accelerated external sorting;Random access memory;Hardware;Software;Benchmark testing;Software algorithms;Field programmable gate arrays;Programming;graph analytics;flash storage;FPGA;sort-reduce;hardware acceleration},
}

@TechReport{Muhammad2019,
  author      = {Osama, Muhammad and Truong, Minh and Yang, Carl and Buluç, Aydın and Owens, John D},
  title       = {Graph Coloring on the GPU},
  institution = {UC Davis: College of Engineering},
  year        = {2019},
  url         = {https://escholarship.org/uc/item/6kp4p18t},
  abstract    = {We design and implement parallel graph coloring algorithms on the GPU using two different abstractions—one datacentric (Gunrock), the other linear-algebra-based (GraphBLAS). We analyze the impact of variations of a baseline independent-set algorithm on quality and runtime. We study how optimizations such as hashing, avoiding atomics, and a max-min heuristic affect performance. Our Gunrock graph coloring implementation has a peak 2$\times$ speed-up, a geomean speed-up of 1.3$\times$ and produces 1.6$\times$ more colors over previous hardwired state-of-theart implementations on real-world datasets. Our GraphBLAS implementation of Luby’s algorithm produces 1.9$\times$ fewer colors than the previous state-of-the-art parallel implementation at the cost of 3$\times$ extra runtime, and 1.014$\times$ fewer colors than a greedy, sequential algorithm with a geomean speed-up of 2.6$\times$.},
  timestamp   = {2019.06.09},
}

@InProceedings{Mohammadi2019,
  author    = {Mohammadi, Mahdi Soltan and Yuki, Tomofumi and Cheshmi, Kazem and Davis, Eddie C. and Hall, Mary and Dehnavi, Maryam Mehri and Nandy, Payal and Olschanowsky, Catherine and Venkat, Anand and Strout, Michelle Mills},
  title     = {Sparse Computation Data Dependence Simplification for Efficient Compiler-generated Inspectors},
  booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  year      = {2019},
  series    = {PLDI 2019},
  publisher = {ACM},
  location  = {Phoenix, AZ, USA},
  isbn      = {978-1-4503-6712-7},
  pages     = {594--609},
  doi       = {10.1145/3314221.3314646},
  abstract  = {This paper presents a combined compile-time and runtime loop-carried dependence analysis of sparse matrix codes and evaluates its performance in the context of wavefront parallellism. Sparse computations incorporate indirect memory accesses such as x[col[j]] whose memory locations cannot be determined until runtime. The key contributions of this paper are two compile-time techniques for significantly reducing the overhead of runtime dependence testing: (1) identifying new equality constraints that result in more efficient runtime inspectors, and (2) identifying subset relations between dependence constraints such that one dependence test subsumes another one that is therefore eliminated. New equality constraints discovery is enabled by taking advantage of domain-specific knowledge about index arrays, such as col[j]. These simplifications lead to automatically-generated inspectors that make it practical to parallelize such computations. We analyze our simplification methods for a collection of seven sparse computations. The evaluation shows our methods reduce the complexity of the runtime inspectors significantly. Experimental results for a collection of five large matrices show parallel speedups ranging from 2x to more than 8x running on a 8-core CPU.},
  acmid     = {3314646},
  address   = {New York, NY, USA},
  keywords  = {Presburger arithmetic with uninterpreted functions, SMT solvers, data dependence simplification, dependence analysis, inspector-executor strategies, sparse matrices},
  numpages  = {16},
}

@InProceedings{Augustine2019,
  author    = {Augustine, Travis and Sarma, Janarthanan and Pouchet, Louis-Noël and Rodríguez, Gabriel},
  title     = {Generating Piecewise-regular Code from Irregular Structures},
  booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  year      = {2019},
  series    = {PLDI 2019},
  publisher = {ACM},
  location  = {Phoenix, AZ, USA},
  isbn      = {978-1-4503-6712-7},
  pages     = {625--639},
  doi       = {10.1145/3314221.3314615},
  url       = {http://doi.acm.org/10.1145/3314221.3314615},
  abstract  = {Irregular data structures, as exemplified with sparse matrices, have proved to be essential in modern computing. Numerous sparse formats have been investigated to improve the overall performance of Sparse Matrix-Vector multiply (SpMV). But in this work we propose instead to take a fundamentally different approach: to automatically build sets of regular sub-computations by mining for regular sub-regions in the irregular data structure. Our approach leads to code that is specialized to the sparsity structure of the input matrix, but which does not need anymore any indirection array, thereby improving SIMD vectorizability. We particularly focus on small sparse structures (below 10M nonzeros), and demonstrate substantial performance improvements and compaction capabilities compared to a classical CSR implementation and Intel MKL IE's SpMV implementation, evaluating on 200+ different matrices from the SuiteSparse repository.},
  acmid     = {3314615},
  address   = {New York, NY, USA},
  keywords  = {Polyhedral compilation, SpMV, sparse data structure, trace compression},
  numpages  = {15},
}

@InProceedings{Anzt2019a,
  author    = {Anzt, Hartwig and Chen, Yen-Chen and Cojean, Terry and Dongarra, Jack and Flegar, Goran and Nayak, Pratik and Quintana-Ortí, Enrique S. and Tsai, Yuhsiang M. and Wang, Weichung},
  title     = {Towards Continuous Benchmarking: An Automated Performance Evaluation Framework for High Performance Software},
  booktitle = {Proceedings of the Platform for Advanced Scientific Computing Conference},
  year      = {2019},
  series    = {PASC '19},
  publisher = {ACM},
  location  = {Zurich, Switzerland},
  isbn      = {978-1-4503-6770-7},
  pages     = {1--11},
  doi       = {10.1145/3324989.3325719},
  abstract  = {We present an automated performance evaluation framework that enables an automated workflow for testing and performance evaluation of software libraries. Integrating this component into an ecosystem enables sustainable software development, as a community effort, via a web application for interactively evaluating the performance of individual software components. The performance evaluation tool is based exclusively on web technologies, which removes the burden of downloading performance data or installing additional software. We employ this framework for the Ginkgo software ecosystem, but the framework can be used with essentially any software project, including the comparison between different software libraries. The Continuous Integration (CI) framework of Ginkgo is also extended to automatically run a benchmark suite on predetermined HPC systems, store the state of the machine and the environment along with the compiled binaries, and collect results in a publicly accessible performance data repository based on Git. The Ginkgo performance explorer (GPE) can be used to retrieve the performance data from the repository, and visualizes it in a web browser. GPE also implements an interface that allows users to write scripts, archived in a Git repository, to extract particular data, compute particular metrics, and visualize them in many different formats (as specified by the script). The combination of these approaches creates a workflow which enables performance reproducibility and software sustainability of scientific software. In this paper, we present example scripts that extract and visualize performance data for Ginkgo's SpMV kernels that allow users to identify the optimal kernel for specific problem characteristics.},
  acmid     = {3325719},
  address   = {New York, NY, USA},
  articleno = {9},
  keywords  = {automated performance benchmarking, continuous integration, healthy software lifecycle, interactive performance visualization},
  numpages  = {11},
}

@InProceedings{Xie2019,
  author    = {Zhen Xie and Guangmin Tan and Weifeing Liu and Ninghui Sun},
  title     = {{IA-SpGEMM}: An Input-aware Auto-tuning Framework for Parallel Sparse Matrix-Matrix Multiplication},
  booktitle = {Proceedings of the 33rd ACM Conference on Supercomputing},
  year      = {2019},
  series    = {ICS '19},
  location  = {Phoenix, AZ, USA},
  url       = {https://folk.idi.ntnu.no/weifengl/papers/spgemm_xie_ics19.pdf},
  abstract  = {Sparse matrix-matrix multiplication (SpGEMM) is a sparse kernel that is used in a number of scientific applications. Although several SpGEMM algorithms have been proposed, almost all of them are restricted to the compressed sparse row (CSR) format, and the possible performance gain from exploiting other formats has not been well studied. The particular format and algorithm that yield the best performance for SpGEMM also remain undetermined.\\ In this work, we conduct a prospective study on format-specific parallel SpGEMM algorithms, and analyze their pros and cons. We then propose IA-SpGEMM, an input-aware auto-tuning Framework for SpGEMM, that provides a unified programming interface in the CSR format and automatically determines the best format and algorithm for arbitrary sparse matrices. For this purpose, we set-up an algorithm set and design a deep learning model called MatNet that is trained by over 2,700 matrices from the SuiteSparse Matrix Collection to quickly and accurately predict the best solution by using sparse features and density representations. We evaluate our framework on CPUs and a GPU, and the results show that IA-SpGEMM is on average 3.27$\times$ and 13.17$\times$ faster than MKL on an Intel and an AMD platform, respectively, and is 2.23$\times$ faster than cuSPARSE on an NVIDIA GPU.},
  timestamp = {2019.06.16},
}

@InProceedings{Montagne2019,
  author    = {E. {Montagne} and R. {Surós}},
  title     = {Systolic Sparse Matrix Vector Multiply in the Age of TPUs and Accelerators},
  booktitle = {2019 Spring Simulation Conference (SpringSim)},
  year      = {2019},
  month     = {4},
  pages     = {1-10},
  doi       = {10.23919/SpringSim.2019.8732860},
  abstract  = {Tensor Processing Units has brought back systolic arrays as a computational alternative to high performance computing. Recently Google presented a Tensor Processing Unit for handling matrix multiplication using systolic arrays. This unit is designed for dense matrices only. As they stated, sparse architectural support was omitted momentarily but they will focus on sparsity in future designs. We propose a systolic array to compute the Sparse Matrix Vector product in $T2(n)\approx \displaystyle \lceil\frac{nnz}{2}\rceil+2n+2$ using 2 n+2 processing elements. The systolic array we propose also use accumulators to collect the partial results of the resulting vector and supports adapting tiling.},
  keywords  = {Sparse matrices;Arrays;Adders;Artificial neural networks;Indexes;systolic arrays;sparse matrix;spmv product;tensor processing unit(tpu)},
}

@Article{Burkhardt2019,
  author     = {Paul Burkhardt},
  title      = {Optimal algebraic Breadth-First Search for sparse graphs},
  eprint     = {arXiv:1906.03113v1},
  eprinttype = {arXiv},
  abstract   = {There has been a rise in the popularity of algebraic methods for graph algorithms given the development of the GraphBLAS library and other sparse matrix methods. These are useful in practice because many graph algorithms are amenable to sparse matrix multiplication. An exemplar for these approaches is Breadth-First Search (BFS). The algebraic BFS algorithm is simply a recursion of matrix-vector multiplications with the $n \times n$ adjacency matrix. Despite many redundant operations over nonzeros that ultimately lead to suboptimal performance, the algebraic BFS is appealing for practical implementations because it is simple and embarrassingly parallel. By using highly tuned matrix libraries it can be faster in practice than the theoretically optimal combinatorial algorithm. Therefore an optimal algebraic BFS should be of keen interest especially if it is easily integrated with existing matrix methods.\\ Current methods, notably in the GraphBLAS, use a Sparse Matrix Sparse Vector (SpMSpV) multiplication in which the input vector is kept in a sparse representation in each step of the BFS. But simply applying SpMSpV in BFS does not lead to optimal runtime. Each nonzero in the vector must be masked in subsequent steps. This has been an area of recent recent in GraphBLAS and other libraries. While in theory these masking methods are asymptotically optimal on sparse graphs, many add work that leads to suboptimal runtime. We give a new optimal, algebraic BFS for sparse graphs that is also a constant factor faster than theoretically optimal SpMSpV methods. We show how to eliminate redundant operations so an element in the adjacency matrix is operated upon no more than once, thus taking $O(m)$ operations for a graph with $O(m)$ edges.\\ Our method multiplies progressively smaller submatrices of the adjacency matrix at each step. The matrix remains unchanged, rather we are masking the rows and columns in the matrix that corresponds to previously visited vertices. The input vector in each step is also effectively masked so it is a sparse vector. Thus our method multiplies a sparse submatrix by a sparse vector in decreasing size each step. Our sequential algebraic BFS algorithm takes $O(m)$ algebraic operations on a sparse graph as opposed to $O(mn)$ operations of other sparse matrix approaches. Our analysis closes a gap in the literature.},
  timestamp  = {2019.06.16},
}

@Article{Ioannidis2019,
  author     = {E.I. Ioannidis and N. Cheimarios and A.N. Spyropoulos and A.G. Boudouvis},
  title      = {On the performance of various parallel {GMRES} implementations on {CPU} and {GPU} clusters},
  year       = {2019},
  eprint     = {arXiv:1906.04051v1},
  eprinttype = {arXiv},
  annotation = {As the need for computational power and efficiency rises, parallel systems become increasingly popular among various scientific fields. While multiple core-based architectures have been the center of attention for many years, the rapid development of general purposes GPU-based architectures takes high performance computing to the next level. In this work, different implementations of a parallel version of the preconditioned GMRES - an established iterative solver for large and sparse linear equation sets - are presented, each of them on different computing architectures: From distributed and shared memory core-based to GPU-based architectures. The computational experiments emanate from the dicretization of a benchmark boundary value problem with the finite element method. Major advantages and drawbacks of the various implementations are addressed in terms of parallel speedup, execution time and memory issues. Among others, comparison of the results in the different architectures, show the high potentials of GPU-based architectures.},
  timestamp  = {2019.06.16},
}

@Online{Cartis2018a,
  author        = {Coralia Cartis and Nick I. M. Gould and Philippe L. Toint},
  title         = {Sharp worst-case evaluation complexity bounds for arbitrary-order nonconvex optimization with inexpensive constraints},
  year          = {2018},
  __markedentry = {[ap8213:]},
  abstract      = {We provide sharp worst-case evaluation complexity bounds for non convex minimization problems with general inexpensive constraints, i.e. problems where the cost of evaluating/enforcing of the (possibly nonconvex or even disconnected) constraints, if any, is negligible compared to that of evaluating the objective function.  These bounds unify, extend or improve all known upper and lower complexity bounds for unconstrained and convexly-constrained problems. It is shown that, given an accuracy level $\epsilon$, a degree of highest available Lipschitz continuous derivatives $p$ and a desired optimality order $q$ between one and $p$, a conceptual regularization algorithm requires no more than $O(\epsilon^{-\frac{p+1}{p-q+1}}$ evaluations of the objective function and its derivatives to compute a suitably approximate $q$-th order minimizer. With an appropriate choice of the regularization, a similar result also holds if the $p$-th derivative is merely Holder rather than Lipschitz continuous. We provide an example that shows that the above complexity bound is sharp for unconstrained and a wide class of constrained problems; we also give reasons for the optimality of regularization methods from a worst-case complexity point of view, within a large class of algorithms that use the same derivative information.},
  eprint        = {arXiv:1811.01220},
  eprinttype    = {arXiv},
  timestamp     = {2019.06.16},
}

@Article{Sao2019,
  author        = {Piyush Sao and Xiaoye S. Li and Richard Vuduc},
  title         = {A communication-avoiding 3D algorithm for sparse LU factorization on heterogeneous systems},
  journal       = {Journal of Parallel and Distributed Computing},
  year          = {2019},
  issn          = {0743-7315},
  doi           = {10.1016/j.jpdc.2019.03.004},
  url           = {http://www.sciencedirect.com/science/article/pii/S0743731518305197},
  __markedentry = {[ap8213:]},
  abstract      = {We propose a new algorithm to improve the strong scalability of right-looking sparse LU factorization on distributed memory systems. Our 3D algorithm for sparse LU uses a three-dimensional MPI process grid, exploits elimination tree parallelism, and trades off increased memory for reduced per-process communication. We also analyze the asymptotic improvements for planar graphs (e.g., those arising from 2D grid or mesh discretizations) and certain non-planar graphs (specifically for 3D grids and meshes). For a planar graph with n vertices, our algorithm reduces communication volume asymptotically in n by a factor of Ologn and latency by a factor of Ologn. For non-planar cases, our algorithm can reduce the per-process communication volume by 3$\times$ and latency by On13 times. In all cases, the memory needed to achieve these gains is a constant factor. We implemented our algorithm by extending the 2D data structure used in SuperLU_DIST. Our new 3D code achieves empirical speedups up to 27$\times$ for planar graphs and up to 3.3$\times$ for non-planar graphs over the baseline 2D SuperLU_DIST when run on 24,000 cores of a Cray XC30. We extend the 3D algorithm for heterogeneous architectures by adding the Highly Asynchronous Lazy Offload (Halo) algorithm for co-processor offload [44]. On 4096 nodes of a Cray XK7 with 32,768 CPU cores and 4096 Nvidia K20x GPUs, the 3D algorithm achieves empirical speedups up to 24$\times$ for planar graphs and 3.5$\times$ for non-planar graphs over the baseline 2D SuperLU_DIST with co-processor acceleration.},
  timestamp     = {2019.06.16},
}

@Article{Elgohary2019,
  author        = {Elgohary, Ahmed and Boehm, Matthias and Haas, Peter J. and Reiss, Frederick R. and Reinwald, Berthold},
  title         = {Compressed Linear Algebra for Declarative Large-scale Machine Learning},
  journal       = {Communications of the ACM},
  year          = {2019},
  volume        = {62},
  number        = {5},
  month         = {4},
  pages         = {83--91},
  issn          = {0001-0782},
  doi           = {10.1145/3318221},
  url           = {http://doi.acm.org/10.1145/3318221},
  __markedentry = {[ap8213:]},
  abstract      = {Large-scale Machine Learning (ML) algorithms are often iterative, using repeated read-only data access and I/O-bound matrix-vector multiplications. Hence, it is crucial for performance to fit the data into single-node or distributed main memory to enable fast matrix-vector operations. General-purpose compression struggles to achieve both good compression ratios and fast decompression for block-wise uncompressed operations. Therefore, we introduce Compressed Linear Algebra (CLA) for lossless matrix compression. CLA encodes matrices with lightweight, value-based compression techniques and executes linear algebra operations directly on the compressed representations. We contribute effective column compression schemes, cache-conscious operations, and an efficient sampling-based compression algorithm. Our experiments show good compression ratios and operations performance close to the uncompressed case, which enables fitting larger datasets into available memory. We thereby obtain significant end-to-end performance improvements.},
  acmid         = {3318221},
  address       = {New York, NY, USA},
  issue_date    = {May 2019},
  numpages      = {9},
  publisher     = {ACM},
  timestamp     = {2019.06.16},
}

@TechReport{Chen2016a,
  author        = {Zhangxin Chen and Hui Liu and Bo Yang},
  title         = {Parallel Triangular Solvers on {GPU}},
  institution   = {The Computing Research Repository},
  date          = {2016},
  url           = {http://arxiv.org/abs/1606.00541},
  __markedentry = {[ap8213:6]},
  abstract      = {In this paper, we investigate GPU based parallel triangular solvers systematically. The parallel triangular solvers are fundamental to incomplete LU factorization family preconditioners and algebraic multigrid solvers. We develop a new matrix format suitable for GPU devices. Parallel lower triangular solvers and upper triangular solvers are developed for this new data structure. With these solvers, ILU preconditioners and domain decomposition preconditioners are developed. Numerical results show that we can speed triangular solvers around seven times faster.},
  bibsource     = {dblp computer science bibliography, http://dblp.org},
  biburl        = {http://dblp2.uni-trier.de/rec/bib/journals/corr/ChenLY16},
  timestamp     = {Fri, 01 Jul 2016 17:39:49 +0200},
  volume        = {abs/1606.00541},
}

@TechReport{Sutton2016a,
  author        = {Michael Sutton and Tal Ben{-}Nun and Amnon Barak and Sreepathi Pai and Keshav Pingali},
  title         = {Adaptive Work-Efficient Connected Components on the {GPU}},
  institution   = {The Computing Research Repository},
  date          = {2016},
  url           = {http://arxiv.org/abs/1612.01178},
  __markedentry = {[ap8213:6]},
  abstract      = {This report presents an adaptive work-efficient approach for implementing the Connected Components algorithm on GPUs. The results show a considerable increase in performance (up to 6.8$\times$) over current state-of-the-art solutions.},
  bibsource     = {dblp computer science bibliography, http://dblp.org},
  biburl        = {http://dblp.uni-trier.de/rec/bib/journals/corr/SuttonBBPP16},
  timestamp     = {Mon, 02 Jan 2017 11:09:15 +0100},
  volume        = {abs/1612.01178},
}

@Article{Li2018a,
  author        = {Li, Ruipeng and Xi, Yuanzhe and Erlandson, Lucas and Saad, Yousef},
  title         = {The Eigenvalues Slicing Library (EVSL): Algorithms, Implementation, and Software},
  year          = {2018},
  eprint        = {arXiv:1802.05215},
  __markedentry = {[ap8213:6]},
  abstract      = {This paper describes a software package called EVSL (for EigenValues Slicing Library) for solving large sparse real symmetric standard and generalized eigenvalue problems. As its name indicates, the package exploits spectrum slicing, a strategy that consists of dividing the spectrum into a number of subintervals and extracting eigenpairs from each subinterval independently. In order to enable such a strategy, the methods implemented in EVSL rely on a quick calculation of the spectral density of a given matrix, or a matrix pair. What distinguishes EVSL from other currently available packages is that EVSL relies entirely on filtering techniques. Polynomial and rational filtering are both implemented and are coupled with Krylov subspace methods and the subspace iteration algorithm. On the implementation side, the package offers interfaces for various scenarios including matrix-free modes, whereby the user can supply his/her own functions to perform matrix-vector operations or to solve sparse linear systems. The paper describes the algorithms in EVSL, provides details on their implementations, and discusses performance issues for the various methods.},
  timestamp     = {2019.06.16},
}

@Article{Coutinho2018a,
  author        = {Coutinho, Demetrios and Xavier-de-Souza, Samuel and Aloise, Daniel},
  title         = {A Scalable Shared-Memory Parallel Simplex for Large-Scale Linear Programming},
  year          = {2018},
  eprint        = {arXiv:1804.04737},
  __markedentry = {[ap8213:6]},
  abstract      = {We present a shared-memory parallel implementation of the Simplex tableau algorithm for dense large-scale Linear Programming (LP) problems. We present the general scheme and explain each parallelization step of the standard simplex algorithm, emphasizing important solutions for solving performance bottlenecks. We analyzed the speedup and the parallel efficiency for the proposed implementation relative to the standard Simplex algorithm using a shared-memory system with 64 processing cores. The experiments were performed for several different problems, with up to 8192 variables and constraints, in their primal and dual formulations. The results show that the performance is mostly much better when we use the formulation with more variables than inequality constraints. Also, they show that the parallelization strategies applied to avoid bottlenecks caused the implementation to scale well with the problem size and the core count up to a certain limit of problem size. Further analysis showed that this was an effect of resource limitation. Even though, our implementation was able to reach speedups in the order of 19$\times$.},
  timestamp     = {2019.06.16},
}

@Article{Tavernier2018a,
  author        = {Joris Tavernier and Jaak Simm and Karl Meerbergen and Yves Moreau},
  title         = {Multilevel preconditioning for Ridge Regression},
  year          = {2018},
  eprint        = {arXiv:1806.05826},
  __markedentry = {[ap8213:6]},
  abstract      = {Solving linear systems is often the computational bottleneck in real-life problems. Iterative solvers are the only option due to the complexity of direct algorithms or because the system matrix is not explicitly known. Here, we develop a multilevel preconditioner for regularized least squares linear systems involving a feature or data matrix. Variants of this linear system may appear in machine learning applications, such as ridge regression, logistic regression, support vector machines and matrix factorization with side information. We use clustering algorithms to create coarser levels that preserve the principal components of the covariance or Gram matrix. These coarser levels approximate the dominant eigenvectors and are used to build a multilevel preconditioner accelerating the Conjugate Gradient method. We observed speed-ups for artificial and real-life data. For a specific data set, we achieved speed-up up to a factor 100.},
  timestamp     = {2019.06.16},
}

@Article{Mohammadi2018a,
  author        = {Mahdi Soltan Mohammadi and Kazem Cheshmi and Ganesh Gopalakrishnan and Mary W. Hall and Maryam Mehri Dehnavi and Anand Venkat and Tomofumi Yuki and Michelle Mills Strout},
  title         = {Sparse Matrix Code Dependence Analysis Simplification at Compile Time},
  journal       = {CoRR},
  year          = {2018},
  volume        = {abs/1807.10852},
  eprint        = {1807.10852},
  url           = {http://arxiv.org/abs/1807.10852},
  __markedentry = {[ap8213:6]},
  abstract      = {Analyzing array-based computations to determine data dependences is useful for many applications including automatic parallelization, race detection, computation and communication overlap, verification, and shape analysis. For sparse matrix codes, array data dependence analysis is made more difficult by the use of index arrays that make it possible to store only the nonzero entries of the matrix (e.g., in A[B[i]], B is an index array). Here, dependence analysis is often stymied by such indirect array accesses due to the values of the index array not being available at compile time. Consequently, many dependences cannot be proven unsatisfiable or determined until runtime. Nonetheless, index arrays in sparse matrix codes often have properties such as monotonicity of index array elements that can be exploited to reduce the amount of runtime analysis needed. In this paper, we contribute a formulation of array data dependence analysis that includes encoding index array properties as universally quantified constraints. This makes it possible to leverage existing SMT solvers to determine whether such dependences are unsatisfiable and significantly reduces the number of dependences that require runtime analysis in a set of eight sparse matrix kernels. Another contribution is an algorithm for simplifying the remaining satisfiable data dependences by discovering equalities and/or subset relationships. These simplifications are essential to make a runtime-inspection-based approach feasible.},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/abs-1807-10852},
  timestamp     = {Mon, 13 Aug 2018 16:46:36 +0200},
}

@Article{Yang2018d,
  author        = {Carl Yang and Aydin Bulu{\c{c}} and John D. Owens},
  title         = {Implementing Push-Pull Efficiently in GraphBLAS},
  year          = {2018},
  volume        = {abs/1804.03327},
  eprint        = {arXiv:1804.03327},
  eprinttype    = {arXiv},
  __markedentry = {[ap8213:6]},
  abstract      = {We factor Beamer's push-pull, also known as direction-optimized breadth-first-search (DOBFS) into 3 separable optimizations, and analyze them for generalizability, asymptotic speedup, and contribution to overall speedup. We demonstrate that masking is critical for high performance and can be generalized to all graph algorithms where the sparsity pattern of the output is known a priori. We show that these graph algorithm optimizations, which together constitute DOBFS, can be neatly and separably described using linear algebra and can be expressed in the GraphBLAS linear-algebra-based framework. We provide experimental evidence that with these optimizations, a DOBFS expressed in a linear-algebra-based graph framework attains competitive performance with state-of-the-art graph frameworks on the GPU and on a multi-threaded CPU, achieving 101 GTEPS on a Scale 22 RMAT graph.},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/abs-1804-03327},
  timestamp     = {Mon, 13 Aug 2018 16:48:40 +0200},
}

@Misc{Fukaya2018a,
  author        = {Takeshi Fukaya and Ramaseshan Kannan and Yuji Nakatsukasa and Yusaku Yamamoto and Yuka Yanagisawa},
  title         = {Shifted CholeskyQR for computing the QR factorization of ill-conditioned matrices},
  year          = {2018},
  eprint        = {arXiv:1809.11085},
  __markedentry = {[ap8213:6]},
  abstract      = {The Cholesky QR algorithm is an efficient communication-minimizing algorithm for computing the QR factorization of a tall-skinny matrix. Unfortunately it has the inherent numerical instability and breakdown when the matrix is ill-conditioned. A recent work establishes that the instability can be cured by repeating the algorithm twice (called CholeskyQR2). However, the applicability of CholeskyQR2 is still limited by the requirement that the Cholesky factorization of the Gram matrix runs to completion, which means it does not always work for matrices X with $\kappa_2(X) \ge u^{-\frac{1}{2}}$ where $u$ is the unit roundoff. In this work we extend the applicability to $\kappa_2(X)=\mathcal{O}(u^{-1})$ by introducing a shift to the computed Gram matrix so as to guarantee the Cholesky factorization $R^T R = A^T A+sI$ succeeds numerically. We show that the computed $A R^{-1}$ has reduced condition number ${} \le u^{-\frac{1}{2*}}$, for which CholeskyQR2 safely computes the QR factorization, yielding a computed Q of orthogonality $\mid Q^T Q - I\mid_2$ and residual $\mid A-QR\mid _F/\mid A\mid_F$ both $\mathcal{O}(u)$. Thus we obtain the required QR factorization by essentially running Cholesky QR thrice. We extensively analyze the resulting algorithm shiftedCholeskyQR to reveal its excellent numerical stability. shiftedCholeskyQR is also highly parallelizable, and applicable and effective also when working in an oblique inner product space. We illustrate our findings through experiments, in which we achieve significant (up to $\times$40) speedup over alternative methods.},
  timestamp     = {2019.06.16},
}

@Misc{Rong2018a,
  author        = {Hongbo Rong},
  title         = {Expressing Sparse Matrix Computations for Productive Performance on Spatial Architectures},
  year          = {2018},
  eprint        = {arXiv:1810.07517},
  __markedentry = {[ap8213:6]},
  abstract      = {This paper addresses spatial programming of sparse matrix computations for productive performance. The challenge is how to express an irregular computation and its optimizations in a regular way.

A sparse matrix has (non-zero) values and a structure. In this paper, we propose to classify the implementations of a computation on a sparse matrix into two categories: (1) structure-driven, or top-down, approach, which traverses the structure with given row and column indices and locates the corresponding values, and (2) values-driven, or bottom-up, approach, which loads and processes the values in parallel streams, and decodes the structure for the values’ corresponding row and column indices. On a spatial architecture like FPGAs, the values-driven approach is the norm. We show how to express a sparse matrix computation and its optimizations for a values-driven implementation. A compiler automatically synthesizes a code to decode the structure. In this way, programmers focus on optimizing the processing of the values, using familiar optimizations for dense matrices, while leaving the complex, irregular structure traversal to an automatic compiler. We also attempt to regularize the optimizations of the reduction for a dynamic number of values, which is common in a sparse matrix computation.},
  timestamp     = {2019.06.16},
}

@Misc{Knigge2018a,
  author        = {Timon E. Knigge and Rob H. Bisseling},
  title         = {An improved exact algorithm and an NP-completeness proof for sparse matrix bipartitioning},
  year          = {2018},
  eprint        = {arXiv:1811.02043},
  __markedentry = {[ap8213:6]},
  abstract      = {We formulate the sparse matrix bipartitioning problem of minimizing the communication volume in parallel sparse matrix-vector multiplication. We prove its NP-completeness in the perfectly balanced case, where both parts of the partitioned matrix must have an equal number of nonzeros, by reduction from the graph bisection problem. We present an improved exact branch-and-bound algorithm which finds the minimum communication volume for a given maximum allowed imbalance. The algorithm is based on a maximum-flow bound and a pack- ing bound, which extend previous matching and packing bounds. We implemented the algorithm in a new program called MP (Matrix Partitioner), which solved 839 matrices from the SuiteSparse collection to optimality, each within 24 hours of CPU-time. Furthermore, MP solved the difficult problem of the matrix cage6 in about 3 days. The new program is about 13.8 times faster than the previous program MondriaanOpt.},
  timestamp     = {2019.06.16},
}

@Misc{Cartis2018b,
  author        = {Coralia Cartis and Nick I. M. Gould and Philippe L. Toint},
  title         = {Sharp worst-case evaluation complexity bounds for arbitrary-order nonconvex optimization with inexpensive constraints},
  year          = {2018},
  eprint        = {arXiv:1811.01220},
  __markedentry = {[ap8213:6]},
  abstract      = {We provide sharp worst-case evaluation complexity bounds for non convex minimization problems with general inexpensive constraints, i.e. problems where the cost of evaluating/enforcing of the (possibly nonconvex or even disconnected) constraints, if any, is negligible compared to that of evaluating the objective function.  These bounds unify, extend or improve all known upper and lower complexity bounds for unconstrained and convexly-constrained problems. It is shown that, given an accuracy level $\epsilon$, a degree of highest available Lipschitz continuous derivatives $p$ and a desired optimality order $q$ between one and $p$, a conceptual regularization algorithm requires no more than $O(\epsilon^{-\frac{p+1}{p-q+1}}$ evaluations of the objective function and its derivatives to compute a suitably approximate $q$-th order minimizer. With an appropriate choice of the regularization, a similar result also holds if the $p$-th derivative is merely Holder rather than Lipschitz continuous. We provide an example that shows that the above complexity bound is sharp for unconstrained and a wide class of constrained problems; we also give reasons for the optimality of regularization methods from a worst-case complexity point of view, within a large class of algorithms that use the same derivative information.},
  timestamp     = {2019.06.16},
}

@Article{Agullo2019,
  author        = {Emmanuel Agullo, Luc Giraud, Louis Poirel},
  title         = {Robust preconditioners via generalized eigenproblems for hybrid sparse linear solvers},
  journaltitle  = {{SIAM} Journal on Matrix Analysis and Applications},
  year          = {2019},
  url           = {https://hal.inria.fr/hal-02074474/document},
  __markedentry = {[ap8213:6]},
  abstract      = {The solution of large sparse linear systems is one of the most time consuming kernels in many numerical simulations. The domain decomposition community has developed many efficient and robust methods in the last decades. While many of these solvers fall into the abstract Schwarz (aS) framework, their robustness has originally been demonstrated on a case-by-case basis. In this paper, we propose a bound for the condition number of all deflated aS methods provided that the coarse grid consists of the assembly of local components that contain the kernel of some local operators. We show that classical results from the literature on particular instances of aS methods can be retrieved from this bound. We then show that such a coarse grid correction can be explicitly obtained algebraically via generalized eigenproblems, leading to a condition number independent of the number of domains. This result can be readily applied to retrieve or improve the bounds previously obtained via generalized eigenproblems in the particular cases of Neumann-Neumann (NN), Additive Schwarz (AS) and optimized Robin but also generalizes them when applied with approximate local solvers. Interestingly, the proposed methodology turns out to be a comparison of the considered particular aS method with generalized versions of both NN and AS for tackling the lower and upper part of the spectrum, respectively. We furthermore show that the application of the considered grid corrections in an additive fashion is robust in the AS case although it is not robust for aS methods in general. In particular, the proposed framework allows for ensuring the robustness of the AS method applied on the Schur complement (AS/S), either with deflation or additively, and with the freedom of relying on an approximate local Schur complement. Numerical experiments illustrate these statements.},
  timestamp     = {2019.06.16},
}

@TechReport{Georgieva2019,
  author        = {Irina Georgieva and Stanislav Harizanov and Clemens Hofreither},
  title         = {Iterative Low-rank Approximation Solvers for the Extension Method for Fractional Diffusion},
  institution   = {Johann Radon Institute for Computational and Applied Mathematics (RICAM)},
  year          = {2019},
  number        = {RICAM-Report 2019-14},
  __markedentry = {[ap8213:6]},
  abstract      = {We consider the numerical method for fractional diffusion problems which is based on an extension to a mixed boundary value problem for a local operator in a higher dimensional space. We observe that, when this problem is discretized using tensor product spaces as is commonly done, the solution can be very well approximated by low-rank tensors. This motivates us to apply iterative low-rank approximation algorithms in order to efficiently solve this extended problem. In particular, we employ a recently proposed greedy Tucker approximation method as well as a more classical greedy rank one update method. Throughout, all objects of interest are kept in suitable low-rank approximations, which dramatically reduces the required amount of memory compared to the full formulation of the extended problem.\\
Our approach can be used for general, non-structured space discretizations. If the space discretization itself has tensor product structure, we can further decompose the problem in order to deal with even lower dimensional objects. We also note that the approach can be directly applied to higher-order discretizations both in space and the extended variable.\\
In several numerical examples, we demonstrate the convergence behaviour of the proposed methods. In particular, the Tucker approximation approach requires only a few iterations in order to reach the discretization error in all tested settings.},
  timestamp     = {2019.06.16},
}

@Article{Zhou2019,
  author        = {Gan Zhou and Yanjun Feng and Rui Bo and Tao Zhang},
  title         = {{GPU}-accelerated sparse matrices parallel inversion algorithm for large-scale power systems},
  journal       = {International Journal of Electrical Power \& Energy Systems},
  year          = {2019},
  volume        = {111},
  pages         = {34--43},
  issn          = {0142-0615},
  doi           = {https://doi.org/10.1016/j.ijepes.2019.03.074},
  url           = {http://www.sciencedirect.com/science/article/pii/S0142061518325109},
  __markedentry = {[ap8213:6]},
  abstract      = {State-of-the-art Graphics Processing Unit (GPU) has superior performances on float-pointing calculation and memory bandwidth, and therefore has great potential in many computationally intensive power system applications, one of which is the inversion of large-scale sparse matrix. It is a fundamental component for many power system analyses which requires to solve massive number of forward and backward substitution (F\&B) subtasks and seems to be a good GPU-accelerated candidate application. By means of solving multiple F\&B subtasks concurrently and a serial of performance tunings in compliance with GPU’s architectures, we successfully develop a batch F\&B algorithm on GPUs, which not only extracts the intra-level and intra-level parallelisms inside single F\&B subtask but also explores a more regular parallelism among massive F\&B subtasks, called inter-task parallelism. Case study on a 9241-dimension case shows that the proposed batch F\&B solver consumes 2.92 $\mu$s per forward substitution (FS) subtask when the batch size is equal to 3072, achieving 65 times speedup relative to KLU library. And on the basis the complete design process of GPU-based inversion algorithm is proposed. By offloading the tremendous computational burden to GPU, the inversion of 9241-dimension case consumes only 97 ms, which can achieve 8.1 times speedup relative to the 12-core CPU inversion solver based on KLU library. The proposed batch F\&B solver is practically very promising in many other power system applications requiring solving massive F\&B subtasks, such as probabilistic power flow analysis.},
  keywords      = {Inversion, Forward substitution, Backward substitution, Spares matrix, GPU, Accelerated, Parallelism, Power flow},
  timestamp     = {2019.06.16},
}

@Article{Xiao2019,
  author        = {G. {Xiao} and K. {Li} and Y. {Chen} and W. {He} and A. {Zomaya} and T. {Li}},
  title         = {{CASpMV}: A Customized and Accelerative SpMV Framework for the Sunway TaihuLight},
  journal       = {IEEE Transactions on Parallel and Distributed Systems},
  year          = {2019},
  pages         = {1--1},
  issn          = {1045-9219},
  doi           = {10.1109/TPDS.2019.2907537},
  __markedentry = {[ap8213:6]},
  abstract      = {The Sunway TaihuLight, equipped with 10 million cores, is currently the world's third fastest supercomputer. SpMV is one of core algorithms in many high-performance computing applications. This paper implements a fine-grained design for generic parallel SpMV based on the special Sunway architecture and finds three main performance limitations, i.e., storage limitation, load imbalance, and huge overhead of irregular memory accesses. To address these problems, this paper introduces a customized and accelerative framework for SpMV (CASpMV) on the Sunway. The CASpMV customizes an auto-tuning four-way partition scheme for SpMV based on the proposed statistical model, which describes the sparse matrix structure characteristics, to make it better fit in with the computing architecture and memory hierarchy of the Sunway. Moreover, the CASpMV provides an accelerative method and customized optimizations to avoid irregular memory accesses and further improve its performance on the Sunway. Our CASpMV achieves a performance improvement that ranges from 588.05\% to 2118.62\% over the generic parallel SpMV on a CG (which corresponds to an MPI process) of the Sunway on average and has good scalability on multiple CGs. The performance comparisons of the CASpMV with state-of-the-art methods on the Sunway indicate that the sparsity and irregularity of data structures have less impact on CASpMV.},
  keywords      = {Sparse matrices;Computer architecture;Parallel processing;Acceleration;Supercomputers;Kernel;Graphics processing units;Heterogeneous many-core processor;matrix partition;optimization;parallelism;SpMV;Sunway TaihuLight supercomputer},
  timestamp     = {2019.06.16},
}

@Article{Ma2019,
  author        = {S. {Ma} and Z. {Liu} and S. {Chen} and L. {Huang} and Y. {Guo} and Z. {Wang} and M. {Zhang}},
  title         = {Coordinated DMA: Improving the DRAM Access Efficiency for Matrix Multiplication},
  journal       = {IEEE Transactions on Parallel and Distributed Systems},
  year          = {2019},
  pages         = {1--1},
  issn          = {1045-9219},
  doi           = {10.1109/TPDS.2019.2906891},
  __markedentry = {[ap8213:6]},
  abstract      = {High performance implementation of matrix multiplication is essential for scientific computing. The memory access procedure is quite possible to be the bottleneck of matrix multiplication. The widely used GotoBLAS GEMM implementation divides the integral matrix into several partitions to be assigned to different cores for parallelization. Traditionally, each core deploys a DMA transfer to access its own partition in the DRAM memory. However, deploying an independent DMA transfer for each core cannot efficiently exploit the inter-core locality. Also, multiple concurrent DMA transfers interfere with each other, further reducing the DRAM access efficiency. We observe that the same row of neighboring partitions is in the same DRAM page, which means that there is significant locality inherent in the address layout. We propose the coordinated DMA to efficiently exploit the locality. It invokes one transfer to serve all cores and moves data in a row-major manner to improve the DRAM access efficiency. Compared with a baseline design, the coordinated DMA improves the bandwidth by 84.8\% and reduces DRAM energy consumption by 43.1\% for micro-benchmarks. It achieves higher performance for the GEMM and Linpack benchmark. With much less hardware costs, the coordinated DMA significantly outperforms an out-of-order memory controller.},
  keywords      = {Random access memory;Bandwidth;Out of order;Computer architecture;Layout;Graphics processing units;Hardware;Coordinated DMA;DRAM Access Efficiency;Matrix Multiplication},
  timestamp     = {2019.06.16},
}

@InProceedings{Li2019a,
  author    = {Li, Jiajia and Uçar, Bora and Çatalyürek, Ümit V. and Sun, Jimeng and Barker, Kevin and Vuduc, Richard},
  title     = {Efficient and Effective Sparse Tensor Reordering},
  booktitle = {Proceedings of the ACM International Conference on Supercomputing},
  year      = {2019},
  series    = {ICS '19},
  publisher = {ACM},
  location  = {Phoenix, Arizona},
  isbn      = {978-1-4503-6079-1},
  pages     = {227--237},
  doi       = {10.1145/3330345.3330366},
  abstract  = {This paper formalizes the problem of reordering a sparse tensor to improve the spatial and temporal locality of operations with it, and proposes two reordering algorithms for this problem, which we call BFS-MCS and Lexi-Order. The BFS-MCS method is a Breadth First Search (BFS)-like heuristic approach based on the maximum cardinality search family; Lexi-Order is an extension of doubly lexical ordering of matrices to tensors. We show the effects of these schemes within the context of a widely used tensor computation, the CANDECOMP/PARAFAC decomposition (CPD), when storing the tensor in three previously proposed sparse tensor formats: coordinate (COO), compressed sparse fiber (CSF), and hierarchical coordinate (HiCOO). A new partition-based superblock scheduling is also proposed for HiCOO format to improve load balance. On modern multicore CPUs, we show Lexi-Order obtains up to 4.14$\times$ speedup on sequential HiCOO-Mttkrp and 11.88$\times$ speedup on its parallel counterpart. The performance of COO- and CSF-based Mttkrps also improves. Our two reordering methods are more effective than state-of-the-art approaches. The code is released as part of Parallel Tensor Infrastructure (ParTI!): https://github.com/hpcgarage/ParTI.},
  acmid     = {3330366},
  address   = {New York, NY, USA},
  keywords  = {HiCOO, hierarchical coordinate, reordering, sparse tensor, tensor decomposition},
  numpages  = {11},
}

@InProceedings{Sao2019a,
  author    = {Sao, Piyush and Kannan, Ramakrishnan and Li, Xiaoye Sherry and Vuduc, Richard},
  title     = {A Communication-avoiding 3D Sparse Triangular Solver},
  booktitle = {Proceedings of the ACM International Conference on Supercomputing},
  year      = {2019},
  series    = {ICS '19},
  publisher = {ACM},
  location  = {Phoenix, Arizona},
  isbn      = {978-1-4503-6079-1},
  pages     = {127--137},
  doi       = {10.1145/3330345.3330357},
  abstract  = {We present a novel distributed memory algorithm to improve the strong scalability of the solution of a sparse triangular system. This operation appears in the solve phase of direct methods for solving general sparse linear systems, $Ax = b$. Our 3D sparse triangular solver employs several techniques, including a 3D MPI process grid, elimination tree parallelism, and data replication, all of which reduce the per-process communication when combined. We present analytical models to understand the communication cost of our algorithm and show that our 3D sparse triangular solver can reduce the per-process communication volume asymptotically by a factor of $O(n^{1/4})$ and $O(n^{1/6})$ for problems arising from the finite element discretizations of 2D "planar" and 3D "non-planar" PDEs, respectively. We implement our algorithm for use in SuperLU_DIST3D, using a hybrid MPI+OpenMP programming model. Our 3D triangular solve algorithm, when run on 12k cores of Cray XC30, outperforms the current state-of-the-art 2D algorithm by 7.2$\times$ for planar and 2.7$\times$ for the non-planar sparse matrices, respectively.},
  acmid     = {3330357},
  address   = {New York, NY, USA},
  keywords  = {communication-avoiding algorithms, distributed-memory parallelism, sparse matrix computations},
  numpages  = {11},
}

@InBook{Alyahya2020,
  author    = {Alyahya, Hana and Mehmood, Rashid and Katib, Iyad},
  title     = {Parallel Iterative Solution of Large Sparse Linear Equation Systems on the Intel {MIC} Architecture},
  booktitle = {Smart Infrastructure and Applications: Foundations for Smarter Cities and Societies},
  year      = {2020},
  editor    = {Mehmood, Rashid and See, Simon and Katib, Iyad and Chlamtac, Imrich},
  publisher = {Springer International Publishing},
  isbn      = {978-3-030-13705-2},
  pages     = {377--407},
  doi       = {10.1007/978-3-030-13705-2_16},
  abstract  = {Many important scientific, engineering, and smart city applications require solving large sparse linear equation systems. The numerical methods for solving linear equations can be categorised into direct methods and iterative methods. Jacobi method is one of the iterative solvers that has been widely used due to its simplicity and efficiency. Its performance is affected by factors including the storage format, the specific computational algorithm, and its implementation. While the performance of Jacobi has been studied extensively on conventional CPU architectures, research on its performance on emerging architectures, such as the Intel Many Integrated Core (MIC) architecture, is still in its infancy. In this chapter, we investigate the performance of parallel implementations of the Jacobi method on Knights Corner (KNC), the first generation of the Intel MIC architectures. We implement Jacobi with two storage formats, Compressed Sparse Row (CSR) and Modified Sparse Row (MSR), and measure their performance in terms of execution time, offloading time, and speedup. We report results of sparse matrices with over 28 million rows and 640 million non-zero elements acquired from 13 diverse application domains. The experimental results show that our Jacobi parallel implementation on MIC achieves speedups of up to 27.75$\times$ compared to the sequential implementation. It also delivers a speedup of up to 3.81$\times$ compared to a powerful node comprising 24 cores in two Intel Xeon E5-2695v2 processors.},
  address   = {Cham},
}

@InBook{AlAhmadi2020,
  author    = {AlAhmadi, Sarah and Muhammed, Thaha and Mehmood, Rashid and Albeshri, Aiiad},
  title     = {Performance Characteristics for Sparse Matrix-Vector Multiplication on GPUs},
  booktitle = {Smart Infrastructure and Applications: Foundations for Smarter Cities and Societies},
  year      = {2020},
  editor    = {Mehmood, Rashid and See, Simon and Katib, Iyad and Chlamtac, Imrich},
  publisher = {Springer International Publishing},
  isbn      = {978-3-030-13705-2},
  pages     = {409--426},
  doi       = {10.1007/978-3-030-13705-2_17},
  abstract  = {The massive parallelism provided by the graphics processing units (GPUs) offers tremendous performance in many high-performance computing applications. One such application is Sparse Matrix-Vector (SpMV) multiplication, which is an essential building block for numerous scientific and engineering applications. Researchers who propose new storage techniques for sparse matrix-vector multiplication focus mainly on a single evaluation metrics or performance characteristics which is usually the throughput performance of sparse matrix-vector multiplication in FLOPS. However, such an evaluation does not provide a deeper insight nor allow to compare new SpMV techniques with their competitors directly. In this chapter, we explain the notable performance characteristics of the GPU architectures and SpMV computations. We discuss various strategies to improve the performance of SpMV on GPUs. We also discuss a few performance criteria that are usually overlooked by the researchers during the evaluation process. We also analyze various well-known schemes such as COO, CSR, ELL, DIA, HYB, and CSR5 using the discussed performance characteristics.},
  address   = {Cham},
}

@Online{Artemov2019,
  author     = {Anton G. Artemov},
  title      = {Sparse approximate matrix multiplication in a fully recursive distributed task-parallel framework},
  year       = {2019},
  abstract   = {In this paper we consider parallel implementations of approximate multiplication of large matrices with exponential decay of elements. Such matrices arise in computations related to electronic structure calculations and some other fields of science. Commonly, sparsity is introduced by truncation of input matrices. In turn, the sparse approximate multiplication algorithm [M. Challacombe and N. Bock, arXiv preprint 1011.3534, 2010] performs truncation of sub-matrix products. We consider these two methods and their combination, i.e. truncation of both input matrices and sub-matrix products. Implementations done using the Chunks and Tasks programming model and library [E. H. Rubensson and E. Rudberg, Parallel Comput., 40:328343, 2014] are presented and discussed. The absolute error asymptotic behavior is derived. A comparison between the three methods in terms of performance is done on a model problem. The algorithms are also applied to matrices coming from large chemical systems with $\approx$106 atoms.},
  eprint     = {arXiv:1906.0814},
  eprinttype = {arXiv},
}

@InProceedings{Anzalone2019,
  author   = {Anzalone, E. and Capra, M. and Peloso, R. and Martina, M. and Masera, G.},
  title    = {Low-power Hardware Accelerator for Sparse Matrix Convolution in Deep Neural Network"},
  year     = {2019},
  abstract = {Deep Neural Networks (DNN) have reached an outstanding accuracy in the past years, often going beyond human abilities. Nowadays, DNNs are widely used in many Artificial Intelligence (AI) applications such as computer vision, natural language processing and autonomous driving. However, these incredible performance come at a high computational cost, requiring complex hardware platforms. Therefore, the need for dedicated hardware accelerators able to drastically speed up the execution by preserving a low-power attitude arise. This paper presents innovative techniques able to tackle matrix sparsity in convolutional DNNs due to non-linear activation functions. Developed architectures allow to skip unnecessary operations, like zero multiplications, without sacrificing accuracy or throughput and improving the energy efficiency. Such improvement could enhance the performance of embedded limited-budget battery applications, where cost-effective hardware, accuracy and duration are critical to expanding the deployment of AI.},
}

@Article{Davydov2019,
  author        = {Davydov, Denis and Kronbichler, Martin},
  title         = {Algorithms and data structures for matrix-free finite element operators with MPI-parallel sparse multi-vectors},
  year          = {2019},
  month         = {Jul},
  eprint        = {arXiv:1907.01005},
  eprinttype    = {arXiv},
  abstract      = {Traditional solution approaches for problems in quantum mechanics scale as $O(M3)$, where $M$ is the number of electrons. Various methods have been proposed to address this issue and obtain linear scaling $O(M)$. One promising formulation is the direct minimization of energy. Such methods take advantage of physical localization of the solution, namely that the solution can be sought in terms of non-orthogonal orbitals with local support. In this work a numerically efficient implementation of sparse parallel vectors within the open-source finite element library deal.II is proposed. The main algorithmic ingredient is the matrix-free evaluation of the Hamiltonian operator by cell-wise quadrature. Based on an a-priori chosen support for each vector we develop algorithms and data structures to perform (i) matrix-free sparse matrix multivector products (SpMM), (ii) the projection of an operator onto a sparse sub-space (inner products), and (iii) post-multiplication of a sparse multivector with a square matrix. The node-level performance is analyzed using a roofline model. Our matrix-free implementation of finite element operators with sparse multivectors achieves the performance of 157 GFlop/s on Intel Cascade Lake architecture. Strong and weak scaling results are reported for a typical benchmark problem using quadratic and quartic finite element bases.},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2019arXiv190701005D},
  archiveprefix = {arXiv},
  keywords      = {Computer Science - Mathematical Software, Computer Science - Data Structures and Algorithms, Mathematics - Numerical Analysis, Physics - Computational Physics},
  primaryclass  = {cs.MS},
}

@Article{Choi2019a,
  author   = {Choi, Dongjin and Jang, Jun-Gi and Kang, U},
  title    = {S3CMTF: Fast, accurate, and scalable method for incomplete coupled matrix-tensor factorization},
  journal  = {{PloS} one},
  year     = {2019},
  volume   = {14},
  number   = {6},
  issn     = {1932-6203},
  doi      = {10.1371/journal.pone.0217316},
  abstract = {How can we extract hidden relations from a tensor and a matrix data simultaneously in a fast, accurate, and scalable way? Coupled matrix-tensor factorization (CMTF) is an important tool for this purpose. Designing an accurate and efficient CMTF method has become more crucial as the size and dimension of real-world data are growing explosively. However, existing methods for CMTF suffer from lack of accuracy, slow running time, and limited scalability. In this paper, we propose S3CMTF, a fast, accurate, and scalable CMTF method. In contrast to previous methods which do not handle large sparse tensors and are not parallelizable, S3CMTF provides parallel sparse CMTF by carefully deriving gradient update rules. S3CMTF asynchronously updates partial gradients without expensive locking. We show that our method is guaranteed to converge to a quality solution theoretically and empirically. S3CMTF further boosts the performance by carefully storing intermediate computation and reusing them. We theoretically and empirically show that S3CMTF is the fastest, outperforming existing methods. Experimental results show that S3CMTF is up to 930$\times$ faster than existing methods while providing the best accuracy. S3CMTF shows linear scalability on the number of data entries and the number of cores. In addition, we apply S3CMTF to Yelp rating tensor data coupled with 3 additional matrices to discover interesting patterns.},
}

@InProceedings{Lee2019,
  author    = {Lee, Chao-Lin and Chao, Chen-Ting and Lee, Jenq-Kuen and Huang, Chung-Wen and Hung, Ming-Yu},
  title     = {Sparse-Matrix Compression Primitives with OpenCL Framework to Support Halide},
  booktitle = {Proceedings of the International Workshop on OpenCL},
  year      = {2019},
  series    = {IWOCL'19},
  publisher = {ACM},
  location  = {Boston, MA, USA},
  isbn      = {978-1-4503-6230-6},
  pages     = {1--2},
  doi       = {10.1145/3318170.3318179},
  abstract  = {Halide and OpenCL now play important roles for heterogeneous multi-core computing. OpenCL provides vendor-level support and Halide provides domain-specific support such as vision processing and AI model (TVM Halide IR). Halide also provides flexible scheduling for applications on target machines. OpenCL plays a supporting role for Halide environments. In this work, we investigate the research issues in supporting sparse computation with Halide and their corresponding OpenCL support. We present sparse matrix compression primitives on Halide for sparse matrix matrix (SpMM) multiplication with OpenCL framework. Halide is a programming language designed to process image and array from numerous algorithms and scheduling primitives to achieve state-of-art performance including SIMD and heterogeneous computation. This paper proposed the implementation of sparse matrix compression for Halide scheduling primitives including COO, CSR, and hybrid CSR. The design of experiments includes Halide primitives for sparse matrix compression and matrix computations. The experimental result of computation with compressing matrix shows the performance are improved by up to 85\% compared to the baseline without compression.},
  acmid     = {3318179},
  address   = {New York, NY, USA},
  articleno = {24},
  keywords  = {Halide, OpenCL, Sparse Matrix},
  numpages  = {2},
}

@InProceedings{Loe2019,
  author     = {Jennifer A. Loe and Heidi K. Thornquist and Erik G. Boman},
  title      = {Polynomial Preconditioned GMRES to Reduce Communication in Parallel Computing},
  year       = {2019},
  eprint     = {arXiv:1907.00072},
  eprinttype = {arXiv},
  abstract   = {Polynomial preconditioning with the GMRES minimal residual polynomial has the potential to greatly reduce orthogonalization costs, making it useful for communication reduction. We implement polynomial preconditioning in the Belos package from Trilinos and show how it can be effective in both serial and parallel implementations. We further show it is a communication-avoiding technique and is a viable option to CAGMRES for large-scale parallel computing.},
}

@Article{Grutzmacher2019,
  author   = {Grützmacher, Thomas and Cojean, Terry and Flegar, Goran and Göbel, Fritz and Anzt, Hartwig},
  title    = {A customized precision format based on mantissa segmentation for accelerating sparse linear algebra},
  journal  = {Concurrency and Computation: Practice and Experience},
  year     = {2019},
  doi      = {10.1002/cpe.5418},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.5418},
  abstract = {Summary In this work, we pursue the idea of radically decoupling the floating point format used for arithmetic operations from the format used to store the data in memory. We complement this idea with a customized precision memory format derived by splitting the mantissa (significand) of standard IEEE formats into segments, such that values can be accessed faster if lower accuracy is acceptable. Combined with precision-aware algorithms that dynamically adapt the data access accuracy to the numerical requirements, the customized precision memory format can render attractive runtime savings without impacting the memory footprint of the data or the accuracy of the final result. In an experimental analysis using the adaptive precision Jacobi method on diagonalizable test problems, we assess the benefits of the mantissa-segmenting customized precision format on recent multi- and manycore architectures.},
  keywords = {adaptive precision Jacobi, GPUs, mantissa segmentation, modular precision ecosystem, multiprecision algorithm, multicore},
}

@Article{Goldenberg2019,
  author   = {Goldenberg, S. and Stathopoulos, A. and Romero, E.},
  title    = {A Golub--Kahan Davidson Method for Accurately Computing a Few Singular Triplets of Large Sparse Matrices},
  journal  = {{SIAM} Journal on Scientific Computing},
  year     = {2019},
  volume   = {41},
  number   = {4},
  pages    = {A2172-A2192},
  doi      = {10.1137/18M1222004},
  abstract = {Obtaining high accuracy singular triplets for large sparse matrices is a significant challenge, especially when searching for the smallest triplets. Due to the difficulty and size of these problems, efficient methods must function iteratively, with preconditioners, and under strict memory constraints. In this research, we present a Golub--Kahan Davidson method (GKD), which satisfies these requirements and includes features such as soft-locking with orthogonality guarantees, an inner correction equation similar to Jacobi--Davidson, locally optimal +k restarting, and the ability to find real zero singular values in both square and rectangular matrices. Additionally, our method achieves full accuracy while avoiding the augmented matrix, which often converges slowly for the smallest triplets due to the difficulty of interior eigenvalue problems. We describe our method in detail, including implementation issues that arise. Our experimental results confirm the efficiency and stability of our method over the current implementation of PHSVDS in the PRIMME software package.},
}

@Article{Choi2019,
  author     = {Bosu Choi and Andrew Christlieb and Yang Wang},
  title      = {Multiscale High-Dimensional Sparse Fourier Algorithms for Noisy Data},
  eprint     = {arXiv:1907.03692},
  eprinttype = {arXiv},
  abstract   = {We develop an efficient and robust high-dimensional sparse Fourier algorithm for noisy samples. Earlier in the paper Multi-dimensional sublinear sparse Fourier algorithm (2016) [3], an efficient sparse Fourier algorithm with $O(ds log s)$ average-case runtime and $O(ds)$ sampling complexity under certain assumptions was developed for signals that are s-sparse and bandlimited in the d-dimensional Fourier domain, i.e. there are at most s energetic frequencies and they are in $[-N/2, N/2)^d \cap \mathbb{Z}^d$. However, in practice the measurements of signals often contain noise, and in some cases may only be nearly sparse in the sense that they are well approximated by the best s Fourier modes. In this paper, we propose a multiscale sparse Fourier algorithm for noisy samples that proves to be both robust against noise and efficient.},
}

@Article{Klowckiewicz2019,
  author     = {Bazyl Klowckiewicz and Eric Darve},
  title      = {Sparse hierarchical preconditioners using piecewise smooth approximations of eigenvectors},
  year       = {2019},
  eprint     = {arXiv:1907.0},
  eprinttype = {arXiv},
  abstract   = {When solving linear systems arising from PDE discretizations, iterative methods (such as Conjugate Gradient, GMRES, or MINRES) are often the only practical choice. To converge in a small number of iterations, however, they have to be coupled with an efficient preconditioner. The efficiency of the preconditioner depends largely on its accuracy on the eigenvectors corresponding to small eigenvalues, and unfortunately, black-box methods typically cannot guarantee sufficient accuracy on these eigenvectors. Thus, constructing the preconditioner becomes a very problemdependent task. We describe a hierarchical approximate factorization approach which addresses this issue by focusing on improving the accuracy on smooth eigenvectors (such eigenvectors typically correspond to the small eigenvalues). The improved accuracy is achieved by preserving the action of the factorized matrix on piecewise polynomial functions of the PDE domain. Based on the factorization, we propose a family of sparse preconditioners with $O (n)$ or $O (n log n)$ construction complexities. Our methods exhibit the optimal $O (n)$ solution times in benchmarks run on large elliptic problems of different types, arising for example in flow or mechanical simulations. In the case of the linear elasticity equation the preconditioners are exact on the near-kernel rigid body modes.},
}

@PhdThesis{Yang2019,
  author      = {Yang, Carl Y.},
  title       = {High-Performance Linear Algebra-based Graph Framework on the GPU},
  institution = {University of California, Davis},
  year        = {2019},
  url         = {https://escholarship.org/uc/item/37j8j27d},
  abstract    = {High-performance implementations of graph algorithms are challenging to implement on new parallel hardware such as GPUs, because of three challenges: (1) difficulty of coming up with graph building blocks, (2) load imbalance on parallel hardware, and (3) graph problems having low arithmetic ratio. To address these challenges, GraphBLAS is an innovative, on-going effort by the graph analytics community to propose building blocks based in sparse linear algebra, which will allow graph algorithms to be expressed in a performant, succinct, composable and portable manner. Initial research efforts in implementing GraphBLAS on GPUs has been promising, but performance still trails by an order of magnitude compared to state-of-the-art graph frameworks using the traditional graph-centric approach of describing operations on vertices or edges.\\
This dissertation examines the performance challenges of a linear algebra-based approach to building graph frameworks and describes new design principles for overcoming these bottlenecks. Among the new design principles is making exploiting input sparsity a first-class citizen in the framework. This is an especially important optimization, because it allows users to write graph algorithms without specifying certain implementation details thus permitting the software backend to choose the optimal implementation based on the input sparsity. Exploiting output sparsity allows users to tell the backend which values of the output in a single vectorized computation they do not want computed. We examine when it is profitable to exploit this output sparsity to reduce computational complexity. Load-balancing is an important feature for balancing work amongst parallel workers. We describe the important load-balancing features for handling graphs with different characteristics.\\
The design principles described in the thesis have been implemented in GraphBLAST, an open-source high-performance graph framework on GPU developed as part of this dissertation. It is notable for being the first graph framework based in linear algebra to get comparable or faster performance compared to the traditional, vertex-centric backends. The benefits of design principles described in this thesis have been shown to be important for single GPU, and it will grow in importance when it serves as a building block for distributed implementation in the future and as a single GPU backend for higher-level languages such as Python. A graph framework based in linear algebra not only improves performance of existing graph algorithms, but in quickly prototyping new algorithms as well.},
}

@Article{Camacho2019,
  author     = {Camacho, J. and Smilde, A. K. and Saccenti, E. and Westerhuis, J. A.},
  title      = {All Sparse PCA Models Are Wrong, But Some Are Useful. Part I: Computation of Scores, Residuals and Explained Variance},
  year       = {2019},
  eprint     = {arXiv:1907.03989},
  eprinttype = {arXiv},
  abstract   = {Sparse Principal Component Analysis (sPCA) is a popular matrix factorization approach based on Principal Component Analysis (PCA) that combines variance maximization and sparsity with the ultimate goal of improving data interpretation. When moving from PCA to sPCA, there are a number of implications that the practitioner needs to be aware of. A relevant one is that scores and loadings in sPCA may not be orthogonal. For this reason, the traditional way of computing scores, residuals and variance explained that is used in the classical PCA cannot directly be applied to sPCA models. This also affects how sPCA components should be visualized. In this paper we illustrate this problem both theoretically and numerically using simulations for several state-ofthe-art sPCA algorithms, and provide proper computation of the different elements mentioned. We show that sPCA approaches present disparate and limited performance when modeling noisefree, sparse data. In a follow-up paper, we discuss the theoretical properties that lead to this problem.},
}

@Article{Bertsimas2019,
  author     = {Dimitris Bertsimas and Bartolomeo Stellato},
  title      = {Online Mixed-Integer Optimization in Milliseconds},
  eprint     = {arXiv:1907.02206},
  eprinttype = {arXiv},
  abstract   = {We propose a method to solve online mixed-integer optimization (MIO) problems at very high speed using machine learning. By exploiting the repetitive nature of online optimization, we are able to greatly speedup the solution time. Our approach encodes the optimal solution into a small amount of information denoted as strategy using the Voice of Optimization framework proposed in [BS18]. In this way the core part of the optimization algorithm becomes a multiclass classification problem which can be solved very quickly. In this work we extend that framework to real-time and high-speed applications focusing on parametric mixed-integer quadratic optimization (MIQO). We propose an extremely fast online optimization algorithm consisting of a feedforward neural network (NN) evaluation and a linear system solution where the matrix has already been factorized. Therefore, this online approach does not require any solver nor iterative algorithm. We show the speed of the proposed method both in terms of total computations required and measured execution time. We estimate the number of floating point operations (flops) required to completely recover the optimal solution as a function of the problem dimensions. Compared to state-of-the-art MIO routines, the online running time of our method is very predictable and can be lower than a single matrix factorization time. We benchmark our method against the state-ofthe-art solver Gurobi obtaining from two to three orders of magnitude speedups on benchmarks with real-world data.},
  timestamp  = {2019.07.09},
}

@InBook{Bollhofer2019,
  author     = {Bollhöfer, Matthias and Schenk, Olaf and Janalík, Radim and Hamm, Steve and Gullapalli, Kiran},
  title      = {State-of-The-Art Sparse Direct Solvers},
  year       = {2019},
  eprint     = {arXiv:1907.05309},
  eprinttype = {arXiv},
  abstract   = {In this chapter we will give an insight into modern sparse elimination methods. These are driven by a preprocessing phase based on combinatorial algorithms which improve diagonal dominance, reduce fill-in and improve concurrency to allow for parallel treatment. Moreover, these methods detect dense submatrices which can be handled by dense matrix kernels based on multi-threaded level-3 BLAS. We will demonstrate for problems arising from circuit simulation how the improvement in recent years have advanced direct solution methods significantly},
}

@Article{Alappat2019,
  author     = {Christie Alappat and Georg Hager and Olaf Schenk and Jonas Thies and Achim Basermann and Alan R. Bishop and Holger Fehske and Gerhard Wellein},
  title      = {A Recursive Algebraic Coloring Technique for Hardware-Efficient Symmetric Sparse Matrix-Vector Multiplication},
  year       = {2019},
  eprint     = {arXiv:1907.06487},
  eprinttype = {arXiv},
  abstract   = {The symmetric sparse matrix-vector multiplication (SymmSpMV) is an important building block for many numerical linear algebra kernel operations or graph traversal applications. Parallelizing SymmSpMV on today's multicore platforms with up to 100 cores is difficult due to the need to manage conflicting updates on the result vector. Coloring approaches can be used to solve this problem without data duplication, but existing coloring algorithms do not take load balancing and deep memory hierarchies into account, hampering scalability and full-chip performance. In this work, we propose the recursive algebraic coloring engine (RACE), a novel coloring algorithm and open-source library implementation, which eliminates the shortcomings of previous coloring methods in terms of hardware efficiency and parallelization overhead. We describe the level construction, distance-k coloring, and load balancing steps in RACE, use it to parallelize SymmSpMV, and compare its performance on 31 sparse matrices with other state-of-the-art coloring techniques and Intel MKL on two modern multicore processors. RACE outperforms all other approaches substantially and behaves in accordance with the roofline model. Outliers are discussed and analyzed in detail. While we focus on SymmSpMV in this paper, our algorithm and software is applicable to any sparse matrix operation with data dependencies that can be resolved by distance-k coloring.},
}

@PhdThesis{Shi2019,
  author      = {Yang Shi},
  title       = {Efficient Tensor Operations via Compression and Parallel Computation},
  institution = {University of California, Irvine},
  year        = {2019},
  url         = {https://escholarship.org/uc/item/2wm4k3sn},
  abstract    = {Linear algebra is the foundation of machine learning, especially for handling big data. We want to extract useful information that can represent the behavior of the data. For data with underlying known structures, it is straightforward to apply algorithms that maintain that structure. For instance, singular value decomposition (SVD) is one way to approximate lowrank matrices. The generalized SVD, tensor decomposition, is the crux of model estimation for tensors. However, not all data has a trivial structure. Multi-modality data that contains information from different sources can be complex and hard to extract the structure. A data-independent randomized algorithm, such as sketching, is the solution for this case. Under both scenarios, the information extraction process may be statistically challenging as the problems are non-convex optimization problems. More importantly, the large size and the high-dimensionality of the data have been significant obstacles in discovering hidden variables and summarizing them. Thus, how to improve high-dimensional data computation efficiency is vitally important.\\ This thesis contains the theoretical analysis for learning the underlying information from high-dimensional structured or non-structured data via tensor operations such as tensor decomposition and tensor sketching. It is easy to consider tensors as multi-dimensional vectors or matrices and apply vector/matrix-based algorithms to find the solution. However, these methods omit multi-dimensionality of the data and can be computational inefficient than considering the tensor as a whole. We show the superiority of our approximation algorithms over these methods from computation and memory efficiency point of views.\\ This thesis also discusses optimizing tensor operation computations from the high-performance computing aspect. Conventional methods treat tensors as flattened matrices or vectors. Operations between tensors may require lots of permutations and reshapes. We propose new tensor algebra computation routines that avoid the prepossessing as much as possible. The value of this approach and its applications are recognized by NVIDIA. The proposed interface exists in the CUBLAS 8.0.},
}

@PhdThesis{Falco2019,
  author      = {Aurélien Falco},
  title       = {Bridging the Gap Between H-Matrices and Sparse Direct Methods for the Solution of Large Linear Systems},
  institution = {Université de Bordeaux},
  year        = {2019},
  abstract    = {Many physical phenomena may be studied through modeling and numerical simulations, commonplace in scientific applications. To be tractable on a computer, appropriated discretization techniques must be considered, which often lead to a set of linear equations whose features depend on the discretization techniques. Among them, the Finite Element Method usually leads to sparse linear systems whereas the Boundary Element Method leads to dense linear systems. The size of the resulting linear systems depends on the domain where the studied physical phenomenon develops and tends to become larger and larger as the performance of the computer facilities increases. For the sake of numerical robustness, the solution techniques based on the factorization of the matrix associated with the linear system are the methods of choice when affordable. In that respect, hierarchical methods based on low-rank compression have allowed a drastic reduction of the computational requirements for the solution of dense linear systems over the last two decades. For sparse linear systems, their application remains a challenge which has been studied by both the community of hierarchical matrices and the community of sparse matrices. On the one hand, the first step taken by the community of hierarchical matrices most often takes advantage of the sparsity of the problem through the use of nested dissection. While this approach benefits from the hierarchical structure, it is not, however, as efficient as sparse solvers regarding the exploitation of zeros and the structural separation of zeros from non-zeros. On the other hand, sparse factorization is organized so as to lead to a sequence of smaller dense operations, enticing sparse solvers to use this property and exploit compression techniques from hierarchical methods in order to reduce the computational cost of these elementary operations. Nonetheless, the globally hierarchical structure may be lost if the compression of hierarchical methods is used only locally on dense submatrices. We here review the main techniques that have been employed by both those communities, trying to highlight their common properties and their respective limits with a special emphasis on studies that have aimed to bridge the gap between them. With these observations in mind, we propose a class of hierarchical algorithms based on the symbolic analysis of the structure of the factors of a sparse matrix. These algorithms rely on a symbolic information to cluster and construct a hierarchical structure coherent with the non-zero pattern of the matrix. Moreover, the resulting hierarchical matrix relies on low-rank compression for the reduction of the memory consumption of large submatrices as well as the time to solution of the solver. We also compare multiple ordering techniques based on geometrical or topological properties. Finally, we open the discussion to a coupling between the Finite Element Method and the Boundary Element Method in a unified computational framework. },
}

@Article{Massias2019,
  author     = {Mathurin Massias and Samuel Vaiter and Alexandre Gramfort and Joseph Salmon},
  title      = {Dual Extrapolation for Sparse Generalized Linear Models},
  year       = {2019},
  eprint     = {arXiv:1907.05830},
  eprinttype = {arXiv},
  abstract   = {Generalized Linear Models (GLM) form a wide class of regression and classification models, where prediction is a function of a linear combination of the input variables. For statistical inference in high dimension, sparsity inducing regularizations have proven to be useful while offering statistical guarantees. However, solving the resulting optimization problems can be challenging: even for popular iterative algorithms such as coordinate descent, one needs to loop over a large number of variables. To mitigate this, techniques known as screening rules and working sets diminish the size of the optimization problem at hand, either by progressively removing variables, or by solving a growing sequence of smaller problems. For both techniques, significant variables are identified thanks to convex duality arguments. In this paper, we show that the dual iterates of a GLM exhibit a Vector AutoRegressive (VAR) behavior after sign identification, when the primal problem is solved with proximal gradient descent or cyclic coordinate descent. Exploiting this regularity, one can construct dual points that offer tighter certificates of optimality, enhancing the performance of screening rules and helping to design competitive working set algorithms.},
}

@InProceedings{Behnezhad2019,
  author    = {Behnezhad, Soheil and Brandt, Sebastian and Derakhshan, Mahsa and Fischer, Manuela and Hajiaghayi, MohammadTaghi and Karp, Richard M. and Uitto, Jara},
  title     = {Massively Parallel Computation of Matching and MIS in Sparse Graphs},
  booktitle = {Proceedings of the 2019 {ACM} Symposium on Principles of Distributed Computing},
  year      = {2019},
  series    = {PODC '19},
  publisher = {ACM},
  location  = {Toronto ON, Canada},
  isbn      = {978-1-4503-6217-7},
  pages     = {481--490},
  doi       = {10.1145/3293611.3331609},
  abstract  = {The Massively Parallel Computation (MPC) model serves as a common abstraction of many modern large-scale parallel computation frameworks and has recently gained a lot of importance, especially in the context of classic graph problems. In this work, we mainly consider maximal matching and maximal independent set problems in the MPC model.\\ 
  These problems are known to admit efficient MPC algorithms if the space available per machine is near-linear in the number n of nodes. This is not only often significantly more than what we can afford, but also allows for easy if not trivial solutions for sparse graphs -- which are common in real-world large-scale graphs. We are, therefore, interested in the low-memory MPC model, where the space per machine is restricted to be strongly sublinear, that is, $n^\delta$ for any constant $0 < \delta < 1$. \\
  We parametrize our algorithms by the arboricity $\lambda$ of the input graph. Our key ingredient is a degree reduction technique that reduces these problems in graphs with arboricity $\lambda$ to the corresponding problems in graphs with maximum degree $poly(\lambda, log n)$ in $O(log^2 log n)$ rounds, giving rise to $O(\sqrt{log \lambda} \cdot log log \lambda + log 2 log n)$-round algorithms.\\
  Our result is particularly interesting for graphs with $poly log n$ arboricity as for such graphs, we get $O(log^2 log n)$-round algorithms. This covers most natural families of sparse graphs and almost exponentially improves over previous algorithms that all required log $O(1)$ n rounds in this regime of MPC.\\
  Finally, our maximal matching algorithm can be employed to obtain a $(1+\epsilon)$-approximate maximum cardinality matching, a $(2+\epsilon)$-approximate maximum weighted matching, as well as a 2-approximate minimum vertex cover in essentially the same number of rounds.},
  acmid     = {3331609},
  address   = {New York, NY, USA},
  keywords  = {approximation algorithms, arboricity, massively parallel computation, matching, maximal independent set, sparse graphs, sublinear memory},
  numpages  = {10},
}

@InProceedings{Chang2019,
  author    = {Chang, Yi-Jun and Fischer, Manuela and Ghaffari, Mohsen and Uitto, Jara and Zheng, Yufan},
  title     = {The Complexity of {$\Delta +1$} Coloring in Congested Clique, Massively Parallel Computation, and Centralized Local Computation},
  booktitle = {Proceedings of the 2019 ACM Symposium on Principles of Distributed Computing},
  year      = {2019},
  series    = {PODC '19},
  publisher = {ACM},
  location  = {Toronto ON, Canada},
  isbn      = {978-1-4503-6217-7},
  pages     = {471--480},
  doi       = {10.1145/3293611.3331607},
  url       = {http://doi.acm.org/10.1145/3293611.3331607},
  abstract  = {In this paper, we present new randomized algorithms that improve the complexity of the classic $(\Delta+1)$-coloring problem, and its generalization $(\Delta+1)$-list-coloring, in three well-studied models of distributed, parallel, and centralized computation: Distributed Congested Clique: We present an $O(1)$-round randomized algorithm for $(\Delta + 1)$-list-coloring in the congested clique model of distributed computing. This settles the asymptotic complexity of this problem. It moreover improves upon the $O(log^\star \Delta)$-round randomized algorithms of Parter and Su [DISC'18] and $O((log log \Delta) \cdot log^\star \Delta)$-round randomized algorithm of Parter [ICALP'18].\\ Massively Parallel Computation: We present a randomized $(\Delta + 1)$-list-coloring algorithm with round complexity $O(\sqrt{log log n})$ in the Massively Parallel Computation (MPC) model with strongly sublinear memory per machine. This algorithm uses a memory of $O(n\alpha)$ per machine, for any desirable constant $\alpha > 0$, and a total memory of $\tilde{O} (m)$, where m is the number of edges in the graph. Notably, this is the first coloring algorithm with sublogarithmic round complexity, in the sublinear memory regime of MPC. For the quasilinear memory regime of MPC, an $O(1)$-round algorithm was given very recently by Assadi et al. [SODA'19].\\ Centralized Local Computation: We show that $(\Delta + 1)$-list-coloring can be solved by a randomized algorithm with query complexity $\Delta O(1) \dots O(log n)$, in the centralized local computation model. The previous state of the art for $(\Delta+1)$-list-coloring in the centralized local computation model are based on simulation of known LOCAL algorithms. The deterministic $O(\sqrt{\Delta poly log \Delta} + log^\star n)$-round LOCAL algorithm of Fraigniaud et al. [FOCS'16] can be implemented in the centralized local computation model with query complexity $\Delta^O(\sqrt{ \Delta poly log \Delta}) \dots O(log^\star n)$; the randomized $O(log^\star \Delta) + 2^O(\sqrt{log log n})$-round LOCAL algorithm of Chang et al. [STOC'18] can be implemented in the centralized local computation model with query complexity $\Delta^O(log\star \Delta) \dots O(log n)$.},
  acmid     = {3331607},
  address   = {New York, NY, USA},
  keywords  = {centralized local computation, coloring, congested clique, massively parallel computation},
  numpages  = {10},
}

@InProceedings{Kurzak2019,
  author    = {Kurzak, Jakub and Tsai, Yaohung M. and Gates, Mark and Abdelfattah, Ahmad and Dongarra, Jack},
  title     = {Massively Parallel Automated Software Tuning},
  booktitle = {Proceedings of the 48th International Conference on Parallel Processing},
  year      = {2019},
  series    = {ICPP 2019},
  publisher = {ACM},
  location  = {Kyoto, Japan},
  isbn      = {978-1-4503-6295-5},
  pages     = {92:1--92:10},
  doi       = {10.1145/3337821.3337908},
  url       = {http://doi.acm.org/10.1145/3337821.3337908},
  abstract  = {This article presents an implementation of a distributed autotuning engine developed as part of the Bench-testing OpenN Software Autotuning Infrastructure project. The system is geared towards performance optimization of computational kernels for graphics processing units, and allows for the deployment of vast autotuning sweeps to massively parallel machines. The software implements dynamic work scheduling to distributed-memory resources and takes advantage of multithreading for parallel compilation and dispatches kernel launches to multiple accelerators. This paper lays out the main design principles of the system and discusses the basic mechanics of the initial implementation. Preliminary performance results are presented, encountered challenges are discussed, and the future directions are outlined.},
  acmid     = {3337908},
  address   = {New York, NY, USA},
  articleno = {92},
  keywords  = {automated software tuning, graphics processing unit},
  numpages  = {10},
}

@InProceedings{Argueta2019,
  author    = {Arturo Argueta and David Chiang},
  title     = {Accelerating Sparse Matrix Operations in Neural Networks on Graphics Processing Units},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  year      = {2019},
  location  = {Florence, IT},
  pages     = {6215--6224},
  abstract  = {Graphics Processing Units (GPUs) are commonly used to train and evaluate neural networks efficiently. While previous work in deep learning has focused on accelerating operations on dense matrices/tensors on GPUs, efforts have concentrated on operations involving sparse data structures. Operations using sparse structures are common in natural language models at the input and output layers, because these models operate on sequences over discrete alphabets. We present two new GPU algorithms: one at the input layer, for multiplying a matrix by a few-hot vector (generalizing the more common operation of multiplication by a one-hot vector) and one at the output layer, for a fused softmax and top-N selection (commonly used in beam search). Our methods achieve speedups over state-of-theart parallel GPU baselines of up to 7$\times$ and 50$\times$, respectively. We also illustrate how our methods scale on different GPU architectures.},
  timestamp = {2019.08.02},
}

@InProceedings{Li2019b,
  author    = {Li, Ming and Hawrylak, Peter and Hale, John},
  title     = {Combining OpenCL and MPI to Support Heterogeneous Computing on a Cluster},
  booktitle = {Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (Learning)},
  year      = {2019},
  series    = {PEARC '19},
  publisher = {ACM},
  location  = {Chicago, IL, USA},
  isbn      = {978-1-4503-7227-5},
  pages     = {5:1--5:6},
  doi       = {10.1145/3332186.3333059},
  url       = {http://doi.acm.org/10.1145/3332186.3333059},
  abstract  = {This paper presents an implementation of a heterogeneous programming model which combines Open Computing Language (OpenCL) and Message Passing Interface (MPI). The model is applied to solving a Markov decision process (MDP) with value iteration method. The performance test is conducted on a high performance computing cluster. At peak performance, the model is able to achieve a 57$\times$ speedup over a serial implementation. For an extremely large input MDP, which has 1,000,000 states, the obtained speedup is still over 12$\times$, showing that this heterogeneous programming model can solve MDPs more efficiently than the serial solver does.},
  acmid     = {3333059},
  address   = {New York, NY, USA},
  articleno = {5},
  keywords  = {HPC, MDP, MPI, OpenCL, heterogeneous computing, parallelism},
  numpages  = {6},
}

@PhdThesis{Mamooler2019,
  author      = {Mamooler, Parisa},
  title       = {The domain decomposition method of Bank and Jimack as an optimized Schwarz method},
  institution = {University of Geneva},
  year        = {2019},
  abstract    = {The aim of this thesis is to introduce the Bank-Jimack domain decomposition method and study its convergence behavior. We are interested in understanding what the precise contribution of the outer coarse mesh is to the convergence behavior of the domain decomposition method proposed by Bank and Jimack. We show for a two subdomain decomposition that the outer coarse mesh can be interpreted as computing an approximation to the optimal transmission condition represented by the Dirichlet to Neumann map, and thus the method of Bank and Jimack can be viewed as an optimized Schwarz method, i.e. a Schwarz method that uses Robin or higher order transmission conditions instead of theclassical Dirichlet ones.},
  timestamp   = {2019.08.17},
}

@Article{Kong2019,
  author      = {Fande Kong},
  title       = {A parallel monolithic multilevel Schwarz preconditioner for the neutron transport criticality calculations with a nonlinear diffusion acceleration method},
  year        = {2019},
  eprint      = {1907.12590v1},
  eprintclass = {math.NA},
  eprinttype  = {arXiv},
  abstract    = {The multigroup neutron transport criticality calculations using modern supercomputers have been widely employed in a nuclear reactor analysis for studying whether or not a system is self-sustaining. However, the design and development of an efficient parallel algorithm for the transport criticality calculations is a challenging task especially when the number of processor cores is large and the unstructured mesh is adopted since both the compute time and the memory usage need to be taken into consideration. In this paper, we study a monolithic multilevel Schwarz preconditioner for the transport criticality calculations using the nonlinear diffusion acceleration (NDA). In NDA, the linear systems of equations arising from the discretizations of the nonlinear diffusion equations and the transport equations need to be efficiently solved. To achieve this goal, we propose a monolithically coupled approach equipped with several important ingredients; e.g., subspace-based coarsening, aggressive coarsening and strength matrix thresholding. The proposed monolithic multilevel method is capable of efficiently handling the linear systems of equations for both the transport system and the diffusion system. In the multilevel method, the construction of coarse spaces is nontrivial and expensive. We propose a subspace-based coarsening algorithm to resolve this issue by exploring the matrix structures of the transport equations and the nonlinear diffusion equations. We numerically demonstrate that the monolithic multilevel preconditioner with the subspace-based coarsening algorithm is twice as fast as that equipped with a full space based coarsening approach on thousands of processor cores for an unstructured mesh neutron transport problem with billions of unknowns.},
  file        = {online:http\://arxiv.org/pdf/1907.12590v1:PDF},
  keywords    = {math.NA, cs.NA},
}

@InProceedings{Regunta2019,
  author    = {S. C. Regunta and S. H. Tondomker and K. Kothapalli},
  title     = {BRICS – Efficient Techniques for Estimating the Farness-Centrality in Parallel},
  booktitle = {2019 IEEE International Parallel and Distributed Processing Symposium Workshops},
  year      = {2019},
  series    = {IPDPSW'19},
  month     = {5},
  pages     = {645--654},
  doi       = {10.1109/IPDPSW.2019.00110},
  abstract  = {In this paper, we study scalable parallel algorithms for estimating the farness-centrality value of the nodes in a given undirected and connected graph. Our algorithms consider approaches that are more suitable for sparse graphs. To this end, we propose four optimization techniques based on removing redundant nodes, removing identical nodes, removing chain nodes, and making use of decomposition based on the biconnected components of the input graph. We test our techniques on a collection of real-world graphs for the time taken and the average error percentage. We further analyze the applicability of our techniques on various classes of real-world graphs. We suggest why certain techniques work better on certain classes of graphs.},
  keywords  = {Optimization;Measurement;Parallel algorithms;Scalability;Silicon;Social networking (online);Estimation;closeness centrality;parallel;real world graphs;estimation},
}

@Article{Carson2019,
  author      = {Erin C. Carson},
  title       = {An Adaptive $s$-step Conjugate Gradient Algorithm with Dynamic Basis Updating},
  year        = {2019},
  date        = {2019-08-12},
  eprint      = {1908.04081v1},
  eprintclass = {math.NA},
  eprinttype  = {arXiv},
  abstract    = {The adaptive $s$-step CG algorithm is a solver for sparse, symmetric positive definite linear systems designed to reduce the synchronization cost per iteration while still achieving a user-specified accuracy requirement. In this work, we improve the adaptive $s$-step conjugate gradient algorithm by use of iteratively updated estimates of the largest and smallest Ritz values, which give approximations of the largest and smallest eigenvalues of $A$, using a technique due to Meurant and Tichý [G. Meurant and P. Tichý, Numer. Algs. (2018), pp.~1--32]. The Ritz value estimates are used to dynamically update parameters for constructing Newton or Chebyshev polynomials so that the conditioning of the $s$-step bases can be continuously improved throughout the iterations. These estimates are also used to automatically set a variable related to the ratio of the sizes of the error and residual, which was previously treated as an input parameter. We show through numerical experiments that in many cases the new algorithm improves upon the previous adaptive $s$-step approach both in terms of numerical behavior and reduction in number of synchronizations.},
  file        = {online:http\://arxiv.org/pdf/1908.04081v1:PDF},
  keywords    = {math.NA, cs.DC, cs.NA},
}

@Article{Yang2019a,
  author      = {Carl Yang and Aydin Buluc and John D. Owens},
  title       = {GraphBLAST: A High-Performance Linear Algebra-based Graph Framework on the GPU},
  year        = {2019},
  eprint      = {1908.01407v2},
  eprintclass = {cs.DC},
  eprinttype  = {arXiv},
  abstract    = {High-performance implementations of graph algorithms are challenging to implement on new parallel hardware such as GPUs, because of three challenges: (1) difficulty of coming up with graph building blocks, (2) load imbalance on parallel hardware, and (3) graph problems having low arithmetic intensity. To address these challenges, GraphBLAS is an innovative, on-going effort by the graph analytics community to propose building blocks based in sparse linear algebra, which will allow graph algorithms to be expressed in a performant, succinct, composable and portable manner. In this paper, we examine the performance challenges of a linear algebra-based approach to building graph frameworks and describe new design principles for overcoming these bottlenecks. Among the new design principles is exploiting input sparsity, which allows users to write graph algorithms without specifying push and pull direction. Exploiting output sparsity allows users to tell the backend which values of the output in a single vectorized computation they do not want computed. Load-balancing is an important feature for balancing work amongst parallel workers. We describe the important load-balancing features for handling graphs with different characteristics. The design principles described in this paper have been implemented in "GraphBLAST", the first open-source linear algebra-based graph framework on GPU targeting high-performance computing. The results show that on a single GPU, GraphBLAST has on average at least an order of magnitude speedup over previous GraphBLAS implementations SuiteSparse and GBTL, comparable performance to the fastest GPU hardwired primitives and shared-memory graph frameworks Ligra and Gunrock, and better performance than any other GPU graph framework, while offering a simpler and more concise programming model.},
  file        = {online:http\://arxiv.org/pdf/1908.01407v2:PDF},
  keywords    = {cs.DC},
}

@Article{Iwashita2019,
  author      = {Takeshi Iwashita and Senxi Li and Takeshi Fukaya},
  title       = {Hierarchical Block Multi-Color Ordering: A New Parallel Ordering Method for Vectorization and Parallelization of the Sparse Triangular Solver in the ICCG Method},
  year        = {2019},
  eprint      = {1908.00741v1},
  eprintclass = {cs.DC},
  eprinttype  = {arXiv},
  abstract    = {In this paper, we propose a new parallel ordering method to vectorize and parallelize the sparse triangular solver, which is called hierarchical block multi-color ordering. In this method, the parallel forward and backward substitutions can be vectorized while preserving the advantages of block multi-color ordering, that is, fast convergence and fewer thread synchronizations. To evaluate the proposed method in a parallel ICCG (Incomplete Cholesky Conjugate Gradient) solver, numerical tests were conducted using five test matrices on three types of computational nodes. The numerical results indicate that the proposed method outperforms the conventional block and nodal multi-color ordering methods in 13 out of 15 test cases, which confirms the effectiveness of the method.},
  file        = {online:http\://arxiv.org/pdf/1908.00741v1:PDF},
  keywords    = {cs.DC},
}

@Article{Kong2019b,
  author   = {Qian Kong and Yan-Fei Jing and Ting-Zhu Huang and Heng-Bin An},
  title    = {Acceleration of the Scheduled Relaxation Jacobi method: promising strategies for solving large, sparse linear systems},
  journal  = {Journal of Computational Physics},
  year     = {2019},
  pages    = {108862},
  issn     = {0021-9991},
  doi      = {https://doi.org/10.1016/j.jcp.2019.108862},
  url      = {http://www.sciencedirect.com/science/article/pii/S0021999119305467},
  abstract = {The main aim of this paper is to develop two algorithms based on the Scheduled Relaxation Jacobi (SRJ) method [J. Comput. Phys., 274 (2014), pp. 695-708] for solving problems arising from the finite-difference discretization of elliptic partial differential equations on large grids. These two algorithms are the Alternating Anderson-Scheduled Relaxation Jacobi (AASRJ) method by utilizing Anderson mixing after each SRJ iteration cycle and the Minimal Residual Scheduled Relaxation Jacobi (MRSRJ) method by minimizing residual after each SRJ iteration cycle, respectively. Through numerical experiments, we show that AASRJ is competitive with the optimal version of the SRJ method [J. Comput. Phys., 332 (2017), pp. 446-460] in most problems we considered here, and MRSRJ outperforms SRJ in all cases. The properties of AASRJ and MRSRJ are demonstrated. Both of them are promising strategies for solving large, sparse linear systems while maintaining the simplicity of the Jacobi method.},
  keywords = {Acceleration, The Scheduled Relaxation Jacobi method, Anderson mixing},
}

@Article{Usman2019,
  author    = {Sardar Usman and Rashid Mehmood and Iyad Katib and Aiiad Albeshri and Saleh M. Altowaijri},
  title     = {ZAKI: A Smart Method and Tool for Automatic Performance Optimization of Parallel SpMV Computations on Distributed Memory Machines},
  journal   = {Mobile Networks and Applications},
  year      = {2019},
  doi       = {10.1007/s11036-019-01318-3},
  abstract  = {SpMV is a vital computing operation of many scientific, engineering, economic and social applications, increasingly being used to develop timely intelligence for the design and management of smart societies. Several factors affect the performance of SpMV computations, such as matrix characteristics, storage formats, software and hardware platforms. The complexity of the computer systems is on the rise with the increasing number of cores per processor, different levels of caches, processors per node and high speed interconnect. There is an ever-growing need for new optimization techniques and efficient ways of exploiting parallelism. In this paper, we propose ZAKI, a data-driven, machine-learning approach and tool, to predict the optimal number of processes for SpMV computations of an arbitrary sparse matrix on a distributed memory machine. The aim herein is to allow application scientists to automatically obtain the best configuration, and hence the best performance, for the execution of SpMV computations. We train and test the tool using nearly 2000 real world matrices obtained from 45 application domains including computational fluid dynamics (CFD), computer vision, and robotics. The tool uses three machine learning methods, decision trees, random forest, gradient boosting, and is evaluated in depth. A discussion on the applicability of our proposed tool to energy efficiency optimization of SpMV computations is given. This is the first work where the sparsity structure of matrices have been exploited to predict the optimal number of processes for a given matrix in distributed memory environments by using different base and ensemble machine learning methods.},
  timestamp = {2019.08.17},
}

@Article{Peng2019,
  author      = {Shaoyi Peng and Sheldon X. -D. Tan},
  title       = {GLU3.0: Fast GPU-based Parallel Sparse LU Factorization for Circuit Simulation},
  year        = {2019},
  eprint      = {1908.00204v2},
  eprintclass = {cs.DC},
  eprinttype  = {arXiv},
  abstract    = {In this article, we propose a new GPU-based sparse LU factorization method, called GLU3.0, solves the aforementioned problems. First, it introduces a much more efficient double-U dependency detection algorithm to make the detection much simpler. Second, we observe that the potential parallelism is different as the matrix factorization goes on. We then develop three different modes of GPU kernel to adapt to different stages to accommodate the computing task changes in the factorization. As a result, the new GLU can dynamically allocate GPU blocks and wraps based on the number of columns in a level to better balance the computing demands and resources during the LU factorization process. Experimental results on circuit matrices from University of Florida Sparse Matrix Collection (UFL) show that the GLU3.0 can deliver 2-3 orders of magnitude speedup over GLU2.0 for the data dependency detection. Furthermore, GLU3.0 achieve 13.0$\times$ (arithmetic mean) and 6.7$\times$ (geometric mean) speedup over GLU2.0 and 7.1$\times$ (arithmetic mean) and 4.8$\times$ (geometric mean) over the recently proposed enhanced GLU2.0 sparse LU solver on the same set of circuit matrices.},
  file        = {online:http\://arxiv.org/pdf/1908.00204v2:PDF},
  keywords    = {cs.DC, cs.DS},
}

@InProceedings{Ribizel2019,
  author    = {T. Ribizel and H. Anzt},
  title     = {Approximate and Exact Selection on GPUs},
  booktitle = {2019 IEEE International Parallel and Distributed Processing Symposium Workshops},
  year      = {2019},
  series    = {IPDPSW'19},
  month     = {May},
  pages     = {471--478},
  doi       = {10.1109/IPDPSW.2019.00088},
  abstract  = {We present a novel algorithm for parallel selection on GPUs. The algorithm requires no assumptions on the input data distribution, and has a much lower recursion depth compared to many state-of-the-art algorithms. We implement the algorithm for different GPU generations, always using the respectively-available low-level communication features, and assess the performance on server-line hardware. The computational complexity of our SampleSelect algorithm is comparable to specialized algorithms designed for - and exploiting the characteristics of - "pleasant" data distributions. At the same time, as the SampleSelect does not work on the actual values but the ranks of the elements only, it is robust to the input data and can complete significantly faster for adversarial data distributions. Additionally to the exact SampleSelect, we address the use case of approximate selection by designing a variant that radically reduces the computational cost while preserving high approximation accuracy.},
  keywords  = {Approximation algorithms;Sorting;Indexes;Kernel;Graphics processing units;Partitioning algorithms;Hardware;parallel selection algorithm;GPU;kth order statistics;approximate threshold selection},
}

@InProceedings{Xie2019a,
  author    = {Xie, Jiaming and Liang, Yun},
  title     = {SPART: Optimizing CNNs by Utilizing Both Sparsity of Weights and Feature Maps},
  booktitle = {Advanced Parallel Processing Technologies},
  year      = {2019},
  editor    = {Yew, Pen-Chung and Stenström, Per and Wu, Junjie and Gong, Xiaoli and Li, Tao},
  publisher = {Springer International Publishing},
  isbn      = {978-3-030-29611-7},
  pages     = {71--85},
  abstract  = {Intense convolution computation and great memory requirement in CNNs constraint their wider deployments and applications. Although both the weights and feature maps in CNNs can be sparse, directly mapping sparse convolution to spGEMM in HPC domain fails to improve the actual performance. Besides, existing sparse formats like CSR are not suitable for encoding the sparse feature maps because convolution operates across rows.},
  address   = {Cham},
}

@InProceedings{Anzt2019b,
  author    = {Hartwig Anzt and Goran Flegar},
  title     = {Are we Doing the Right Thing? A Critical Analysis of the Academic {HPC} Community},
  booktitle = {2019 {IEEE} International Parallel and Distributed Processing Symposium Workshops},
  year      = {2019},
  series    = {IPDPSW'19},
  publisher = {{IEEE}},
  month     = {5},
  doi       = {10.1109/ipdpsw.2019.00122},
  abstract  = {Like in any other research field, academically surviving in the High Performance Computing (HPC) community generally requires to publish papers, in the bast case many of them and in high-ranked journals or at top-tier conferences. As a result, the number of scientific papers published each year in this relatively small community easily outnumbers what a single researcher can read. At the same time, many of the proposed and analyzed strategies, algorithms, and hardware-optimized implementations never make it beyond the prototype stage, as they are abandoned once they served the single purpose of yielding (another) publication. In a time and field where high-quality manpower is a scarce resource, this is extremely inefficient. In this position paper we promote a radical paradigm shift towards accepting high-quality software patches to community software packages as legitimate conference contributions. In consequence, the reputation and appointability of researchers is no longer based on the classical scientific metrics, but on the quality and documentation of open source software contributions -- effectively improving and accelerating the collaborative development of community software.},
}

@InProceedings{Garstka2019,
  author    = {Michael Garstka and Mark Cannon and Paul Goulart},
  title     = {{COSMO}: A conic operator splitting method for large convex problems},
  booktitle = {2019 18th European Control Conference ({ECC})},
  year      = {2019},
  publisher = {{IEEE}},
  month     = {6},
  doi       = {10.23919/ecc.2019.8796161},
  abstract  = {This paper describes the Conic Operator Splitting Method (COSMO), an operator splitting algorithm for convex optimisation problems with quadratic objective function and conic constraints. At each step the algorithm alternates between solving a quasi-definite linear system with a constant coefficient matrix and a projection onto convex sets. The solver is able to exploit chordal sparsity in the problem data and to detect infeasible problems. The low per-iteration computational cost makes the method particularly efficient for large problems, e.g. semidefinite programs in portfolio optimisation, graph theory, and robust control. Our Julia implementation is open-source, extensible, integrated into the Julia optimisation ecosystem and performs well on a variety of large convex problem classes.},
}

@Article{Stramondo2019,
  author    = {Giulio Stramondo and Cătălin Bogdan Ciobanu and Cees Laat and Ana Lucia Varbanescu},
  title     = {Designing and building application-centric parallel memories},
  journal   = {Concurrency and Computation: Practice and Experience},
  year      = {2019},
  month     = {8},
  doi       = {10.1002/cpe.5485},
  abstract  = {Memory bandwidth is a critical performance factor for many applications and architectures. Intuitively, a parallel memory could be a good solution for any bandwidth-limited application, yet building application-centric custom parallel memories remains a challenge. In this work, we present a comprehensive approach to tackle this challenge and demonstrate how to systematically design and implement application-centric parallel memories. Specifically, our approach (1) analyzes the application memory access traces to extract parallel accesses, (2) configures our parallel memory for maximum performance, and (3) builds the actual application-centric memory system. We further provide a simple performance prediction model for the constructed memory system. We evaluate our approach with two sets of experiments. First, we demonstrate how our parallel memories provide performance benefits for a broad range of memory access patterns. Second, we prove the feasibility of our approach and validate our performance model by implementing and benchmarking the designed parallel memories using FPGA hardware and a sparse version of the STREAM benchmark.},
  publisher = {Wiley},
}

@InProceedings{Nie2019a,
  author    = {Jing Nie and Chunlei Zhang and Dan Zou and Fei Xia and Lina Lu and Xiang Wang and Fei Zhao},
  title     = {Adaptive Sparse Matrix-Vector Multiplication on {CPU}-{GPU} Heterogeneous Architecture},
  booktitle = {Proceedings of the 2019 3rd High Performance Computing and Cluster Technologies Conference},
  year      = {2019},
  series    = {HPCCT'19},
  publisher = {{ACM} Press},
  doi       = {10.1145/3341069.3341072},
  abstract  = {SpMV is the core algorithm in solving the sparse linear equations, which is widely used in many research and engineering application field. GPU is the most common coprocessor in high-performance computing domain, and has already been proven to researchers the practical value in accelerating various algorithms. A lot of reletead work has been carried out to optimize parallel SpMV on CPU-GPU platforms, which mainly focuses on reducing the computing overhead on the GPU, including branch divergence and cache missing, and little attention was paid to the overall efficiency of the heterogeneous platform. In this paper, we describe the design and implementation of an adaptive sparse matrix-vector multiplication (SpMV) on CPU-GPU heterogeneous architecture. We propose a dynamic task scheduling framework for CPU-GPU platform to improve the utilization of both CPU and GPU. A double buffering scheme is also presented to hide the data transfer overhead between CPU and GPU. Two deeply optimized SpMV kernels are deployed for CPU and GPU respectively. The evaluation on typical sparse matrices indicates that the proposed algorithm obtains both significant performance increase and adaptability to different types of sparse matrices.},
}

@Comment{jabref-meta: databaseType:biblatex;}
